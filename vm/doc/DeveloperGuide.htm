<!--
    Copyright 2005-2006 The Apache Software Foundation or its licensors, as applicable.

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

	Portions, Copyright © 1991-2005 Unicode, Inc. The following applies to Unicode.

	COPYRIGHT AND PERMISSION NOTICE
    Copyright © 1991-2005 Unicode, Inc. All rights reserved. Distributed under the Terms of Use
	in http://www.unicode.org/copyright.html.
    Permission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files
	and any associated documentation (the "Data Files") or Unicode software and any associated documentation
	(the "Software") to deal in the Data Files or Software without restriction, including without limitation
	the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software,
	and to permit persons to whom the Data Files or Software are furnished to do so, provided that
	(a) the above copyright notice(s) and this permission notice appear with all copies of the Data Files or Software,
	(b) both the above copyright notice(s) and this permission notice appear in associated documentation, and
	(c) there is clear notice in each modified Data File or in the Software as well as in the documentation associated with
	the Data File(s) or Software that the data or software has been modified.
    THE DATA FILES AND SOFTWARE ARE PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
	INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE
	AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED
	IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER
	RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION,
	ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.
    Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise
	to promote the sale, use or other dealings in these Data Files or Software without prior written authorization
	of the copyright holder.
    2. Additional terms from the Database:
    Copyright © 1995-1999 Unicode, Inc. All Rights reserved.
    Disclaimer
    The Unicode Character Database is provided as is by Unicode, Inc. No claims are made as to fitness for
	any particular purpose. No warranties of any kind are expressed or implied. The recipient agrees to determine
	applicability of information provided. If this file has been purchased on magnetic or optical media from Unicode, Inc.,
	the sole remedy for any claim will be exchange of defective media within 90 days of receipt.
    This disclaimer is applicable for all other data files accompanying the Unicode Character Database,
	some of which have been compiled by the Unicode Consortium, and some of which have been supplied by other sources.
    Limitations on Rights to Redistribute This Data
	Recipient is granted the right to make copies in any form for internal distribution and to freely use
	the information supplied in the creation of products supporting the UnicodeTM Standard.
	The files in the Unicode Character Database can be redistributed to third parties or other organizations
	(whether for profit or not) as long as this notice and the disclaimer notice are retained.
	Information can be extracted from these files and used in documentation or programs, as long as there is
	an accompanying notice indicating the source.

-->
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN"
"http://www.w3.org/TR/html4/loose.dtd">
<html>
   <head>
      <meta http-equiv="Content-Type" content=
      "text/html; charset=windows-1252">
      <title>
         Virtual Machine Developer&#39;s Guide
      </title>
      <link rel="Stylesheet" type="text/css" href="drl.css">

   </head>
   <body>
    <p class="title">
         <a name="Top"></a>Dynamic Runtime Layer Developer's Guide
    <p class="TOCHeading"><a href="#Revision_History">Revision History</a>
   </p>
    <p class="TOCHeading"><a href="#Disclaimer">Disclaimer</a>
   </p>
    <p class="TOCHeading">
         <a href="#About_this_document">1. About this Document</a>
   </p>
      <p class="TOC">
         <a href="#Purpose">1.1 Purpose</a>
      </p>
      <p class="TOC">
         <a href="#Intended_Audience">1.2 Intended Audience</a>
      </p>
      <p class="TOC">
         <a href="#Using_this_document">1.3 Using This Document</a>
      </p>
      <p class="TOC">
         <a href="#Conventions_and_Symbols">1.4 Conventions and Symbols</a>
      </p>
      <p class="TOCHeading">
         <a href="#VM_Architecture">2. VM Architecture</a>
      </p>
      <p class="TOC">
         <a href="#Overview">2.1 Overview</a>
      </p>
      <p class="TOC">
         <a href="#Component_Structure">2.2 About Components</a>
      </p>
      <p class="TOC">
         <a href="#major_components">2.3 Major DRL Components</a>
      </p>
      <p class="TOC">
         <a href="#Data_Structures">2.4 Data Structures</a>
      </p>
      <p class="TOC">
         <a href="#Initialization">2.5 Initialization</a>
      </p>
      <p class="TOC">
         <a href="#Root_Set_Enumeration">2.6 Root Set Enumeration</a>
      </p>
      <p class="TOC">
         <a href="#Finalization">2.7 Finalization</a>
      </p>
      <p class="TOCHeading">
         <a href="#VM_Core">3. VM Core</a>
      </p>
      <p class="TOC">
         <a href="#VMCore_architecture">3.1 Architecture</a>
      </p>
      <p class="TOC">
         <a href="#Class_support">3.2 Class Support</a>
      </p>
      <p class="TOC">
         <a href="#Native_Code_Support">3.3 Native Code Support</a>
      </p>
      <p class="TOC">
         <a href="#Stack_Support">3.4 Stack Support</a>
      </p>
      <p class="TOC">
         <a href="#Thread_Management">3.5 Thread Management</a>
      </p>
      <p class="TOC">
         <a href="#Kernel_Classes">3.6 Kernel Classes</a>
      </p>
      <p class="TOC">
         <a href="#Kernel_Class_Natives">3.7 Kernel Class Natives</a>
      </p>
      <p class="TOC">
         <a href="#VM_Services">3.8 VM Services</a>
      </p>
      <p class="TOC">
         <a href="#Exception_Handling">3.9 Exception Handling</a>
      </p>
      <p class="TOC">
         <a href="#JVMTI_Support">3.10 JVMTI Support</a>
      </p>
      <p class="TOC">
         <a href="#Verifier">3.11 Verifier</a>
      </p>
      <p class="TOC">
         <a href="#Utilities">3.12 Utilities</a>
      </p>
      <p class="TOC">
         <a href="#VM_exported_interfaces">3.13 Public Interfaces</a>
      </p>
      <p class="TOCHeading">
         <a href="#JIT_Compiler">4. JIT Compiler</a>
      </p>
      <p class="TOC">
         <a href="#JIT_architecture">4.1 Architecture</a>
      </p>
      <p class="TOC">
         <a href="#Front-end">4.2 Front-end</a>
      </p>
      <p class="TOC">
         <a href="#Optimizer">4.3 Optimizer</a>
      </p>
      <p class="TOC">
         <a href="#Code_selector">4.4 Code Selector</a>
      </p>
      <p class="TOC">
         <a href="#Back-end">4.5 IA-32 Back-end</a>
      </p>
      <p class="TOC">
         <a href="#JIT_utilities">4.6 Utilities</a>
      </p>
      <p class="TOC">
         <a href="#JIT_interfaces">4.7 Public Interfaces</a>
      </p>
      <p class="TOC">
         <a href="#JET_introduction">4.8 Jitrino.JET</a>
      </p>
      <p class="TOCHeading">
         <a href="#EM">5. Execution Manager</a>
      </p>
      <p class="TOC">
         <a href="#EM_architecture">5.1 Architecture</a>
      </p>
      <p class="TOC">
         <a href="#Recompilation">5.2 Recompilation Model</a>
      </p>
      <p class="TOC">
         <a href="#PC">5.3 Profile Collector</a>
      </p>
      <p class="TOC">
         <a href="#Profiler_thread">5.4 Profiler Thread</a>
      </p>
      <p class="TOC">
         <a href="#EM_interfaces">5.5 Public Interfaces</a>
      </p>
      <p class="TOCHeading">
         <a href="#GC">6. Garbage Collector</a>
      </p>
      <p class="TOC">
         <a href="#GC_Architecture">6.1 Architecture</a>
      </p>
      <p class="TOC">
         <a href="#GC_procedure">6.2 GC Procedure</a>
      </p>
      <p class="TOC">
         <a href="#Object_Allocation">6.3 Object Allocation</a>
      </p>
      <p class="TOC">
         <a href="#GC_Exported_Interfaces">6.4 Public Interfaces</a>
      </p>
      <p class="TOCHeading">
         <a href="#Interpreter">7. Interpreter</a>
      </p>
      <p class="TOC">
         <a href="#Characteristics_of_the_Interpreter">7.1 Characteristics</a>
      </p>
      <p class="TOC">
         <a href="#Interpreter_structure">7.2 Internal Structure</a>
      </p>
      <p class="TOC">
         <a href="#Interpreter_support_VM">7.3 Support Functions</a>
      </p>
      <p class="TOCHeading">
         <a href="#Porting_Layer">8. Porting Layer</a>
      </p>
      <p class="TOC">
         <a href="#Porting_Layer_Characteristics">8.1 Characteristics</a>
      </p>
      <p class="TOC">
         <a href="#Component_Manager">8.2 Component Manager</a>
      </p>
      <p class="TOC">
         <a href="#Portlib_exported">8.3 Public Interfaces</a>
      </p>
      <p class="TOCHeading">
         <a href="#Class_Libraries">9. Class Libraries</a>
      </p>
      <p class="TOC">
         <a href="#CL_characteristics">9.1 Characteristics</a>
      </p>
      <p class="TOC">
         <a href="#CL_packaging_structure">9.2 Packaging Structure</a>
      </p>
      <p class="TOCHeading">
         <a href="#Inter_component_Optimizations">10. Inter-component
         Optimizations</a>
      </p>
      <p class="TOC">
         <a href="#Fast_subtype_checking">10.1 Fast Subtype Checking</a>
      </p>
      <p class="TOC">
         <a href="#Direct_call_conversion">10.2 Direct-call Conversion</a>
      </p>
      <p class="TOC">
         <a href="#Fast_constant_string">10.3 Fast Constant-string
         Instantiation</a>
      </p>
      <p class="TOC">
         <a href="#Lazy_exceptions">10.4 Lazy Exceptions</a>
      </p>
      <p class="TOCHeading">
         <a href="#References">11. References</a>
      </p>
      <h1>
         <a name="Revision_History"></a>Revision History
      </h1>
      <table width="100%">
         <tr>
            <td class="TableHeading" width="25%">
               Version
            </td>
            <td class="TableHeading" width="50%">
               Version Information
            </td>
            <td class="TableHeading">
               Date
            </td>
         </tr>
         <tr>
            <td class="TableCell" width="25%">
               Initial version
            </td>
            <td class="TableCell">
               Intel, Nadya Morozova: document created.
            </td>
            <td class="TableCell">
               November 16, 2005
            </td>
         </tr>
         <tr>
            <td class="TableCell" width="25%">
               Version 1.0
            </td>
            <td class="TableCell">
               Intel, Nadya Morozova: document updated and expanded.
            </td>
            <td class="TableCell">
               March 2, 2006
            </td>
         </tr>
      </table>
      <h1>
         <a name="Disclaimer"></a>Disclaimer and Legal Information
      </h1>
      <p>
         Copyright 2005-2006 The Apache Software Foundation or its licensors, as
         applicable.
      </p>
      <p>
         Licensed under the Apache License, Version 2.0 (the
         &quot;License&quot;); you may not use this file except in compliance
         with the License. You may obtain a copy of the License at

         <a href=
         "http://www.apache.org/licenses/LICENSE-2.0">http://www.apache.org/licenses/LICENSE-2.0</a>
      </p>
      <p>
         Unless required by applicable law or agreed to in writing, software
         distributed under the License is distributed on an &quot;AS IS&quot;
         BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
         implied. See the License for the specific language governing
         permissions and limitations under the License.
</p>
      <p> Portions, Copyright &copy; 1991-2005 Unicode, Inc. The following applies to Unicode. <br>
        <br>
COPYRIGHT AND PERMISSION NOTICE</p>
      <p>        Copyright &copy; 1991-2005 Unicode, Inc. All rights reserved. Distributed under the Terms of Use
        in <a href="http://www.unicode.org/copyright.html"  target="_blank">http://www.unicode.org/copyright.html</a>.
        Permission is hereby granted, free of charge, to any person obtaining a copy of the Unicode data files
        and any associated documentation (the &quot;Data Files&quot;) or Unicode software and any associated documentation
        (the &quot;Software&quot;) to deal in the Data Files or Software without restriction, including without limitation
        the rights to use, copy, modify, merge, publish, distribute, and/or sell copies of the Data Files or Software,
        and to permit persons to whom the Data Files or Software are furnished to do so, provided that
        (a) the above copyright notice(s) and this permission notice appear with all copies of the Data Files or Software,
        (b) both the above copyright notice(s) and this permission notice appear in associated documentation, and
        (c) there is clear notice in each modified Data File or in the Software as well as in the documentation associated with
        the Data File(s) or Software that the data or software has been modified.</p>
      <p> THE DATA FILES AND SOFTWARE ARE PROVIDED &quot;AS IS&quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED,
        INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE
        AND NONINFRINGEMENT OF THIRD PARTY RIGHTS. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR HOLDERS INCLUDED
        IN THIS NOTICE BE LIABLE FOR ANY CLAIM, OR ANY SPECIAL INDIRECT OR CONSEQUENTIAL DAMAGES, OR ANY DAMAGES WHATSOEVER
        RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION,
        ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THE DATA FILES OR SOFTWARE.</p>
      <p> Except as contained in this notice, the name of a copyright holder shall not be used in advertising or otherwise
        to promote the sale, use or other dealings in these Data Files or Software without prior written authorization
        of the copyright holder.</p>
      <p> 2. Additional terms from the Database:</p>
      <p>Copyright &copy; 1995-1999 Unicode, Inc. All Rights reserved.</p>
      <p>Disclaimer </p>
      <p> The Unicode Character Database is provided as is by Unicode, Inc. No claims are made as to fitness for
        any particular purpose. No warranties of any kind are expressed or implied. The recipient agrees to determine
        applicability of information provided. If this file has been purchased on magnetic or optical media from Unicode, Inc.,
        the sole remedy for any claim will be exchange of defective media within 90 days of receipt.
        This disclaimer is applicable for all other data files accompanying the Unicode Character Database,
        some of which have been compiled by the Unicode Consortium, and some of which have been supplied by other sources.</p>
      <p> Limitations on Rights to Redistribute This Data</p>
      <p> Recipient is granted the right to make copies in any form for internal distribution and to freely use
        the information supplied in the creation of products supporting the Unicode<sup>TM</sup> Standard.
        The files in the Unicode Character Database can be redistributed to third parties or other organizations
        (whether for profit or not) as long as this notice and the disclaimer notice are retained.
        Information can be extracted from these files and used in documentation or programs, as long as there is
        an accompanying notice indicating the source. </p>
      <h1>
         <a name="About_this_document"></a>1. About This Document
      </h1>
      <h2>
         <a name="Purpose"></a>1.1 Purpose
      </h2>
      <p>
         This document introduces DRL, the dynamic run-time layer, explains
         basic concepts and terms, and gives an overview of the product&#39;s
         structure and interfaces for inter-component communication. Special
         focus is given to the virtual machine, DRLVM. Use this document to
         focus on the DRLVM implementation specifics and to understand the
         internal peculiarities of the product.
</p>
      <p>The document describes version 1 of the DRL virtual machine donated in March 2006. </p>
      <h2>
         <a name="Intended_Audience"></a>1.2 Intended Audience
      </h2>
      <p>
         The target audience for the document includes a wide community of
         engineers interested in using DRLVM and in working further with the
         product to contribute to its development.
      </p>
      <h2>
         <a name="Using_this_document"></a>1.3 Using This Document
      </h2>
      <p>
         This document consists of several major parts describing the key
         processes and components of the DRL virtual machine, as follows:
      </p>
      <p>
         <a href="#VM_Architecture">Part 2. VM Architecture</a> provides an
         overview of the DRL component-based model and describes the major
         inter-component processes running inside the virtual machine, such as
         <a href="#Root_Set_Enumeration">root set enumeration</a> and <a href=
         "#Finalization">object finalization</a>. The part also comprises a
         section about <a href="#Data_Structures">data structures</a> used in
         DRLVM. You can start with this part to learn about major principles of
         VM internal operation.
      </p>
      <p>
         <a href="#VM_Core">Part 3. VM Core</a> gives an in-depth description
         of the core virtual machine and its subcomponents responsible for
         various functions of the virtual machine, including <a href=
         "#Stack_Walking">stack walking</a> and <a href=
         "#Thread_Management">thread management</a>.
      </p>
      <p>
         <a href="#JIT_Compiler">Part 4. JIT Compiler</a> describes compilation
         paths and specific features of the DRL just-in-time compiler. Consult
         this part of the guide for details on optimizations implemented in the
         DRL JIT compiler and its code generation path.
      </p>
      <p>
         <a href="#EM">Part 5. Execution Manager</a> shows the details of the
         dynamic profile-guided optimization subsystem. In this part, you can
         find information on method profiles and recompilation logic.
      </p>
      <p>
         <a href="#GC">Part 6. Garbage Collector</a> focuses on object
         allocation and garbage collection processes. This part contains a
         description of the garbage collector component and of its interaction
         with the VM core.
      </p>
      <p>
         <a href="#Interpreter">Part 7. Interpreter</a> has a description of
         the interpreter component and its debugging services.
      </p>
      <p>
         <a href="#Porting_Layer">Part 8. Porting Layer</a> gives an overview
         of platform-dependent functionality used in DRL. The part also
         includes an overview of the <a href="#Component_Manager">component
         manager</a>.
      </p>
      <p>
         <a href="#Class_Libraries">Part 9. Class Libraries</a> gives
         information on the layout and characteristics of the Java<a href=
         "#*">*</a> class libraries interacting with the DRL virtual machine.
      </p>
      <p>
         <a href="#Inter_component_Optimizations">Part 10. Inter-component
         Optimizations</a> is devoted to performance-improving operations that
         involve multiple components.
      </p>
      <p>
         <a href="#References">Part 11. References</a> lists the links to
         external materials supporting this document. These materials include
         specifications, manual on programming, and articles on specific
         issues. You can consult this part of the document for directions on
         investigating a specific problem or alternative ways of implementing
         specific features.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Conventions_and_Symbols"></a>1.4 Conventions and Symbols
      </h2>
      <p>
         This document uses the <a href="conventions.htm">unified
         conventions</a> for the DRL documentation kit.
      </p>
      <p>
         The table below provides the definitions of all acronyms used in the
         document.
      </p>
      <table class="normalTable" border="0" cellpadding="0" width="100%">
         <tr>
            <td class="TableHeading">
               Acronym
            </td>
            <td class="TableHeading">
               Definition
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               API
            </td>
            <td class="TableCell">
               Application Program Interface
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               APR
            </td>
            <td class="TableCell">
               Apache Portable Runtime Layer
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               CFG
            </td>
            <td class="TableCell">
               Control Flow Graph
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               CG
            </td>
            <td class="TableCell">
               Code Generator
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               CLI
            </td>
            <td class="TableCell">
               Common Language Interface
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               DFG
            </td>
            <td class="TableCell">
               Data Flow Graph
            </td>
         </tr>
         <tr>
            <td class="TableCell" height="40">
               DPGO
            </td>
            <td class="TableCell" height="40">
               Dynamic Profile-guided Optimizations
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               DRL
            </td>
            <td class="TableCell">
               Dynamic Run-time Layer
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               DRLVM
            </td>
            <td class="TableCell">
               Dynamic Run-time Layer Virtual Machine
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               EE
            </td>
            <td class="TableCell">
               Execution Engine
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               EM
            </td>
            <td class="TableCell">
               Execution Manager
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               FP
            </td>
            <td class="TableCell">
               Floating Point
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               GC
            </td>
            <td class="TableCell">
               Garbage Collector
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               HIR
            </td>
            <td class="TableCell">
               High-level Intermediate Representation
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               IR
            </td>
            <td class="TableCell">
               Intermediate Representation
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               J2SE<a href="#*">*</a>
            </td>
            <td class="TableCell">
               Java<a href="#*">*</a> 2 Standard Edition
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               JCL
            </td>
            <td class="TableCell">
               Java<a href="#*">*</a> Class Libraries
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               JIT
            </td>
            <td class="TableCell">
               Just-in-time Compiler
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               JNI
            </td>
            <td class="TableCell">
               Java<a href="#*">*</a> Native Interface
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               JVM
            </td>
            <td class="TableCell">
               Java<a href="#*">*</a> Virtual Machine
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               JVMTI
            </td>
            <td class="TableCell">
               JVM Tool Interface
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               LIR
            </td>
            <td class="TableCell">
               Low-level Intermediate Representation
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               LMF
            </td>
            <td class="TableCell">
               Last Managed Frame
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               LOB
            </td>
            <td class="TableCell">
               Large Object Block
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               LOS
            </td>
            <td class="TableCell">
               Large Object Space
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               OS
            </td>
            <td class="TableCell">
               Operating System
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               PC
            </td>
            <td class="TableCell">
               Profile Collector
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               SIMD
            </td>
            <td class="TableCell">
               Single Instruction Multiple Data
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               SOB
            </td>
            <td class="TableCell">
               Single Object Block
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               SSA
            </td>
            <td class="TableCell">
               Single Static Assignment
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               SSE, SSE2
            </td>
            <td class="TableCell">
               Streaming SIMD Extensions (2)
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               STL
            </td>
            <td class="TableCell">
               Standard Template Library
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               TBS
            </td>
            <td class="TableCell">
               Time-based Sampling
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               TLS
            </td>
            <td class="TableCell">
               Thread Local Storage
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               TM
            </td>
            <td class="TableCell">
               Thread Manager
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               VM
            </td>
            <td class="TableCell">
               Virtual Machine, same as JVM in current document
            </td>
         </tr>
      </table>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="VM_Architecture"></a>2. VM Architecture
      </h1>
      <h2>
         <a name="Overview"></a>2.1 Overview
      </h2>
      <p>
         The Dynamic Runtime Layer (DRL) is a clean-room implementation of the
         Java<a href="#*">*</a> 2 Platform, Standard Edition (J2SE<a href=
         "#*">*</a>) 1.5.0. This Java<a href="#*">*</a> run-time environment
         consists of the virtual machine (DRLVM), and a set of Java<a href=
         "#*">*</a> class libraries (JCL). The product is released in open
         source. The virtual machine is written in C++ code and a small amount
         of assembly code. This document focuses on the virtual machine, and
         gives a short overview of the class libraries supporting it.
      </p>
      <p>
         Key features of DRL include the following:
      </p>
      <ul>
         <li>
            <i>Modularity</i>: Functionality is grouped into a limited number
            of coarse-grained modules with well defined interfaces.

         <li>
            <i>Pluggability</i>: Module implementations can be replaced at
            compile time or run time. Multiple implementations of a given
            module are possible.

         <li>
            <i>Consistency</i>: Interfaces are consistent across platforms.

         <li>
            <i>Performance</i>: Interfaces fully enable implementation of
            modules optimized for specific target platforms.

      </ul>
      <h2>
         <a name="Component_Structure"></a>2.2 About Components
      </h2>
      <p>
         The DRL virtual machine reconciles high performance with the extensive
         use of well-defined interfaces between its components.
      </p>
      <h3><a name="CompInterfInst"></a>
         2.2.1 Components, Interfaces, and Instances
      </h3>
      <p>
         A <em>component</em> corresponds to one static or dynamic library, and
         several libraries linked statically or dynamically at run time make up
         the managed run-time environment. For details on components linking,
         see section <a href="#linking_models">2.2.2 Linking Models</a>.
      </p>
      <p>
         DRLVM components communicate via functional interfaces. An
         <em>interface</em> is a pointer to a table of function pointers to
         pure C methods. Interfaces have string names, which unambiguously
         identify their function table layout. Each component exposes the
         <em>default interface</em> to communicate with the <a href=
         "#Component_Manager">component manager</a>, and one or more interfaces
         for communication with other components.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In the current version, only the <a href="#EM">execution manager</a> uses the component
         manager. Other components will migrate to this new model in further
         releases.
      </p>
      <p>
         DRL can also operate with co-existing component instances, as requires
         the Invocation API [<a href="#Invoc_api_ref">7</a>]. An
         <em>instance</em> of a component contains a pointer to its default
         interface and
         component-specific data. The <a href="#Porting_Layer">porting layer</a>
         always has exactly one instance. This allows a compiler to in-line
         calls to the porting layer functions. Other components have the same
         number of instances as the VM core does.
      </p>
      <p class="class">
         Background
      </p>
      <p class="notetext">
         In Java<a href="#*">*</a> programming, components, interfaces, and
         instances can be described in terms of classes, interfaces and
         objects. A VM component encapsulates common features, attributes, and
         properties of virtual machines, and maps to a Java<a href="#*">*</a>
         class. VM interfaces are tables of methods implemented and exposed by
         the class. If several virtual machines exist in the same address
         space, they all expose the same interfaces. These VM instances are
         instances of the VM class, or objects.<br>
          The <a href="#Component_Manager">component manager</a> enables
         explicit creation of component instances by exposing the
         <code>CreateNewInstance()</code> function, which corresponds to the
         Java<a href="#*">*</a> operator <code>new()</code>. Components with
         only one instance correspond to static class methods in Java<a href=
         "#*">*</a>. All components are initialized at load time.
      </p>
      <p>
         Subsequent sections define each component and provide information on
         public interfaces, dependencies and other component specifics.
      </p>
      <h3>
         <a name="linking_models"></a>2.2.2 Linking Models
      </h3>
      <p>
         Libraries corresponding to different DRL components are linked by one
         of the following models:
      </p>
      <ul>
         <li>
            Unconditionally required components, such as the porting layer, are
            plugged at the source level and linked statically to the main
            executable. The same applies to the code that loads other
            components, see section <a href="#Component_Manager">8.2 Component
            Manager</a>.

         <li>
            Components required by the VM configuration, such as a specific
            garbage collector or a JIT compiler, are loaded at run time based
            on the configuration settings. For example, the virtual machine on
            a multiprocessor system can load a more complex garbage collector
            that takes advantage of parallel processing.

         <li>
            Third-party components shipped as dynamic libraries, such as the
            <a href="#Memory_Management">memory manager</a>, are also loaded at run time.

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="major_components"></a>2.3 Major DRL Components
      </h2>
      <p>
         Figure 1 below displays the major DRL components and their interfaces.
      </p>
      <p align="center">
         <img src="images/DRL_structure.gif" alt="Major DRL Components" border=
         "0">
      </p>
      <p class="special">
         <a name="FigureDRLComponents"></a>Figure 1. Major DRL Components
      </p>
      <p>
         Figure 1 demonstrates the DRL Java<a href="#*">*</a> virtual machine
         major components, and the class libraries that support the machine.
         These components are responsible for the following functions:
      </p>
      <ul>
         <li>
            <a href="#Class_Libraries">Class libraries</a> include a set of
            classes and interfaces that constitute the application programming
            interface (API) for the Java<a href="#*">*</a> run-time
            environment. The Java<a href="#*">*</a> class libraries (JCL)
            complement the virtual machine to make up the Dynamic Runtime
            Layer.
            <p>
               The other components listed below make part of the DRL virtual
               machine.
            </p>

         <li>
            <a href="#VM_Core">VM core</a> with its subcomponents concentrates
            most JVM control functions.

         <li>
            <i>Execution engine</i> is the generic term for components that
            execute bytecode or prepare it for execution. DRLVM
            currently features the following execution engines:
            <ul>
               <li>
                  The <a href="#JIT_Compiler">Jitrino.opt</a> optimizing JIT
                  compiler, which compiles code keeping reasonable balance
                  between compilation time and quality of the generated code.

               <li>
                  The <a href="#JET_introduction">Jitrino.JET</a> just-in-time
                  compiler aimed to fast bytecode compilation with almost no
                  optimizations. Jitrino.JET uses the same interfaces and is
                  packaged in the same dynamic library as the optimizing
                  compiler.

               <li>
                  The <a href="#Interpreter">Interpreter</a> for easier
                  debugging.

            </ul>

        <li>
            <a href="#EM">Execution manager</a> selects the execution engine
            for compiling a method, handles profiles and the dynamic
            recompilation logic.

        <li>
            <a href="#GC">Garbage collector</a> allocates Java<a href=
            "#*">*</a> objects in the heap memory and reclaims unreachable
            objects by using the <a href="#GC_procedure">mark sweep and compaction</a> algorithm.

        <li>
            <a href="#Porting_Layer">Porting layer</a> hides platform-specific
            details from other VM components behind a single interface. In the
            current implementation, the porting layer is based on the Apache
            Portable Runtime layer [<a href="#APR_ref">14</a>].

      </ul>
      <p>
         Depending on the configuration, you can use multiple execution engine
         components, for example, an interpreter and optimizing JIT.
         Simultaneous use of multiple JIT compilers can provide different
         trade-offs between compilation time and code quality.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Data_Structures"></a>2.4 Data Structures
      </h2>
      <p>
         This section provides an overview of data structures in DRLVM, typical
         examples of data structures, and the exposed data layout of public
         data structures.
      </p>
      <p>
         In DRLVM, all data structures are divided into the following groups:
      </p>
      <ul>
         <li>
            <i>Private</i> data structures can only be used inside a specific DRLVM component.
			Other components can only access such data structures via exported component interfaces.
         <li>
            <i>Public</i> data structures shared across different DRLVM
            components as listed in this section.

      </ul>
      <p>
         For example, when compiling an access operation to an instance field,
         the JIT calls the public <code>VM_JIT</code> interface function to
         obtain the offset, and uses the result to generate the appropriate
         load instruction. Another example is the VM core internal
         representation of a class object.
      </p>
      <h3>
         <a name="object_layout"></a>2.4.1 Object Layout
      </h3>
      <p>
         DRLVM exports data structures in accordance with the JNI [<a href=
         "#JNI_ref">5</a>] and JVMTI [<a href="#JVMTI_ref">4</a>] standards. In
         addition to these structures, DRLVM shares information about an object
         layout across its components. In particular, the Java Native Interface
         does not specify the structure of <code>jobject</code>, and DRLVM
         defines it as illustrated below.
      </p>
      <pre>
typedef struct ManagedObject {
  VTable *vt;
  uint32 obj_info;
  /* Class-specific data */
} ManagedObject;
struct _jobject { ManagedObject* object; }
typedef struct _jobject*  jobject;
</pre>
      <p>
         The <code>jobject</code> structure contains the following elements:
      </p>
      <ul>
         <li>
            The <code>vt</code> field points to the object virtual-method
            table.
            <p>
               <a name="vtable"></a>Each class has one <i>virtual-method
               table</i> (VTable) with class-specific information to perform
               common operations, such as getting pointers to virtual methods.
               The VTable is shared across all instances of a class. During garbage
               collection, the VTable supplies such information, as the size of
               the object and the offset of each reference stored in the
               instance.
            </p>

         <li>
            The <code>obj_info</code> field is used during synchronization and
            garbage collection. This is a 32-bit value on all supported
            architectures. This field also stores the hash code of an instance.

      </ul>
      <p>
         Class-specific instance fields immediately follow the <code>vt</code>
         and <code>obj_info</code> fields. Representation of array instances is
         shared between the garbage collector and the JIT compiler. The VM core
         determines the specific offsets to store the array length and the
         first element of the array. This way, the VM core makes these fields
         available for the garbage collector and the JIT via the VM interface.
      </p>
      <dl>
         <dt>
            Example
         </dt>
         <dd>
            The excerpt of code below illustrates the usage of an object
            structure in DRLVM for the <code>GetBooleanField()</code> JNI
            function.
         </dd>
      </dl>
<pre>
typedef jobject ObjectHandle;

jboolean JNICALL GetBooleanField(JNIEnv *env,
                                 jobject obj,
                                 jfieldID fieldID)
{
    Field *f = (Field *) fieldID;
    /* Initialize the class if the field is accessed */
    if (!ensure_initialised(env, f-&gt;get_class())) {
        return 0; /* Error */
    }

    ObjectHandle h = (ObjectHandle) obj;

    tmn_suspend_disable();       //-- Do not allow GC suspension --v
    Byte *java_ref = (Byte *)h-&gt;object;
    jboolean val = *(jboolean *)(java_ref + offset);
    tmn_suspend_enable();        //--------------------------------^

    return val;
} // GetBooleanField
</pre>
      <h3>
         <a name="compressed_references"></a>2.4.2 Compressed References
      </h3>
      <p>
         To decrease memory footprint on 64-bit platforms [<a href=
         "#compres_ref">11</a>], direct object and VTable pointers are
         compressed in the Java<a href="#*">*</a> heap to 32-bit values.
      </p>
      <p>
         To calculate a direct heap pointer, the system adds the pointer to the
         heap base to the compressed value from the reference field. Similarly,
         a direct pointer to an object VTable equals to the compressed value
         stored in the first 32 bits of the object plus the base VTable
         pointer. This limits the maximum heap size to 4 GB, but significantly
         reduces the average object size and the work set size, and improves
         cache performance.
      </p>
      <p>
         Apart from the basic assumptions about object layout and the VTable
         cache, all interaction between major DRLVM components is achieved
         through function calls.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Initialization"></a>2.5 Initialization
      </h2>
      <p>
         VM initialization is a sequence of operations performed at the virtual
         machine start-up before execution of user applications. Currently,
         DRLVM does not support the invocation API [<a href=
         "#Invoc_api_ref">7</a>], and initialization follows the sequence
         described below. The subsection <a href="#destroying_vm">2.5.3
         Destroying the VM</a> below also describes the virtual machine
         shutdown sequence.
      </p>
      <p>
         The <code>main(&hellip;)</code> function is responsible for the major
         stages of initialization sequence and does the following:
      </p>
      <ol>
         <li>
            Initializes the logger

         <li>
            Performs the first pass arguments parsing

         <li>
            Creates a VM instance by calling the <code>create_vm()</code>
            function

         <li>
            Runs the user application by calling the <a href=
            "#vmstarterstart"><code>VMStarter.start()</code></a> method

         <li>
            Destroys the VM instance by calling the <code>destroy_vm()</code>
            function

      </ol>
      <p>
         The subsequent sections describe these initialization stages in
         greater detail.
      </p>
      <h3><a name="1stPass"></a>
         2.5.1 First pass Arguments Parsing
      </h3>
      <p>
         At this stage, the VM splits all command-line arguments into the
         following groups:
      </p>
      <ul>
         <li>
            <code>&lt;vm-arguments&gt;</code> for initializing the VM instance

         <li>
            <code>&lt;class-name | -jar jar-file&gt;</code> for the name or
            class or <code>.jar</code> file

         <li>
            <code>&lt;java-arguments&gt;</code> for the user application

      </ul>
      <p>
         The virtual machine then creates the <code>JavaVMInitArgs</code>
         structure from <code>&lt;vm-arguments&gt;</code>.
      </p>
      <h3><a name="creating_vm"></a>
         2.5.2 Creating the VM
      </h3>
      <p>
         The <code>create_vm()</code> function is a prototype for
         <code>JNI_CreateJavaVM()</code> responsible for creating and
         initializing the virtual machine. This function does the following:
      </p>
      <ol>
         <li value="0">
            For Linux<a href="#*">*</a> platforms, initializes the threading
            system.<br>
             No actions are performed on Windows<a href="#*">*</a> platforms.
            Other steps apply to both operating systems.

         <li>
            Attaches the current thread. This is the first step of the
            three-step procedure of attaching the thread to the VM. See steps
            15 and 19 for further steps of the attaching procedure.
              <ol>
               <li>
                  Creates synchronization objects.

               <li>
                  Initializes the <code>VM_thread</code> structure and stores
                  the structure in the thread local storage.

            </ol>

         <li>
            Initializes the VM global synchronization locks.

         <li>
            Creates the component manager.

         <li>
            Loads the garbage collector and interpreter libraries.

         <li>
            Initializes basic VM properties, such as <code>java.home</code>,
            <code>java.library.path</code>, and
            <code>vm.boot.class.path</code>, according to the location of the
            VM library.<br>
             The list of boot class path <code>.jar</code> files is hard-coded
            into the VM library. Use <code>&ndash;Xbootclasspath</code>
            command-line options to change the settings.

         <li>
            Initializes system signal handlers.

         <li>
            Parses VM arguments.

         <li>
            Initializes JIT compiler instances.

         <li>
            Initializes the VM memory allocator.

         <li>
            Initializes the garbage collector by calling <a href=
            "#gc_init"><code>gc_init()</code></a>.

         <li>
            Preloads basic API native code dynamic libraries.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               The <code>vm.other_natives_dlls</code> property defines the list
               of libraries to be loaded.
            </p>

         <li>
            Initializes the JNI support VM core component.

         <li>
            Initializes the JVMTI support functionality, loads agent dynamic
            libraries. At this step, the <em>primordial phase</em> starts.

         <li>
            Attaches the current thread and creates the <a href=
            "#M2nFrame">M2nFrame</a> at the top of the stack (step 2).

         <li>
            Initializes the bootstrap class loader.

         <li>
            Preloads the classes required for further VM operation.

         <li>
            Caches the class handles for the core classes into the VM
            environment.

         <li>
            Attaches the current thread (step 3).
            <ol>
               <li>
                  Creates the <code>java.lang.Thread</code> object for the
                  current thread.

               <li>
                  Creates the thread group object for the main thread group and
                  includes the main thread in this group.

               <li>
                  Sets the system class loader by calling
                  <code>java.lang.ClassLoader.getSystemClassLoader()</code>.

            </ol>

         <li>
            Sends the <code>VMStart</code> JVMTI event. This step begins the
            <em>start phase</em>.

         <li>
            Sends the <code>ThreadStart</code> JVMTI event for the main thread.
            Send the <code>VMInit</code> JVMTI event. At this stage, the
            <em>live phase</em> starts.

         <li>
            Calls the <a href=
            "#vmstarterinit"><code>VMStarter.initialize()</code></a> method.

      </ol>
      <h3>
         <a name="destroying_vm"></a>2.5.3 Destroying the VM
      </h3>
      <p>
         The <code>destroy_vm()</code> function is a prototype for
         <code>JNI_DestroyJavaVM()</code> responsible for terminating operation
         of a VM instance. This function calls the <a href=
         "#vmstartershutdown"><code>VMStarter.shutdown()</code></a> method.
      </p>
      <h3><a name="VMStarter"></a>
         2.5.4 VMStarter class
      </h3>
      <p>
         This Java<a href="#*">*</a> class supports specific VM core tasks by
         providing the following methods:
      </p>
      <dl>
         <dt>
            <a name="vmstarterinit"></a>initialize()
         </dt>
         <dd>
            Called by the <code>create_vm()</code> method, does the following:
            <ul>
               <li>
                  Starts the finalizer and execution manager helper threads

               <li>
                  Registers the shutdown hook for proper helper threads
                  shutdown

            </ul>
         </dd>
         <dt>
            <a name="vmstartershutdown"></a>shutdown()
         </dt>
         <dd>
            Called by the <code>destroy_vm()</code> method, does the following:

            <ul>
               <li>
                  Waits for non-daemon threads

               <li>
                  Calls the <code>System.exit()</code> method

            </ul>
         </dd>
         <dt>
            <a name="vmstarterstart"></a>start()
         </dt>
         <dd>
            Runs the user application:
            <ul>
               <li>
                  Initializes the system class loader

               <li>
                  Loads the main class of the application

               <li>
                  Obtains the <code>main()</code> method via reflection

               <li>
                  Starts the thread that invokes the <code>main()</code> method
                  and caches exceptions from this method

            </ul>
         </dd>
      </dl>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Root_Set_Enumeration"></a>2.6 Root Set Enumeration
      </h2>
      <p>
         DRLVM automatically manages the Java<a href="#*">*</a> heap by using
         tracing collection techniques.
      </p>
      <h3>
         2.6.1 About Roots
      </h3>
      <p>
         <em>Root set enumeration</em> is the process of collecting the initial
         set of references to live objects, the <em>roots</em>. Defining the
         root set enables the garbage collector to determine a set of all
         objects directly reachable from the all running threads and to reclaim
         the rest of the heap memory. The set of all live objects includes
         objects referred by roots and objects referred by other live objects.
         This way, the set of all live objects can be constructed by means of
         transitive closure of the objects referred by the root set.
      </p>
      <p>
         Roots consist of:
      </p>
      <ul>
         <li>
            Global references, such as static fields of classes, JNI global handles,
            interned string references
         <li>
            Thread-specific references in managed stack frames, local JNI
            handles, and the per-thread data structures maintained by the VM
            core

      </ul>
      <h3>
         2.6.2 Black-box Method
      </h3>
      <p>
         In DRLVM, the <em>black-box method</em> is designed to accommodate
         precise enumeration of the set of root references. The GC considers
         everything outside the Java<a href="#*">*</a> heap as a black box, and
         has little information about the organization of the virtual machine.
         The GC relies on the support of the VM core to enumerate the root set.
         In turn, the VM considers the thread stack as the black box, and uses
         the services provided by the JIT and interpreter to iterate over the
         stack frames and enumerate root references in each stack frame.
      </p>
      <p>
         Enumeration of a method stack frame is best described in terms of safe
         points and GC maps. <a name="GC_map"></a>The <em>GC map</em> is the
         data structure for finding all live object pointers in the stack
         frame. Typically, the GC map contains the list of method arguments and
         local variables of the reference type, as well as spilt over
         registers, in the form of offsets from the stack pointer. The GC map
         is associated with a specific point in the method, the <em>safe
         point</em>. The JIT determines the set of safe points at the method
         compilation time, and the interpreter does this at run time. This way,
         call sites and backward branches enter the list. During method
         compilation, the JIT constructs the GC maps for each safe point. The
         interpreter does not use stack maps, but keeps track of object
         references dynamically, at run time. With the black-box method, the VM
         has little data on the thread it needs to enumerate, only the register
         context.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         2.6.3 Enumeration Procedure
      </h3>
      <p>
         When the GC decides to do garbage collection, it enumerates all roots
         as described below.
      </p>
      <ol>
         <li>
            The garbage collector calls the VM core function
            <code>vm_enumerate_root_set_all_threads()</code>.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               Currently, the DRLVM implementation does not support concurrent
               garbage collectors.
            </p>

         <li>The
            VM core suspends all threads, see section <a href="#Safe_suspension">3.5.4 Safe Suspension</a>.
         <li>
            The VM core enumerates all the global and thread-local references in
            the run-time data structures: the VM enumerates each frame of each
            thread stack. <br>
           For each frame produced by the JIT-compiled code, it
           is necessary to enumerate the roots on that frame and to unwind to
           the previous frame. For that, the VM calls methods
           <code>JIT_get_root_set_from_stack_frame()</code> and
            <code>JIT_unwind_stack_frame()</code>.
            <ol>
               <li>
                  The VM identifies the method that owns the stack frame by looking
                  up the instruction pointer value in the method code block
                  tables.

               <li>
                  The VM passes the instruction pointer and the stack pointer
                  registers to the JIT compiler.

               <li>
                  The JIT identifies the safe point and finds the GC map associated
                  with the code address.

               <li>
                  The JIT consults the GC map for the safe point, and enumerates
                  the root set for the frame. For that, the JIT calls the
                  function <code>gc_add_root_set_entry()</code> for each stack
                  location, which contains pointers to the Java<a href=
                  "#*">*</a> heap [<a href="#GC_article_ref">12</a>].<br>
                   The interpreter uses its own stack frame format and
                  enumerates all thread stack trace when the interpreter
                  function <code>interpreter_enumerate_thread()</code> is
                  called.

            </ol>

         <li>The
            VM core and the execution engine communicate the roots to the garbage collector
            by calling the function
            <code>gc_add_root_set_entry(ManagedObject)</code>.

			 <p class="note">
               Note
            </p>
            <p class="notetext">
               The parameter points to the root, not to the object the root
               points to. This enables the garbage collector to update the root
               in case it has changed object locations during the collection.
            </p>
        <li>The
            VM core returns from
            <code>vm_enumerate_root_set_all_threads()</code>, so that the
            garbage collector has all the roots and proceeds to collect objects
            no longer in use, possibly moving some of the live objects.

        <li>
            The GC determines the set of reachable objects by tracing the reference
            graph. In the graph, Java<a href="#*">*</a> objects are vertices
            and directed edges are connectors between the objects having
            reference pointers to other objects.

        <li>
            The GC calls the VM function <code>vm_resume_threads_after()</code>.
            The VM core resumes all threads, so that the garbage collector can
            proceed with the allocation request that triggered garbage
            collection.


      </ol>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Finalization"></a>2.7 Finalization
      </h2>
      <p>
         <em>Finalization</em> is the process of reclaiming unused system
         resources after garbage collection. The DRL finalization fully
         complies with the specification [<a href="#JVM_spec_ref">1</a>]. The
         VM core and the garbage collector cooperate inside the virtual machine
         to enable finalizing unreachable objects.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In DRL, the virtual machine tries to follow the reverse finalization
         order, so that the object created last is the first to be finalized;
         however, the VM does not guarantee that finalization follows this or
         any specific order.
      </p>
      <h3>
         2.7.1 Finalization Procedure
      </h3>
      <p>
         As Figure 2 shows, several queues can store references to finalizable
         objects:
      </p>
      <ul>
         <li>
            <em>GC live objects queue</em> for marked objects.

         <li>
            <em>GC buffering queue</em> for unmarked objects. This queue is
            empty most of the time.

         <li>
            <em>VM core queue</em> for objects unreachable from the root and
            scheduled for finalization.

      </ul>
      <p align="center">
         <img src="images/final_queques.gif" alt="Object Queues in VM and GC">
      </p>
      <p class="special">
         Figure 2. Finalization Framework
      </p>
      <p>
         The garbage collector uses these queues at different stages of the GC
         procedure to enumerate the root set and kick off finalization for
         unreachable objects, as follows.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <ol>
         <li>
            <p class="class">
               Object Allocation
            </p>
            <p>
               During <a href="#Object_Allocation">object allocation</a>, the
               garbage collector places references to finalizable objects into
               the live object queue, as shown in Figure 3. Functions
               <code>gc_alloc()</code> and <code>gc_alloc_fast()</code>
               register finalizable objects with the queue.
            </p>
            <p align="center">
               <img src="images/final_alloc_all.gif" alt=
               "Allocation functions and the live objects queue">
            </p>
            <p class="special">
               Figure 3. Allocation of Finalizable Objects
            </p>

         <li>
            <p class="class">
               After Mark Scan
            </p>
            <p>
               After marking all reachable objects, the GC moves the remaining
               object references to the unmarked objects queue. Figure 4
               illustrates this procedure: grey squares stand for marked object
               references, and white square are the unmarked object references.
            </p>
            <p align="center">
               <img src="images/final_unmarked_queue.gif" alt=
               "Marked Objects moved to Queue 1 and unmarked objects to Queue 2">
            </p>
            <p class="special">
               Figure 4. Unmarked Objects Queue Usage
            </p>

         <li>
            <p class="class">
               Filling in the Finalizable Objects Queue
            </p>
            <p>
               From the buffering queue, the GC transfers unmarked object
               references to the VM queue, as shown in Figure 5. To place a
               reference into the queue, the garbage collector calls the
               <code>vm_finalize_object()</code> function for each reference
               until the unmarked objects queue is empty.
            </p>
            <p align="center">
               <img src="images/final_final_queue.gif" alt=
               "Unmarked Objects are moved to Queue 3 of finalizable objects">
            </p>
            <p class="special">
               Figure 5. Finalization Scheduling
            </p>

         <li>
            <p class="class">
               Activating the Finalizer Thread
            </p>
            <p>
               Finally, the GC calls the <code>vm_hint_finalize()</code>
               function that wakes up finalizer threads. All finalizer threads
               are pure Java<a href="#*">*</a> threads, see section <a href=
               "#work_balance">2.7.2 Work Balancing Subsystem</a>.<br>
                Each active thread takes one object to finalize and does the
               following:
            </p>
            <ol>
               <li>
                  Gets references to the object from the VM queue

               <li>
                  Removes the reference from the queue

               <li>
                  Calls the <code>finalize()</code> function for the object

            </ol>
            <p>
               If the number of active threads is greater than the number of
               objects, the threads that have nothing to finalize are
               transferred to the sleep mode, as shown in Figure 6.
            </p>
            <p align="center">
               <img src="images/final_threads.gif" alt=
               "Active finalizer threads address objects in the finalizable objects queue or sleep">
            </p>
            <p class="special">
               Figure 6. Finalizer Threads
            </p>

      </ol>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="work_balance"></a>2.7.2 Work Balancing Subsystem
      </h3>
      <p>
         The work balancing subsystem dynamically adjusts the number of running
         finalizer threads to prevent an overflow of the Java heap by
         finalizable objects. This subsystem operates with two kinds of
         finalizer threads: permanent and temporary. During normal operation
         with a limited number of finalizable objects, permanent threads can
         cover all objects scheduled for finalization. When permanent threads
         are no longer sufficient, the work balancing subsystem activates
         temporary finalizer threads as needed.
      </p>
      <p>
         The work balancing subsystem operates in the following stages:
      </p>
      <dl>
         <dt>
            Stage 1: Permanent finalizer threads only
         </dt>
         <dd>
            Object allocation starts. Only permanent finalizer threads run. The
            garbage collector uses the hint counter variable to track
            finalizable objects, and increases the value of the hint counter by
            1 when allocating a finalizable object.
         </dd>
         <dt>
            Stage 2: Temporary finalizer activated
         </dt>
         <dd>
            The number of objects scheduled for finalization increases, and at
            some point in time, the hint counter value exceeds a certain
            threshold (currently set to 128). <br>
           At this stage, the garbage collector calls the
          <code>vm_hint_finalize()</code> function before performing the
            requested allocation. This function is also called after each
            garbage collection. The <code>vm_hint_finalize()</code> function
            checks whether any objects remain in the queue of objects to
            finalize. If the queue is not empty, this means that the current
            quantity of finalizer threads is not enough. In this case, the work
            balancing subsystem creates additional temporary finalizer threads.
            The number of created temporary threads corresponds to the number of
            CPUs.<br>
             The operation of checking the finalizable objects queue state is performed periodically.
			 The number of running temporary threads can be greater than
            suffices, because the optimum number of finalizer threads is
            unknown.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               The work balancing subsystem checks whether the finalization
               queue is empty, but does not take into account the number of
               objects in the queue.
            </p>
		</dd>
         <dt>&nbsp;

        </dt>
         <dt>
            Stage 3: Temporary finalizer threads destroyed
         </dt>
         <dd>
            At a certain point, excess finalizer threads can appear, so that
            the number of objects to finalize starts decreasing. When the
            number of threads becomes two times greater than the optimal number, the
            finalizable objects queue should be empty, see explanation
            below.<br>
             When the finalization queue is empty, temporary threads are
            destroyed and the work balancing cycle restarts.
         </dd>
      </dl>
      <p class="class">
         WBS Internals
      </p>
      <p>
         Assuming that N is an indefinite optimum number of finalizer threads,
         you can make the following conclusions:
      </p>
      <ul>
         <li>
            Number N-1 finalizer threads is not enough, and all the Java<a
            href="#*">*</a> heap gets filled with finalizable objects.

         <li>
            Number N+1 threads is an excess quantity that will cause certain
            threads to wait.

         <li>
            N threads is the optimum solution, however, this cannot be achieved
            if N is unknown.

      </ul>
      <p>
         If N is less or equal to the number of permanent finalizer threads, no temporary threads are created.
		 Otherwise, the number of finalizer threads undergoes the
         following changes during WBS activity, in the chronological order:
      </p>
      <ol>
         <li type="a">
         When the hint counter exceeds the pre-set threshold, and the finalization queue is not empty,
		 the work balance subsystem activates temporary threads as needed.


         <li type="a">
            When the number of temporary threads exceeds N, the number the
            objects starts decreasing; however, the number of finalizer threads
            continues to grow. By the time the number of finalizer threads
            reaches 2N, no objects remain in the queue, because at this time an
            optimum finalization system could finalize the same quantity of
            objects as current.

         <li type="a">
            When the queue is empty, temporary threads are destroyed, as
            described in stage 3.

      </ol>
      <p>
         Figure 7 below demonstrates variations in the number of finalizer
         threads over time.
      </p>
      <p align="center">
         <img src="images/final_graph.gif" alt=
         "Number of objects to finalize and of running threads changing dynamically">
      </p>
      <p class="special">
         Figure 7. Variations in Number of Running Finalizer Threads
      </p>
      <p>
         As a result, the number of running finalizer threads in the current
         work balancing subsystem can vary between 0 and 2N.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The maximum value for 2N is 256 running finalization threads.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="VM_Core"></a>3. VM Core
      </h1>
      <h2>
         <a name="VMCore_architecture"></a>3.1 Architecture
      </h2>
      <p>
         The core virtual machine is the central part of the overall VM design.
         The VM core consists of common VM blocks defined by the JVM
         specification [<a href="#JVM_spec_ref">1</a>] and of elements specific
         for the DRLVM implementation, as follows:
      </p>
      <ul>
         <li>
            <a href="#Class_support">Class support</a> encapsulates class
            loading and resolution, as well as the functional interface to VM
            internal class representation. This component provides interfaces
            for class loading and accessing class structures.

         <li>
            <a href="#Kernel_Classes">Kernel classes</a> component includes a
            subset of the Java<a href="#*">*</a> class library closely tied
            with the virtual machine, which mostly includes classes of the
            <code>java.lang</code> package.

         <li>
            <a href="#Kernel_Class_Natives">Kernel class native</a> methods
            link the Java<a href="#*">*</a> kernel classes with other DRLVM
            components, and are exported as ordinary native methods from the VM
            executable according to the Java<a href="#*">*</a> Native Interface
            (JNI) specification [<a href="#JNI_ref">5</a>].

         <li>
            <a href="#JNI_support">JNI support</a> component supports execution
            of native methods for Java<a href="#*">*</a> classes, and for the
            native interface API [<a href="#JNI_ref">5</a>].

         <li>
            <a href="#JVMTI_Support">JVMTI support</a> enables loading of the
            debugging agent, and provides functionality for running simple
            debug scenarios, see the JVM Tool Interface Specification [<a href=
            "#JVMTI_ref">4</a>].

         <li>
            <a href="#Stack_Support">Stack support</a> allows stack examination
            for creating stack traces and performing enumeration of live
            references.

         <li>
            <a href="#Exception_Handling">Exception handling</a> is activated
            when an exception is thrown; this component is responsible calling
            the appropriate exception handler and, together with the stack
            support, for the stack walking process.

         <li>
            <a href="#VM_Services">VM services</a> include run-time,
            compilation time, and compiled code utilities provided by the VM
            core for the JIT compiler, and utilities for the garbage collector
            and for class library natives.

         <li>
            <a href="#Verifier">Verifier</a> checks the classes to meet safety
            requirements before class loading.

         <li>
            <a href="#Thread_Management">Thread management</a> functionality
            provides threading inside the virtual machine.

         <li>
            <a href="#Utilities">Utilities</a> are used by the VM core during
            normal operation.

      </ul>
      <p>
         The structure of the virtual machine enables building stable
         interfaces for inter-block communication as well as public VM
         interfaces. These interfaces inherit platform independence from the VM
         specification [<a href="#JVM_spec_ref">1</a>]. Figure 8 shows the VM
         core overall structure and the internal logic of components
         interaction. For more details on available interfaces, see <a href=
         "#VM_exported_interfaces">3.13 Interfaces</a>.
      </p>
      <table align="center">
         <tr>
            <td>
               <img border="0" alt="VM Core Components and Interfaces" src=
               "images/VM_core.gif">
            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  <a name="Figure:VM_Core_Components"></a>Figure 8. VM Core
                  Components
               </p>
               <p class="notetext">
                  Red font indicates external interfaces.
               </p>
            </td>
         </tr>
      </table>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Class_support"></a>3.2 Class Support
      </h2>
      <p>
         The class support component processes classes in accordance with the
         JVM specification [<a href="#JVM_spec_ref">1</a>], which includes
         class loading, class preparation, resolution, and initialization
         operations. This component also contains several groups of functions
         that other VM components use to get information on loaded classes and
         other class-related data structures. For example, JVMTI functions
         <code>RedefineClasses()</code> and <code>GetLoadedClasses()</code> use
         utility interfaces provided by class support.
      </p>
      <p>
         The class support component has the following major goals:
      </p>
      <ul>
         <li>
            Load binary class data from <code>.class</code> files and
            <code>.jar</code> archives from the bootstrap class loader

         <li>
            Create internal (VM) representations of classes from byte arrays

         <li>
            Provide access to information on classes, methods, and fields for
            various VM modules

         <li>
            Provide instruments for class redefinition and class support
            related events required for JVMTI

         <li>
            Communicate with the verifier on verification of methods bytecode

      </ul>
      <h3>
         3.2.1 Classification of Class Support Interfaces
      </h3>
      <p>
         Class support functions can be divided into the following groups:
      </p>
      <dl>
         <dt>
            Class Loading
         </dt>
         <dd>
            Comprises functions for loading classes, searching for loaded
            classes inside VM structures, and JVMTI class redefinition. The
            functions obtain bytes from the Java<a href="#*">*</a> class
            libraries via the descendants of the
            <code>java.lang.ClassLoader</code> class or from the files and
            directories listed in the <code>vm.boot.class.path</code> property.
            These functions also bind loaded classes with the defining class
            loader and provide information on all loaded classes.
         </dd>
      </dl>
      <dl>
         <dt>
            Class Manipulation
         </dt>
         <dd>
            Provides access to class properties, such as the internal (VM) and
            the external (Java<a href="#*">*</a>) names, access and properties
            flags, the super-class and the defining class, as well as super
            interfaces, inner classes, methods, fields, and attributes.<br>
             Supports <i>class resolution</i> by resolving symbolic references
            in the run-time constant pool of the class.
         </dd>
      </dl>
      <dl>
         <dt>
            Method Manipulation
         </dt>
         <dd>
            Provides access to the properties of methods of a class, such as
            the name of method, descriptor, signature, access and properties
            flags, bytecode, local variables information, stack, exceptions,
            handlers, attributes, and the declaring class.<br>
             Functions of this group also enable adding new versions of
            JIT-compiled methods code and storing service information about
            compiled code.
         </dd>
      </dl>
      <dl>
         <dt>
            Field Access
         </dt>
         <dd>
            Contains functions that provide access to the properties of class
            fields, that is, to the name, descriptor, containing class, and the
            class of the field.
         </dd>
      </dl>
      <dl>
         <dt>
            Type Access
         </dt>
         <dd>
            Provides access to generalized information on classes for the JIT
            compiler and other DRLVM components. These can easily be adapted to
            work with non-Java<a href="#*">*</a> virtual machines, for example,
            with the ECMA Common Language Infrastructure. Type access functions
            provide descriptions of both Java<a href="#*">*</a> types, such as
            managed pointers, arrays, and primitive types, and non-Java<a href=
            "#*">*</a> types, such as non-managed pointers, method pointers,
            vectors, unboxed data, and certain unsigned primitive types.
         </dd>
      </dl>
      <h3>
         3.2.2 Internal Class Support Data Structures
      </h3>
      <p>
         The VM core stores information about every class, field, and method
         loaded as described below.
      </p>
      <ul>
         <li>
            <i>Class data structure</i> includes attributes of the class
            (public, final, and abstract attributes, the element type for an
            array class, and others), information about inner classes,
            references to static initializers, and references to finalizers.
            The structure also references the virtual-method table (VTable) of
            the class shared by all instances of that class.

         <li>
            <i>Field data structure</i> includes reflection information, such
            as name, type, and reference to the declaring class, as well as
            internal DRLVM information, such as the fields offset from the base
            of the object for instance fields and the fields address in memory
            for static fields.

         <li>
            <i>Method data structure</i> contains the information on methods
            similar to the field data structure content.

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Native_Code_Support"></a>3.3 Native Code Support
      </h2>
      <p>
         The native code support component consists of two parts, execution of
         native methods used by Java<a href="#*">*</a> classes, and an
         implementation of the Java<a href="#*">*</a> Native Interface (JNI)
         API for native code. Execution of native methods is required by the
         Java<a href="#*">*</a> Language Specification [<a href=
         "#Java_lang_spec_ref">2</a>] and JNI is required by JNI Specification
         [<a href="#JNI_ref">5</a>].
      </p>
      <h3>
         <a name="Execution_of_Native_Methods"></a>3.3.1 Execution of Native
         Methods
      </h3>
      <p>
         The virtual machine calls native methods differently with the JIT and
         with the interpreter as described below.
      </p>
      <ul>
         <li>
            <i>When the JIT is used</i>, the virtual machine generates special
            wrappers for calling native methods, which perform synchronization
            for synchronized native methods and record information for <a href=
            "#Stack_unwinding">stack unwinding</a> and enumeration of
            references used in native code. The wrapper code is generated for a
            native method when the method is called for the first time, and
            further on, the wrapper is called from JIT-compiled code directly.

      </ul>
      <p class="class">
         JNI optimizations
      </p>
      <p class="notetext">
         The VM core generates specialized JNI wrappers to support the
         transition from managed to native code. The straight-forward
         implementation of these wrappers calls a function to allocate storage
         and initialize JNI handles for each reference argument. However, most
         JNI methods have only a small number of reference parameters. To take
         advantage of this, an in-line sequence of instructions is used to
         allocate and initialize the JNI handles directly. This improves the
         performance of applications that contain multiple JNI calls.
      </p>
      <ul>
         <li>
            <i>In the interpreter mode</i>, native code is called directly with
            static stubs, and the interpreter performs all the operations done
            by wrappers in the JIT execution mode.

      </ul>
      <h3>
         <a name="JNI_support"></a>3.3.2 JNI Support
      </h3>
      <p>
         The Java<a href="#*">*</a> Native Interface is a set of functions,
         which enable native code to access Java<a href="#*">*</a> classes,
         objects, methods, and all the functionality available for a regular
         method of a Java<a href="#*">*</a> class.
      </p>
      <p>
         The JNI implementation mostly consists of wrappers to different
         components of the virtual machine. For example, class operations are
         wrappers for the class support component, method calls are wrappers
         that invoke the JIT or the interpreter, and object fields and arrays
         are accessed directly by using the known object layout.
      </p>
      <dl>
         <dt>
            Example
         </dt>
      </dl>
      <p class="notetext">
         The following code is implementation of the
         <code>IsAssignableFrom</code> JNI function, which uses the class
         support interface:
      </p>
<pre>
#include &ldquo;vm_utils.h&rdquo;
#include &ldquo;jni_utils.h&rdquo;

jboolean JNICALL IsAssignableFrom(JNIEnv * UNREF env,
   jclass clazz1,
   jclass clazz2)
{
  TRACE2(&quot;jni&quot;, &quot;IsAssignableFrom called&quot;);
  assert(tmn_is_suspend_enabled());
  Class* clss1 = jclass_to_struct_Class(clazz1);
  Class* clss2 = jclass_to_struct_Class(clazz2);

  Boolean isAssignable = class_is_subtype(clss1, clss2);
  if (isAssignable) {
 return JNI_TRUE;
  } else {
 return JNI_FALSE;
  }
} //IsAssignableFrom
</pre>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Stack_Support"></a>3.4 Stack Support
      </h2>
      <h3>
         3.4.1 About the Stack
      </h3>
      <p>
         The stack is a set of frames created to store local method
         information. The stack is also used to transfer parameters to the
         called method and to get back a value from this method. Each frame in
         the stack stores information about one method. Each stack corresponds
         to one thread.
      </p>
      <p class="note">
         <a name="Note1_in_Stack_overview"></a>Note
      </p>
      <p class="notetext">
         The JIT compiler can combine in-lined methods into one for performance
         optimization. In this case, all combined methods information is stored
         in one stack frame.
      </p>
      <p>
         The VM uses native frames related to native C/C++ code and managed
         frames for Java<a href="#*">*</a> methods compiled by the JIT.
         Interaction between native methods is platform-specific. To transfer
         data and control between managed and native frames, the VM uses
         special managed-to-native frames, or <em>M2nFrames</em>.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In the interpreter mode, the VM creates several native frames instead
         of one managed frame for a Java<a href="#*">*</a> method. These native
         frames store data for interpreter functions, which interpret the
         Java<a href="#*">*</a> method code step by step.
      </p>
      <p class="class">
         <a name="M2nFrame"></a>M2nFrames
      </p>
      <p>
         M2nFrames contain the following:
      </p>
      <ul>
         <li>
            Snapshot of CPU registers, which enables iteration over method
            frames and exception propagation. The VM uses the stack pointer and
            the instruction pointer to identify the method and to find the
            boundaries of the method stack frame. The VM uses values of
            callee-saves registers to correctly restore the register context.
            The VM performs this operation when transferring control to
            exception handlers that are defined in the methods located lower on
            the execution stack.

         <li>
            Pointer to the previous M2nFrame. All M2nFrames are linked into a
            list, with the head pointer kept in thread-local structure
            <code>VM_thread</code>. The list is terminated with a dummy frame
            with zero contents.

         <li>
            Container of object handles that are indirect pointers to the
            Java<a href="#*">*</a> heap. Native code must use object handles to
            enable root set enumeration. During this process, the VM traverses
            the list of M2nFrames for each thread and enumerates object handles
            from each frame.

      </ul>
      <h3>
         <a name="Stack_Walking"></a>3.4.2 Stack Walking
      </h3>
      <p>
         Stack walking is the process of going from one frame on the stack to
         another. Typically, this process is activated during exception
         throwing and root set enumeration. In DRLVM, stack walking follows
         different procedures depending on the type of the frame triggering
         iteration, as described below.
      </p>
      <p>
         The system identifies whether the thread is in a managed or in a
         native frame and follows one of the scenarios described below.
      </p>
      <ul>
         <li>
            <i>For managed frames</i>, the VM core calls the <a href=
            "#Stack_unwinding">JIT</a> to get the previous frame. Using this
            call for the found managed frame, the VM core can find all previous
            managed frames one by one. In the end, the compiler returns the
            pointer to the parent native frame, as shown in Figure 9.

         <li>
            <i>For native frames</i>, the VM core finds the last M2nFrame, that
            is, the frame at the end of the M2nFrame list for the current
            thread. Each thread has a pointer to the last M2nFrame in the
            thread-local storage (TLS in figure). This frame contains
            information on how to find the managed frame immediately before the
            M2nFrame and all previous M2nFrames, as shown in Figure 10.

      </ul>
      <p>
         Figure 11 below gives an example of a stack structure with M2nFrames
         and managed frames movement indicated.
      </p>
      <table border="0" align="center">
         <tr>
            <td>
               <img border="0" alt="Stack Walking from a Managed Frame" src=
               "images/Stack_managed.gif">
            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  Figure 9. Stack Walking from a Managed Frame
               </p>
            </td>
         </tr>
         <tr>
            <td>
               <img border="0" alt="Stack Walking from a Native Frame" src=
               "images/Stack_native.gif">
            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  Figure 10. Stack Walking from a Native Frame
               </p>
            </td>
         </tr>
      </table>
      <table align="center">
         <tr>
            <td>
               <img border="0" alt="Stack Illustration" src="images/Stack.gif">

            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  Figure 11. LMF List after the Call to a Native Method
               </p>
            </td>
         </tr>
      </table>
      <p>
         The main component responsible for stack walking is the stack
         iterator.
      </p>
      <h3>
         <a name="Stack_Iterator"></a>3.4.3 Stack Iterator
      </h3>
      <p>
         The stack iterator enables moving through a list of native and Java<a
         href="#*">*</a> code frames. The stack iterator performs the following
         functions:
      </p>
      <ul>
         <li>
            Transferring control to another frame of the current thread, that
            is, changing the thread context to continue execution in the
            exception handler

         <li>
            Root set enumeration for the stack of the current thread

         <li>
            Stack walking, to construct the stack trace, to perform a security
            check or to find the exception handler

      </ul>
      <h3>
         <a name="Stack_trace"></a>3.4.4 Stack Trace
      </h3>
      <p>
         The stack trace converts stack information obtained from the iterator
         and transfers this data to the
         <code>org.apache.harmony.vm.VMStack</code> class.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         One frame indicated by the iterator may correspond to more than one
         line in the stack trace because of method in-lining (see the <a href=
         "#Note1_in_Stack_overview">first note</a> in <i>About the Stack</i>).
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Thread_Management"></a>3.5 Thread Management
      </h2>
      <p>
         The thread management component provides threading functionality
         inside the virtual machine and the class libraries. The purpose of
         thread management is to hide platform specifics from the rest of the
         VM, and to adapt the OS threading functions to the Java<a href=
         "#*">*</a> run-time environment. For example, thread management
         enables root set enumeration by making threads accessible for the
         garbage collector.
      </p>
      <h3>
         3.5.1 Interaction with Other Components
      </h3>
      <p>
         Thread management is used by the following components:
      </p>
      <ul>
         <li>
            Kernel classes ( <code>java.lang.Object, java.lang.Thread,
            java.util.concurrent.locks.LockSupport</code> )

         <li>
            JVMTI

         <li>
            Garbage Collector

         <li>
            Java<a href="#*">*</a> Native Interface API [<a href=
            "#JNI_ref">5</a>]

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The thread management code is currently written by using the
         restricted set of the Win32 threading API. On Linux<a href="#*">*</a>,
         each Win32 thread management function is replaced with the appropriate
         adaptor implemented using the POSIX threading API. This provides
         portability of the thread management code across Windows<a href=
         "#*">*</a> and Linux<a href="#*">*</a> platforms.
      </p>
      <h3>
         3.5.2 Structure
      </h3>
      <p>
         The central part of thread management is the <code>VM_thread</code>
         control structure, which holds all the data necessary to describe a
         Java<a href="#*">*</a> thread within the virtual machine. Instances of
         the <code>VM_thread</code> control structure are referred to as
         <i>thread blocks</i> in the code. All thread blocks, that is, all
         active Java<a href="#*">*</a> threads running inside the VM, are
         represented in a linked list. The list is traversed by means of
         iterators that the <code>thread_manager.cpp</code> module provides.
         Currently, the number of threads simultaneously running in the system
         is limited to 800 threads. Each Java<a href="#*">*</a> thread in the
         system gets a unique index called <code>thread_index</code>
	  within the range of 0 to 2048 at creation time. The maximum number of 2048 has been selected to ensure that it does not set any restrictions on underlying system capabilities. </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         Your system might exceed the approximate maximum number of 800 threads. </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         3.5.3 Thread Creation and Completion
      </h3>
      <p>
         At this time, no single API in thread management is responsible
         for the thread creation. However, the code that creates a thread does
         the following:
      </p>
      <ol>
         <li>
            Allocates a <code>VM_thread</code> structure with help of the
            <code>get_a_thread_block()</code> function.

         <li>
            Creates a new thread by using the appropriate system call.

         <li>
            In a newly started thread, puts a reference to the
            <code>VM_thread</code> structure into the thread local storage.

      </ol>
      <p>
         The newly created thread is responsible for correct completion. The
         completion code is added to the thread procedure. The thread completion code does the
         following:
      </p>
      <ol>
         <li>
            If an exception has remained uncaught in the thread, calls
            exception handler.

         <li>
            Invokes the <code>notify_all()</code> function on the
            <code>java.lang.Thread</code> object associated with the thread.
            This call activates any threads that have invoked the
            <code>join()</code> function for this thread.

         <li>
            De-allocates the <code>VM_thread</code> structure by using the
            <code>free_this_thread_block()</code> function.

      </ol>
      <h3>
         <a name="Safe_suspension"></a>3.5.4 Safe Suspension
      </h3>
      <p>
         One of the key features of thread management in DRLVM is the safe
         suspension functionality. <em>Safe suspension</em> means that the
         thread is physically stopped only at certain safe points or at the end
         of <a href="#safe_region">safe regions</a>. This ensures that the
         suspended thread holds no locks associated with operating system
         resources, such as the native memory heap. Safe suspension helps to
         avoid possible deadlocks in the DRL virtual machine, as described below. </p>
      <ul>
         <li>
            Suspended thread enables the JIT to enumerate live Java<a href=
            "#*">*</a> reference pointers on the stack and in the registers
            precisely. The garbage collector depends on the accurate
            enumeration of live Java<a href="#*">*</a> references for re-using
            unreachable objects memory and for moving reachable objects to decrease memory fragmentation.

         <li>
            Suspended thread holds no system-critical locks that can be
            requested by the other parts of the VM, such as locks associated
            with the native heap memory.

      </ul>
      <p>
         At any moment of time, any thread is in one of the following states:
      </p>
      <ul>
         <li>
            <i><a name="safe_region"></a>Safe region.</i> A period of time
            during thread execution when the thread can be safely suspended.
            Typically, in a safe region, a thread executes  native C code that specifically
            does not access Java<a href="#*">*</a> objects. With safe regions,
            the garbage collector can move objects and avoid the risk of native
            code using stale pointers to read or write Java<a href="#*">*</a>
            object contents.

         <li>
            <i>Unsafe region</i>. A period of time during thread execution when
            the code is changing Java<a href="#*">*</a> objects or impacts the
            Java<a href="#*">*</a> stack, for example, parts of the Java<a
            href="#*">*</a> code compiled by the JIT or JNI function calls.
            Suspending a thread in that region is usually unsafe.

         <li>
            <i>Safe point.</i> A single point during the thread execution time
            when the thread can be safely suspended. For example, the JIT can
            insert safe points in the Java<a href="#*">*</a> code between the
            selected chunks of the assembly code at intervals determined by the
            performance balance between the safe point function call overhead
            and suspension time overhead.

      </ul>
      <p>
         The suspension algorithm typically involves two threads, the
         <i>suspender</i> thread and the <i>suspendee</i> thread.
      </p>
      <p class="class">
         Functions Used
      </p>
      <p>
         A safe region of code in a suspendee thread is marked by functions
         <code>tmn_suspend_enable()</code> and
         <code>tmn_suspend_disable()</code>. Additionally, the code is marked by the
         <code>thread_safe_point()</code> function to denote the point, where
         safe suspension is possible. A suspender thread can invoke
         <code>thread_suspend_generic()</code> or
         <code>thread_resume_generic()</code> functions supplying the suspendee
         thread block as an argument. The <code>thread_suspend_generic()</code>
         function handles safe suspension when called on a thread as shown
         below, and the <code>thread_resume_generic()</code> function instructs
         the suspendee thread to wake up and continue execution.
      </p>
      <p class="class">
         Suspension Algorithm
      </p>
      <p>
         This section describes the algorithm of safe suspension, as follows:
      </p>
      <ol>
         <li>
            The suspender thread calls the
            <code>thread_suspend_generic()</code> function, which sets a flag
            for the suspendee thread indicating a request for suspension.

         <li>
            Depending on the state of the suspendee thread, one of the
            following mechanisms is activated:
            <ol type="a">
               <li>
                  If the suspendee thread is currently running in a safe code
                  region, the <code>thread_suspend_generic()</code> function
                  immediately returns. The suspendee thread runs until it
                  reaches the end of the safe region. After that, the thread is
                  blocked until another thread calls the
                  <code>thread_resume_generic()</code> function for it.

               <li>
                  If the suspendee thread is currently in an unsafe region, the
                  <code>thread_suspend_generic()</code> function is blocked
                  until the suspendee thread reaches the beginning of a safe
                  region or  a safe point. The thread state then changes, and the mechanism described in
                  point a) above starts.

            </ol>

         <li>
            The suspendee thread undergoes the following:
            <ol type="a">
               <li>
                  A thread, while executing Java<a href="#*">*</a> code,
                  periodically calls the <code>thread_safe_point()</code>
                  function. In case of a suspension request set for this
                  thread, this function notifies the requesting thread and
                  waits until another thread calls the
                  <code>thread_resume_generic()</code> function for this
                  thread. In other words, the thread suspends itself at a safe
                  point upon request.

               <li>
                  Once it enters a safe region, the thread calls the
                  <code>tmn_suspend_enable()</code> function. This function
                  sets the <code>suspend_enabled</code> state flag to true. In
                  case a suspension request is set for this thread, the
                  function notifies the requesting thread that a safe region is
                  reached.

               <li>
                  When the thread leaves a safe region, it calls the
                  <code>tmn_suspend_disable()</code> function. This function
                  sets the <code>suspend_enabled</code> state flag to false and
                  invokes the <code>thread_safe_point()</code> function.

            </ol>

      </ol>
      <h3>
         <a name="Monitors"></a>3.5.5 Monitors
      </h3>
      <p>
         Monitors are a central part of Java<a href="#*">*</a> threads
         synchronization. Any Java<a href="#*">*</a> object can serve as a
         monitor. In DRLVM, monitor-related information is kept in the head of
         the Java<a href="#*">*</a> object structure. An object header is
         32-bit long and has the following structure:
      </p>
      <table align="center">
         <tr>
            <td>
               <img src="images/monitor_structure.gif" alt=
               "Monitor structure bits distribution">
            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  Figure 12. Monitor Structure
               </p>
            </td>
         </tr>
      </table>
      <p>
         Where:
      </p>
      <ul>
         <li>
            <code>stack_key</code> stores the index of the Java<a href=
            "#*">*</a> thread that acquired the monitor or equals to
            <code>FREE_MONITOR</code> if no index is provided.

         <li>
            <code>recursion_count</code> counts the number of times that the
            thread acquires a monitor.

         <li>
            <code>7 bit hash</code> is the hash code for the object.

         <li>
            <code>contention bit</code> equals to one if multiple threads are
            contending for acquiring the monitor.

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In the current implementation, the contention bit is always set to 1.
      </p>
      <p class="class">
         Acquiring Monitors
      </p>
      <p>
         The <code>monitor_enter()</code> and <code>monitor_exit()</code>
         functions manage monitors in accordance with the JNI specification [<a
         href="#JNI_ref">5</a>].
      </p>
      <p>
         The <code>monitor_enter()</code> operation for a specific object is
         shown below.
      </p>
      <p>
         First, <code>stack_key</code> in the header of the object is examined.
         The header can be in one of the three states, which determine further
         actions, as follows.
      </p>
      <table border="0">
         <tr>
            <td class="TableHeading">
               State of <code>stack_key</code>
            </td>
            <td class="TableHeading">
               Actions
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Free: <code>stack_key</code> contains <code>FREE_MONITOR</code>
            </td>
            <td class="TableCell">
               The current thread index is stored in <code>stack_key</code>.
               Read and update operations for <code>stack_key</code> are
               performed atomically to prevent possible race conditions.
            </td>
         </tr>
         <tr>
            <td height="25" align="center" class="TableCell">
               Occupied by the current thread
            </td>
            <td class="TableCell">
               The recursion count increases.
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Occupied by another thread
            </td>
            <td class="TableCell">
               The current thread does the following in a loop, until the
               monitor is successfully acquired:
               <ol>
                  <li>
                     Puts the object into a <code>mon_enter_array</code> array,
                     which holds a queue of contending threads waiting for the
                     monitor to be released

                  <li>
                     Waits (schedules off the CPU) until the thread holding the
                     monitor sends the <code>event_handle_monitor</code>
                     notification informing that the monitor has been released

                  <li>
                     Attempts to acquire the monitor again

               </ol>
            </td>
         </tr>
      </table>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The waiting thread is excluded from the system scheduling and does not
         get the CPU resources for its execution.
      </p>
      <p>
         During the <code>monitor_exit()</code> operation, the current thread
         does the following based on the <code>recursion_count</code> value:
      </p>
      <ul>
         <li>
            Recursion is more than zero: The thread decreases the recursion
            counter and returns.

         <li>
            Recursion is zero: the current thread acquired this monitor only
            once
            <ul>
               <li>
                  <code>FREE_MONITOR</code> written into <code>stack_key</code>
                  indicating that monitor is no longer occupied

               <li>
                  Contention bit checked

               <li>
                  If the contention is not zero, the first waiting thread in
                  the <code>mon_enter_array</code> queue is notified by means
                  of <code>event_handle_monitor</code> and enables it to
                  acquire the monitor, see the <code>monitor_enter()</code>
                  operation description.

            </ul>

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Kernel_Classes"></a>3.6 Kernel Classes
      </h2>
      <p>
         The VM kernel classes link the virtual machine with the Java<a href=
         "#*">*</a> class libraries (JCL), and consist of the Java<a href=
         "#*">*</a> part and the native part. This section describes the Java<a
         href="#*">*</a> part of the kernel classes, whereas the native part is
         described in section <a href="#Kernel_Class_Natives">3.7 Kernel Class
         Natives</a>.
      </p>
      <p>
         Kernel classes are Java<a href="#*">*</a> API classes, members of
         which use or are used by the virtual machine. Because these classes
         have data on the VM internals, the kernel classes are delivered with
         the VM. Examples of kernel classes include
         <code>java.lang.Object</code> and
      <code>java.lang.reflect.Field</code>. </p>
      <p>The current implementation is
        based on the Harmony Class Library Porting Documentation [<a href="#SVN_IBMdoc_ref">20</a>].
		The DRL kernel classes have amendments to the porting documentation, as indicated in section <a
         href="#KC_specifics">3.6.2 Implementation Specifics</a> below. </p>
      <h3>
         3.6.1 Kernel Classes and VM
      </h3>
      <p>
         In DRLVM, the kernel classes communicate with the virtual machine
         through a Java<a href="#*">*</a> interface defining a strict set of
         static native methods implemented in the VM. The interface mainly
         consists of four package private classes:
         <code>java.lang.VMClassRegistry</code>,
         <code>java.lang.VMExecutionEngine</code>,
         <code>java.lang.VMMemoryManager</code>, and
         <code>java.lang.VMThreadManager</code>, and two public classes
         <code>java.lang.Compiler</code> and
         <code>org.apache.harmony.vm.VMStack</code>.
      </p>
      <h3>
         <a name="KC_specifics"></a>3.6.2 Implementation Specifics
      </h3>
      <p>
         This section describes the specifics of the kernel classes
         implementation in DRL.
      </p>
      <ol>
         <li>
            The set of kernel classes is extended with the
            <code>java.lang.System</code> class due to its close connection with the VM and the other kernel classes.
         <li>
		 	The DRL implementation provides <code>java.lang.String</code> and
			<code>java.lang.StringBuffer</code> classes due to package private dependencies
		 between them.
         <li>
		 	The class <code>java.util.concurent.locks.LockSupport</code>
			has been added to the kernel classes set to support J2SE 1.5.0.

		 <li>
            The DRL implementation of the
            <code>java.lang.Class.getStackClasses()</code> method does not
            completely correspond to the Harmony Porting Documentation. This method
            adds two frames to the bottom of the resulting array when
            <code>stopAtPrivileged</code> is specified, so that the caller of
            the privileged frame is the last included frame.

         <li>
            DRLVM does not support the shutdown procedure as described in the
            specification. Namely, the
            <code>com.ibm.oti.vm.VM.shutdown()</code> method is not called upon
            VM shutdown.

      </ol>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Kernel_Class_Natives"></a> 3.7 Kernel Class Natives
      </h2>
      <p>
         The kernel class natives component is the part of the <a href=
         "#Kernel_Classes">3.6 Kernel Classes</a> serving as a bridge between
         the Java<a href="#*">*</a> part of the kernel classes and other VM
         components, namely, the garbage collector, class support, stack
         support, exception handling, and object layout support. The kernel
         class natives component also makes use of the thread management
         functionality. The interaction between the kernel classes and VM
         components is based on specific internal interfaces of the virtual
         machine.
      </p>
      <p class="note">
         Note
      </p>
   <p class="notetext">
         The current implementation of kernel class natives is based on JNI and
         uses JNI functions. As a result, kernel class natives functions are
         exported as ordinary native methods from the VM executable as
         specified by the JNI specification [<a href="#JNI_ref">5</a>]. For
         example, when the <code>VMThreadManager</code> Java<a href="#*">*</a>
         class from the kernel classes component defines the method
         <code>native static Thread currentThread()</code>, the kernel class
         natives component implements the function
         <code>Java_java_lang_VMThreadManager_currentThread()</code>.
   </p>
      <h3>
         3.7.1 Structure
      </h3>
      <p>
         Currently, the kernel class natives component consists of the
         following:
      </p>
      <ul>
         <li>
            <i>Simple wrappers</i> for interfaces of different VM components
            constitute the main part of kernel class natives, as shown in the
            example below.
            <dl>
               <dt>
                  Example
               </dt>
            </dl>
<pre>
 jobject
Java_java_lang_VMThreadManager_currentThread(JNIEnv *jenv, jclass)
{
 return thread_current_thread();
}
</pre>

         <li>
            <i>Complex wrappers</i> for data conversion between Java<a href=
            "#*">*</a> objects and VM internal data structures, as well as for
            error checking and processing. These wrappers also provide the
            functionality not directly available in VM components interfaces.
            <dl>
               <dt>
                  Example
               </dt>
            </dl>
            <p class="notetext">
               For method <code>VMClassRegistry.findLoadedClass(String name,
               ClassLoader loader)</code>, the wrapper checks the loader
               parameter and determines further activities. If this parameter
               has a non-null value, the corresponding class loader is used for
               class lookup. If it is null, the Java<a href="#*">*</a>
               execution stack is examined in order to obtain context class
               loader if any, otherwise the system class loader is used.
            </p>

         <li>
            <i>Specific functions:</i>
            <ul>
               <li>
                  <i>Lazy stack inspection for exception objects</i>.<br>
                   This mechanism is used for all descendants of class
                  <code>java.lang.Throwable</code>. When a Java<a href=
                  "#*">*</a> exception object is created, this mechanism
                  prepares and stores the snapshot of the stack trace; this is
                  a fast operation.<br>
                   The more computation intensive operations, such as snapshot
                  parsing and creating a stack trace element array (the
                  <code>java.lang.StackTraceElement</code> array) are only
                  performed when the exception data is actually required, for
                  example when the <code>printStackTrace()</code> method of the
                  <code>Throwable</code> class is called.

               <li>
                  <i>Reflection support</i>.<br>
                   This mechanism is an implementation of standard Java<a href=
                  "#*">*</a> reflection API represented by classes in the
                  <code>java.lang.reflection</code> package [<a href=
                  "#Java_api_ref">6</a>].<br>
                   This mechanism is responsible for providing access to
                  methods and fields of a class by using their symbolic names,
                  as well as for data conversions between the
                  <code>java.lang.Object</code> type and the VM internal type
                  representation required for operations with fields and
                  methods. This mechanism also communicates with the JIT or the
                  interpreter to perform the actual execution of methods.

               <li>
                  <i>Hidden synthetic fields processing</i>.<br>
                   These fields are used for linking Java<a href="#*">*</a>
                  objects of certain kernel classes, such as
                  <code>java.lang.Thread</code> and
                  <code>java.lang.reflect.Field</code>, with the corresponding
                  VM internal data structures. When the classes are loaded, the
                  VM class support component adds the fields to the classes,
                  and the kernel class natives component uses the fields to
                  store the links to the corresponding VM internal data. Note
                  that these fields are not accessible from Java<a href=
                  "#*">*</a> code.

               <li>
                  <i>Debug printing.</i><br>
                   This mechanism can be used for development process only and
                  is not required for the release version of DRL. In this
                  mechanism, the native method <code>print</code> of the class
                  <code>VMDebug</code> allows printing messages to the standard
                  output before printing can be done through the
                  <code>java.lang.System.out/err</code> channel.

            </ul>

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="VM_Services"></a>3.8 VM Services
      </h2>
      <p>
         The VM services component provides the JIT compiler with functionality
         requiring close cooperation with the virtual machine. Below is the
         list of the VM services currently provided for the JIT.
      </p>
      <h3>
         <a name="Compile_time_services"></a>3.8.1 Compile-time Services
      </h3>
      <p>
         During compilation time, the JIT compiler uses the following services:
      </p>
      <ul>
         <li>
            The <code>dump</code> services for dumping generated stubs and
            methods to the file in a human readable form.

         <li>
            Services providing access to the hash table of all loaded methods.

         <li>
            Catch handler registration used by the JIT to provide information
            for the VM exception handling mechanism.

         <li>
            Services providing access to method code chunks.

         <li>
            Services providing access to a method information block with data
            managed by a specific JIT compiler. For example, Jitrino stores
            stack maps and garbage collection status in the block.

         <li>
            Management of blocks of compiled code.

      </ul>
      <p>
         Certain services make a part of class support interface, for example,
         type management and class resolution. For details, see section <a
         href="#Class_support">3.2 Class Support</a>.
      </p>
      <h3>
         <a name="runtime_services"></a>3.8.2 Run-time Services
      </h3>
      <p>
         JIT-compiled code accesses the following groups of services at run
         time:
      </p>
      <ul>
         <li>
            Calls that push an M2nFrame and can perform all the operations of
            an ordinary JNI function, as described in section <a href=
            "#Native_Code_Support">3.3 Native Code Support</a>

         <li>
            Calls to VM functions that do not push an M2nFrame on the stack
            and, therefore, cannot throw exceptions, use stack walking, call
            Java<a href="#*">*</a> code or launch garbage collection

      </ul>
      <p>
         Both service types are described below.
      </p>
      <p class="class">
         Services with M2nFrame
      </p>
      <p>
         The following services are called in the JNI-like way:
      </p>
      <ul>
         <li>
            Throwing exceptions, including special services to throw lazy
            exceptions and standard exceptions

         <li>
            Synchronization primitives

         <li>
            Launching class initialization

         <li>
            Implementing <code>checkcast()</code> and <code>instanceof()</code>
            checks

         <li>
            Creating arrays, including multidimensional arrays

      </ul>
      <p>
         These services enable suspension in their code and push M2nFrames to
         the top of the stack that stores an initial stack state for
         exceptional <a href="#Stack_unwinding">stack unwinding</a> and local
         references for root enumeration purposes.
      </p>
      <p class="class">
         Services without M2nFrame
      </p>
      <p>
         The following frequently used services are invoked without pushing an
         M2nFrame on the stack:
      </p>
      <ul>
         <li>
            Loading constant strings from a constant pool

         <li>
            Storing objects into an array

         <li>
            Lookup of an interface VTable

         <li>
            Copying an array

         <li>
            Converting floating, double and integer types

         <li>
            Binary operations

      </ul>
      <p>
         These services prevent thread suspension in their code. Most direct
         call functions that implement operations or cast types only return a
         required result. Storing a reference to an array uses another
         convention because it returns <code>NULL</code> for success, or a
         class handler of an exception to throw.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Exception_Handling"></a>3.9 Exception Handling
      </h2>
      <p>
         The exceptions interface handles exceptions inside the VM. Exception
         handling can follow different paths depending on the execution engine
         mode, as indicated in subsequent sections.
      </p>
      <p>
         The exceptions interface includes the following function groups:
      </p>
      <ul>
         <li>
            <i>Basic functions</i>: throwing exceptions and getting information
            on the current state of the system

         <li>
            <i>Printing</i>: printing information about exceptions when no
            standard Java<a href="#*">*</a> handlers have caught the exception

         <li>
            <i>Utilities</i>: creating exception objects from native code

         <li>
            <i>Asserts</i>: verifying that the code obeys certain semantic checks
      </ul>
      <p>
         In DRLVM, two ways of handling exceptions are available: exception
         throwing and raising exceptions, as described below.
      </p>
      <h3>
         3.9.1 Throwing Exceptions
      </h3>
      <p>
         <i>Procedure</i>
      </p>
      <p>
         When an exception is thrown, the virtual machine tries to find the
         exception handler provided by the JIT and registered for the specified
         kind of exception and for the specified code address range. If the
         handler is available, the VM transfers control to it, otherwise, the
         VM unwinds the stack and transfers control to the previous native
         frame.
      </p>
      <p>
         <i>When to apply</i>
      </p>
      <p>
         In Java<a href="#*">*</a> code, only exception throwing is used,
         whereas in internal VM native code, raising an exception is also an
         alternative. Exception throwing is usually faster than raising
         exceptions because with exception throwing, the VM uses the <a href=
         "#Stack_unwinding">stack unwinding</a> mechanism.
      </p>
      <h3>
         <a name="Raising_Exceptions"></a>3.9.2 Raising Exceptions
      </h3>
      <p>
         <i>Procedure</i>
      </p>
      <p>
         When the VM raises an exception, a flag is set that an exception
         occurred, and the function exits normally. This approach is similar to
         the one used in JNI [<a href="#JNI_ref">5</a>].
      </p>
      <p>
         <i>When to apply</i>
      </p>
      <p>
         Raising exceptions is used in internal VM functions during JIT
         compilation of Java<a href="#*">*</a> methods, in the interpreter, and
         in the Java<a href="#*">*</a> Native Interface in accordance with the
         specification [<a href="#JNI_ref">5</a>]. This usage is especially
         important at start-up when no stack has been formed.
      </p>
      <h3>
         3.9.3 Choosing the Exception Handling Mode
      </h3>
      <p>
         DRLVM provides the following facilities to set the exception handling
         mode:
      </p>
      <ul>
         <li>
            Automatically by using the <code>exn_throw()</code> function.

         <li>
            Manually by using the <code>exn_throw_only()</code> or
            <code>exn_raise_only()</code> functions. This way is faster.

      </ul>
      <p>
         To get the current exception, use <code>exn_get()</code>, and to check
         that whether it is raised or not, use <code>exn_raised()</code>. The
         last function returns not the exception object, but the boolean flag
         only. This technique saves VM resources because the system does not
         need to create a new copy of the exception object.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         Remember that in the interpreter mode, the VM can only raise
         exceptions, and not throw them.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="JVMTI_Support"></a>3.10 JVMTI Support
      </h2>
      <p>
         In DRLVM, the JVMTI support component implements the standard JVMTI
         interface responsible for debugging and profiling.
      </p>
      <p>
         The DRLVM implementation of JVMTI
         mostly consists of wrapper functions, which request service and
         information from other VM parts, such as the class loader, the JIT,
         the interpreter, and the thread management functionality.
      </p>
      <p>
         Another part of JVMTI implementation is written for service purposes,
         and comprises agent loading and registration, events management, and
         API extensions support.
      </p>
      <h3>
         <a name="JVMTI_functions"></a>3.10.1 JVMTI functions
      </h3>
      <p>
         The JVMTI support component is responsible for the following groups of
         operations:
      </p>
      <ul>
         <li>
            <i>Debugging</i>: control of threads and thread groups, stack
            inspection, local variables access, access to information on
            objects and classes, fields and methods, support of breakpoints,
            and JNI function calls interception

         <li>
            <i>Profiling</i>: classes redefinition for Java<a href="#*">*</a>
            bytecode instrumentation

         <li>
            <i>General</i>: getting VM capabilities, registering event
            callbacks, requesting supported API extensions, and other
            operations

      </ul>
      <p class="class">
         Related Links
      </p>
      <ul>
         <li>
            Section <a href="#TI_in_interpreter">7.3.2 JVMTI Functions</a>
            about interpreter support for debugging

         <li>
            Description of <a href="#JIT_JVMTI">JVMTI Support</a> by the JIT
            compiler in section <a href="#JIT_VM">4.7.1 JIT_VM</a>

         <li>
            Tutorial <i>Creating a Debugging and Profiling Agent with JVMTI</i>
            [<a href="#debug_tut_ref">8</a>] with examples of JVMTI API usage

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Verifier"></a>3.11 Verifier
      </h2>
      <p>
         According to the JVM specification [<a href="#JVM_spec_ref">1</a>],
         the verifier is activated during class loading, before the preparation
         stage, and consequently, before the start of class initialization. Verification of a class consists
         of the following passes:
      </p>
      <ol>
         <li>
            Verifying the class file structure

         <li>
            Checking class data, that is, the logical structure of the data

         <li>
            Verifying bytecode instructions for the methods of the class

         <li>
            Linking the class in run time (handled by the resolver)

      </ol>
      <p>
         Subsequent sections present specifics of verification performed in
         DRLVM.
      </p>
      <h3>
         <a name="Optimized_Verification"></a> 3.11.1 Optimized Verification
         Procedure
      </h3>
      <p>
         The current version of the verifier is optimized to minimize
         performance impact of the time-consuming bytecode verification. The
         improved verification procedure is described below:
      </p>
      <blockquote>
         <p>
            <i>Stage 1</i>: When checking methods of a class, the verifier
            scans dependencies on other classes, methods, and fields. The
            verifier only checks this information if the referenced element is
            loaded. For unloaded elements handling, see Stage 2.
         </p>
         <p>
            <i>Stage 2</i>: The verifier generates a list of constraints to be
            checked during the next stage. <em>Constraints</em> contain
            information on verification checks that cannot be performed because
            referenced elements have not been loaded. The verifier stores the
            list of constraints in the checked class data.
         </p>
         <p>
            <i>Stage 3</i>: Before class initialization, the verifier goes over
            the list of previously generated constraints. Provided all exit
            criteria are met, the verification of the class completes
            successfully and initialization of the class begins.
         </p>
      </blockquote>
      <p>
         The verifier releases the constraints data when the class is unloaded.
      </p>
      <h3>
         <a name="Verifications_Classification"></a>3.11.2 Verifications
         Classification
      </h3>
      <p>
         For optimization purposes, all verification procedures have been
         divided into the following groups:
      </p>
      <ul>
         <li>
            Simple verifications that check the following:
            <ul>
               <li>
                  Targets of control-flow instructions

               <li>
                  Local variables usage

               <li>
                  Reference to the constant pool

               <li>
                  Exception handlers

               <li>
                  Instruction operands

            </ul>
            <p>
               The verifier can perform these checks without constructing the
               control flow graph.
            </p>

         <li>
            Complex verifications that check the following:
            <ul>
               <li>
                  End of code

               <li>
                  Stack depth

               <li>
                  Valid types in the stack

               <li>
                  Class members access

               <li>
                  Method invocation, assignment and value set conversions

               <li>
                  Initialization

            </ul>
            <p>
               For these operations, the bytecode verifier analyzes the control
               and data flow graphs.
            </p>

      </ul>
      <p class="class">
         Background
      </p>
      <p class="notetext">
         The <i>control flow graph</i> (CFG) is a data structure, which is an
         abstract representation of a procedure or program. Each node in the
         graph represents a basic block without jumps or jump targets. Directed
         edges represent jumps in the control flow.
      </p>
      <p class="notetext">
         The <i>data flow graph</i> (DFG) is a graph reflecting data
         dependencies between code instructions of a procedure or program. The
         data flow graph provides global information about how a procedure or a
         larger segment of a program manages its data.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In addition, a group of classes is declared as trusted. The verifier
         skips these classes to minimize performance impact. The group of
         trusted classes mostly includes system classes.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Utilities"></a>3.12 Utilities
      </h2>
      <p>
         This layer provides common general-purpose utilities. The main
         requirements for these utilities include platform independence for
         DRLVM interfaces, thread and stack unwind safety. The following two
         main subcomponents constitute the utilities layer:
      </p>
      <ul>
         <li>
            Memory management tools for automatic memory management in native
            code

         <li>
            Common logging system used across different DRLVM components, such
            as the VM core and the GC

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         This section describes VM utilities. For information on
         the compiler utilities, consult section <a href="#JIT_utilities">4.6
         Utilities</a>.
      </p>
      <p>
         The utilities layer has the following key features:
      </p>
      <ul>
         <li>
            Platform-independent interfaces

         <li>
            Thread safety to support the multi-thread environment of the VM
            core

         <li>
            Focus on memory management tools to enable safe stack unwinding

      </ul>
      <h3>
         <a name="Memory_Management"></a>3.12.1 Memory Management
      </h3>
      <p>
         This interface is responsible for allocating and freeing the memory
         used by other components. The current implementation provides two
         types of memory allocation mechanisms:
      </p>
      <ul>
         <li>
            Direct allocation through standard <code>malloc()</code>,
            <code>free()</code>, <code>realloc()</code> system calls

         <li>
            Allocation based on the Apache Portable Runtime (APR) layer memory
            pools [<a href="#APR_ref">14</a>]

      </ul>
      <p>
         Memory management functionality is concentrated in
         <code>port/include/port_malloc.h</code> and
         <code>port/include/tl/memory_pool.h</code>.
      </p>
      <h3>
         <a name="Logger"></a>3.12.2 Logger
      </h3>
      <p>
         The current logging system is based on the Apache <code>log4cxx</code>
         logger adapted to DRLVM needs by adding a C interface and improving
         the C++ interface. The <code>port/include/logger.h</code> header file describes the
         pure C programmatic logger interface. The <code>cxxlog.h</code> header
         file in the same directory contains a number of convenience macros improving effectiveness
         of the logger for C++ code.
      </p>
      <p>
         Each logging message has a header that may include its category,
         timestamp, location, and other information. Logging messages can be
         filtered by category and by the logging level. You can use specific
         command-line options to configure the logger and make maximum use of
         its capabilities. See help message <code>ij &ndash;X</code> for
         details on the logger command-line options.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="VM_exported_interfaces"></a>3.13 Public Interfaces
      </h2>
      <p>
         The VM core exports the following public interfaces:
      </p>
      <ul>
         <li>
            <em><a href="#VM_Common">VM common</a></em> enables the garbage
            collector and the JIT compiler to access object and class layout in
            the VM core and work with classes, fields, and methods.

         <li>
            <em><a href="#VM_JIT">VM_JIT</a></em> helps VM core and other components (via the VM core) to cooperate with
            the JIT and other components to register exception handlers, manage
            specific code and store data for methods, root set enumeration, GC
            control, binary code patching, and event subscription and handling.

         <li>
            <a href="#VM_EM"><em>VM_EM</em></a> enables managing the hot method
            recompilation logic.

         <li>
            <a href="#VM_GC"><em>VM_GC</em></a> supports garbage collection on
            the VM core side.

         <li>
            <a href="#VM_interpreter"><em>VM interpreter</em></a> enables the
            interpreter to use the VM core functionality.

         <li>
            <a href="#C_VM_Interface"><em>C VM</em></a> serves as a gateway
            between the Java<a href="#*">*</a> class library natives and other
            native components, for example, the porting layer.

         <li>
            <em>Kernel classes</em> interface supports the <a href=
            "#Kernel_Classes">kernel classes</a>, which port the Java<a href=
            "#*">*</a> class libraries to the virtual machine. The interface
            supports VM-dependent functionality declared in Java<a href=
            "#*">*</a> class libraries API&#39;s and includes specific classes,
            methods and fields required for the interdependence between the
            Java<a href="#*">*</a> class libraries and the VM.

         <li>
            <em>Java<a href="#*">*</a> Native Interface</em> (JNI) enables the
            virtual machine to interoperate with native code [<a href=
            "#JNI_ref">5</a>].

         <li>
            <em>JVM Tool Interface</em> is defined by the standard JVMTI [<a
            href="#JVMTI_ref">4</a>] typically used for profiling and
            debugging.

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="VM_Common"></a>3.13.1 VM Common Interface
      </h3>
      <p>
         The VM common interface is exported by the VM core for interaction
         with the <a href="#JIT_architecture">JIT compiler</a> and the <a href=
         "#GC_Architecture">garbage collector</a>. This interface includes a
         large set of getter functions used to query properties of classes,
         methods, fields, and object data structures required by DRLVM
         components. Other functions of this interface do the following:
      </p>
      <ul>
         <li>
            Create, manipulate threads and corresponding events, check thread
            status

         <li>
            Resolve classes and interfaces

         <li>
            Create and push <a href="#M2nFrame">M2nFrames</a> with VM
            information specific for an execution engine

         <li>
            Compile assembler stubs written in architecture-independent
            assembler-like language to invoke C functions::
            <ul>
               <li>
                  JNI stub for a specific JNI function, see section <a href=
                  "#Native_Code_Support">3.3 Native Code Support</a>.

               <li>
                  A stub, optimized for invocation of a specific VM internal
                  function, such as entering a Java<a href="#*">*</a> monitor
                  or object allocation

            </ul>

         <li>
            Create assembler stubs by a code emitter

         <li>
            Expose JNI extended environment structure

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="VM_JIT"></a>3.13.2 VM_JIT Interface
      </h3>
      <p>
         This VM core interface supports <a href="#JIT_Compiler">just-in-time
         compilation</a>. Functions of this interface do the following:
      </p>
      <ul>
         <li>
            During JIT compilation of bytecode into machine code:
            <ul>
               <li>
                  Supply the offset of the VTable entry for a given method. The
                  JIT uses this offset when generating an
                  <code>invokevirtual</code> method call. The location of the
                  VTable and the offset make up the start address of the
                  method.

               <li>
                  Query exception information contained in the application
                  class files.

            </ul>
            <p>
               For details, see section <a href="#Compile_time_services">3.8.1
               Compile-time Services</a>.
            </p>

         <li>
            Provide the JIT compiler with stubs, which
            enable in-lining calls
            to VM helper functions in machine code. VM helper
            functions can allocate a new object or array; throw an exception;
            perform <code>checkcast()</code>, <code>instanceof()</code>,
            <code>monitorenter()</code>, <code>monitorexit()</code>, or a GC <a
            href="#Write_barriers">write barrier</a> operation. For details,
            see section <a href="#runtime_services">3.8.2 Run-time
            Services</a>.

         <li>
            Allocate and de-allocate memory for code, data, and JIT-specific
            information. DRLVM does not currently implement unloading methods
            code.

         <li>
            Dump native code as hexadecimal numbers to a file in the VM debug
            mode.

         <li>
            Send notifications when a class is extended, or a method is
            overridden. For example, the VM core can recommend the JIT to back
            out optimizations where the exact VTable pointer is hard-coded into
            the generated code.

         <li>
            Report how to in-line synchronization and allocation operations,
            and safe points.

         <li>
            Check whether a method has side effects that restrict application
            of the lazy exceptions mechanism.

         <li>
            Check whether compiled method code can be relocated.

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The VM core also exports the GC interface function table to support
         GC-related operations of the JIT, such as root set enumeration. For
         details, see section <a href="#GC_Exported_Interfaces">6.4 Public
         Interfaces</a> in the GC description.
      </p>
      <p>
         For a description of functions that the JIT compiler exports to
         communicate with the VM core, see section <a href="#JIT_VM">4.7.1
         JIT_VM</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="VM_EM"></a>3.13.3 VM_EM INTERFACE
      </h3>
      <p>
         The <code>VM_EM</code>  interface
         of the VM core supports high-level management of execution engines. Functions of this
         interface do the following:
      </p>
      <ul>
         <li>
            Load, unload, and create new instances of JIT compilers

         <li>
            Provide compilation  method calls and callbacks

      </ul>
      <p>
         For a description of functions that the execution manager exports to
         interact with the VM core, see <a href="#EM_VM">5.5.1 EM_VM Interface</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="VM_GC"></a>3.13.4 vm_GC Interface
      </h3>
      <p>
         The VM core uses this interface to communicate with the garbage
         collector. The garbage collector also interacts with the just-in-time
         compiler via indirect calls to the <code>VM_GC</code> interface.
      </p>
      <p>
         On the VM side, most functions of this interface are used for root set
         enumeration and for stopping and resuming all threads. To implement
         stop-the-world collections, DRLVM currently provides the functions
         <code>vm_enumerate_root_set_all_threads()</code> and
         <code>vm_resume_threads_after()</code>.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The current implementation does not support concurrent garbage
         collectors. However, DRLVM has been designed to make implementation of
         concurrent garbage collectors as convenient as possible.
      </p>
      <p>
         For details on the <code>VM_GC</code> interface, see section <a href=
         "#GC_Exported_Interfaces">6.4 GC Public Interfaces</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="VM_interpreter"></a>3.13.5 VM INTERPRETER INTERFACE
      </h3>
      <p>
         This interface enables the interpreter to use the VM core functionality. Functions of the interface do the following:
      </p>
      <ul>
         <li>
            Create enumerable handles containing direct heap pointers

         <li>
            Mark GC-unsafe code regions

         <li>
            Enter and exit Java<a href="#*">*</a> monitors

         <li>
            Provide JVM TI breakpoint, single step, push and pop frame
            callbacks

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="C_VM_Interface"></a>3.13.6 C VM Interface
      </h3>
      <p>
         The C VM interface together with the <a href="#Kernel_Classes">kernel
         classes</a> is responsible for interaction between the VM and the
         class libraries. The C VM interface is used by the native part of the
         Java<a href="#*">*</a> class libraries (JCL) implementation as a
         gateway to different libraries, such as the port library, the VM local
         storage, and the zip cache pool. This component is required for the
         operation of JCL, see the Harmony Class Library Porting documentation
		 [<a href="#SVN_IBMdoc_ref">20</a>].
      </p>
      <p class="class">
         C VM Specifics
      </p>
      <p>
         The C VM interface has the following limitations:
      </p>
      <ul>
         <li>
            <i>VM local storage</i> does not support the multi-VM mode and,
            consequently, ignores the function argument identifying the VM
            instance, for which the call is produced.

         <li>
            <i>Access to the port library and to the zip cache pool</i> does
            not support the multi-VM mode. The implementation keeps the
            instance of the port library and the zip cache pool in the global
            variables.

         <li>
            <i>Access to the VM interface function table</i> does not support
            the multi-VM mode either. The global variable stores the pointer to
            the table.

         <li>
            <i>Version checking</i> is not implemented because the function is
            not called by any library.

         <li>
            <i>Operations with system properties</i> are not implemented.
            Currently, the VM code sets system properties, such as the
            <code>boot.class.path</code> property. For details, see section <a
            href="#Initialization">2.5 Initialization</a>.

      </ul>
      <p>
         The C VM interface is a separate dynamic library. This library
         is statically linked with the pool, the zip support and the thread support
         libraries.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="JIT_Compiler"></a>4. JIT Compiler
      </h1>
      <p>
         Jitrino is the code name for just-in-time (JIT) compilers shipped with
         DRLVM [<a href="#JIT_spec_ref">3</a>]. Jitrino comprises two distinct
         JIT compilers: the <em>Jitrino.JET</em> baseline compiler and the
         optimizing compiler, <em>Jitrino.opt</em>. These two compilers share
         common source code and are packaged in a single library. This section
         is mostly devoted to Jitrino.opt compiler. For details on the baseline
         compiler, see section <a href="#JET_introduction">4.8 Jitrino.JET</a>.
      </p>
      <p>
         The optimizing JIT compiler features two intermediate representation
         (IR) types: platform independent high-level IR (HIR) and
         platform-dependent low-level IR (LIR). Jitrino incorporates an
         extensive set of code optimizations for each IR type. This JIT
         compiler has a distinct internal interface between the front-end
         operating on HIR and the back-end operating on LIR. This enables easy
         re-targeting of Jitrino to different processors and preserving all the
         optimizations done at the HIR level.
      </p>
      <p>
         Key features of the JIT compiler include:
      </p>
      <ul>
         <li>
            Clear interface to plug in different front-end components

         <li>
            Clear interface to plug in code generators for different platforms

         <li>
            Two-level intermediate representation with most optimizations run
            on the platform-independent high level

      </ul>
      <p>
         Jitrino also features:
      </p>
      <ul>
         <li>
            Ability to plug-in new optimization passes easily at the HIR and
            LIR levels
         <li>
            High configurability via command-line options or an initialization
            file

         <li>
            Flexible logging system, which enables tracing of major Jitrino
            activities, including detailed IR dumps during compilation and
            run-time interaction with other DRL components on the per-thread
            basis, as well as gathering execution time statistics of compiler
            code at a very fine granularity level

         <li>
            Configurable self-check capabilities to facilitate bug detection

      </ul>
      <p>
         Jitrino is eminent for its clear and
         consistent overall architecture and a strong <i>global optimizer</i>,
         which runs high-level optimizations and deals with single or multiple
         methods instead of basic blocks.
      </p>
      <p>
         In the current implementation, certain Jitrino features are
         implemented only partially or not enabled, namely:
      </p>
      <ul>
         <li>
            <i>Common Language Infrastructure (CLI) support.</i> No CLI
            bytecode translator is available, but CLI semantics is supported on
            the HIR level via specific HIR instructions and types.

         <li>
            <i>Dynamic profile-guided optimizations</i>. Necessary DPGO support
            is built into HIR data types, for example, special fields in nodes
            and edges, HIR optimization passes, and LIR components are able to
            use dynamic profile information. However, the dynamic profile of
            the type supported by the optimizations is not currently collected.

         <li>
            <i>High-level optimization passes</i>. Only a few passes are
            currently enabled. The precise list is given in the README
            document.

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="JIT_architecture"></a>4.1 Architecture
      </h2>
      <p>
         The Jitrino compiler provides a common strongly typed substrate, which  helps
         developers to optimize code distributed for Java<a href="#*">*</a>
         run-time environments and adapt it to
         different hardware architectures with a lower chance of flaws. The
         architecture of the compiler is organized to support this flexibility
         as illustrated in Figure 13. Paths connect the Java<a href="#*">*</a>
         and ECMA Common Language Interface (CLI) front-ends with every
         architecture-specific back-end, and propagate type information from
         the original bytecode to the architecture-specific back-ends.
      </p>
      <p>
         For extensibility purposes, the Jitrino compiler contains language-
         and architecture-specific parts and language- and
         architecture-independent parts described in subsequent sections of
         this document. As a result, supporting a new hardware architecture
         requires implementation of a new back-end.
      </p>
      <h3>
         4.1.1 Compilation Paths
      </h3>
      <p>
         To optimize time spent on compilation, the Jitrino compiler can follow
         a fast or a slow compilation path. In most applications, only a few
         methods consume the majority of time. Overall performance benefits
         when Jitrino aggressively optimizes these methods.
      </p>
      <p>
         The initial compilation stage is to translate methods into machine
         code by using the baseline compiler <em>Jitrino.JET</em>, the Jitrino
         express compilation path. This compiler performs a very fast and
         simple compilation and applies no optimizations. The main Jitrino
         compilation engine recompiles only hot methods. Jitrino.JET generates
         instrumentation counters to collect the run-time profile. Later, the
         <a href="#EM">execution manager</a> uses this profile to determine
         recompilation necessity.
      </p>
      <h3>
         4.1.2 Compilation Process
      </h3>
      <p>
         The process of compilation in Jitrino.opt follows a single path, as
         shown in Figure 13 below.
      </p>
      <ol>
         <li>
            The run-time environment bytecode is translated into the high-level
            IR by the individual front-ends for each supported source language.
            Currently, Jitrino incorporates the Java<a href="#*">*</a> bytecode
            translator, and provides the high-level IR and optimizer support
            for the Java<a href="#*">*</a> and Common Language Interface (CLI)
            bytecode. The language- and architecture-independent part comprises
            the HIR and the optimizer.

         <li>
            After optimization, architecture-specific code generators translate
            HIR into architecture-specific intermediate representations,
            perform architecture-specific optimizations, register allocation,
            and finally emit the generated native code.

      </ol>
      <p align="center">
         <img border="0" src="images/compilation_process.gif" alt=
         "JIT Architecture">
      </p>
      <p class="special">
         Figure 13. Jitrino Compiler Architecture
      </p>
      <p>
         The subsequent sections provide an overview of the compiler
         subcomponents. Section <a href="#High-level_optimizer">4.3
         Optimizer</a> provides details on the Jitrino high-level
         optimizations.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Front-end"></a>4.2 Front-end
      </h2>
      <p>
         The initial compilation step is the translation of bytecode into HIR,
         which goes in the following phases:
      </p>
      <ol>
         <li>
            Bytecode translator establishes the basic block boundaries and
            exception handling regions, and recovers type information for
            variables and operators. At this phase, the translator generates
            type information for variables and virtual Java<a href="#*">*</a>
            stack locations, similarly to the bytecode verification algorithm
            defined by the JVM specification [<a href="#JVM_spec_ref">1</a>].

         <li>
            Bytecode translator generates the HIR and performs simple
            optimizations, including constant and copy propagation, folding,
            devirtualization and in-lining of method calls, elimination of
            redundant class initialization checks, and value numbering-based
            redundancy elimination [<a href="#Muchnik_ref">15</a>].

      </ol>
      <p>
         Jitrino HIR, which is the internal representation of a lower level
         than the bytecode, breaks down complex bytecode operations into
         several simple instructions to expose more opportunities to later
         high-level optimization phases. For example, loading an object field
         is broken up into operations that perform a null check of the object
         reference, load the base address of the object, compute the address of
         the field, and load the value at that computed address.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Optimizer"></a>4.3 Optimizer
      </h2>
      <p>
         The optimizer includes a set of compiler components independent of the
         original Java<a href="#*">*</a> bytecode and the hardware
         architecture. The optimizer comprises the high-level intermediate
         representation, the optimizer, and the architecture-independent part
         of the <a href="#Code_selector">code selector</a>. The code selector
         has a distinct interface level to set off the architecture-dependent
         part.
      </p>
      <h3>
         4.3.1 High-Level Intermediate Representation
      </h3>
      <p>
         Jitrino uses the traditional high-level intermediate representation,
         where the control flow is represented as a graph consisting of nodes
         and edges. The compiler also maintains dominator and loop structure
         information on HIR for use in optimization and code generation. HIR
         represents:
      </p>
      <ul>
         <li>
            <i>Conventional control flow</i> due to jumps and branches, modeled
            via basic block nodes and edges, which represent jumps and
            conditional branches between basic block nodes.

         <li>
            <i>Exceptional control flow</i> due to thrown and caught
            exceptions, modeled via the dispatch nodes: a thrown exception is
            represented by an edge from a basic block node to a dispatch node,
            and a caught exception is represented by an edge from a dispatch
            node to a block node.<br>
             Because HIR can represent the exceptional control flow, the
            optimizer and code generators account for and optimize exceptions
            and exception handlers.

      </ul>
      <p>
         Explicit modeling of the exception control flow in the control flow
         graph (CFG) enables the compiler to optimize across throw-catch
         boundaries. For locally handled exceptions, the compiler can replace
         expensive throw-catch combinations with cheaper direct branches.
      </p>
      <p>
         To explain the same in greater detail, each basic block node consists
         of a list of instructions, and each instruction includes an operator
         and a set of single static assignment (SSA) operands. The SSA form
         provides explicit use-def links between operands and their defining
         instructions, which simplifies and speeds up high-level optimizations.
         Each HIR instruction and each operand have detailed type information
         propagated to the back-end at further compilation stages.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="High-level_optimizer"></a>4.3.2 Optimizer
      </h3>
      <p>
         The Jitrino compiler uses a single optimization framework for Java<a
         href="#*">*</a> and CLI programs. The optimizer applies a set of
         classical object-oriented optimizations balancing the effectiveness of
         optimizations with their compilation time. Every high-level
         optimization is represented as a separate transformation pass over the
         HIR. These passes are grouped into four categories:
      </p>
      <ul>
         <li>
            <a href="#JIT_simplification_pass">HIR simplification</a> passes
            performed at multiple points to clean up the method representation
            between passes

         <li>
            <a href="#JIT_scope_enhancement_pass">Scope enhancement</a> passes

         <li>
            <a href="#JIT_redundance_pass">Redundancy elimination</a> passes
            performed in sequence

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In the current version, high-level optimizations are disabled by
         default. You can enable these via the command-line interface.
      </p>
      <p>
         The optimization passes performed during compilation of a method
         constitute an <i>optimization path</i>. Each optimization pass has a
         unique string tag used internally to construct the optimization path
         represented as a character string. The default optimization path can
         be overridden on the command-line.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         Many optimizations can use dynamic profile information for greater
         efficiency, such as method and basic block hotness and branch
         probability. However, dynamic profile information creation is not
         currently enabled in Jitrino.
      </p>
      <p class="class">
         <a name="JIT_simplification_pass"></a>HIR Simplification Passes
      </p>
      <p>
         The HIR simplification passes are a set of fast optimization passes
         that the Jitrino optimizer performs several times on the intermediate
         representation to reduce its size and complexity. Simplification
         passes improve the code quality and the efficiency of more expensive
         optimizations. The IR simplification consists of three passes:
      </p>
      <ol>
         <li>
            <i>Propagation and folding</i> performs constant, type, and copy
            propagation, and simplifies and folds expressions. For example,
            when a reference is defined by a <code>new</code> allocation, the
            optimizer omits a run-time check for null references that are
            proven non-null [<a href="#Muchnik_ref">15</a>].

         <li>
            <i>Unreachable and dead code cleanup</i> eliminates unreachable
            code by testing reachability via traversal from the control flow
            graph entry, and dead code by using a sparse liveness traversal
            over SSA-form use-def links [<a href="#Muchnik_ref">15</a>].

         <li>
            <i>Fast high-level value numbering</i> eliminates common
            sub-expressions [<a href="#value_number_ref">16</a>]. This pass
            uses an in-order depth-first traversal of the dominator tree
            instead of the more expensive iterative data flow analysis done by
            traditional common sub-expression elimination. High-level value
            numbering effectively eliminates redundant address computation and
            check instructions. For example, <code>chkzero()</code>,
            <code>chknull()</code>, and <code>chkcast()</code> HIR instructions
            are redundant if guarded by explicit conditional branches.

      </ol>
      <p>
         Together, the IR simplification passes constitute a single cleanup
         pass performed at various points in the optimization process.
      </p>
      <p class="class">
         <a name="JIT_scope_enhancement_pass"></a>Scope Enhancement Passes
      </p>
      <p>
         The high-level optimization begins with a set of transformations to
         enhance the scope of further optimizations, as follows:
      </p>
      <ol>
         <li>
            <i>Normalization of control flow</i> by removing critical edges,
            and factoring entry and back edges of loops, which facilitates loop
            peeling, redundancy elimination passes and other operations.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               A critical edge is an edge from a node with multiple successors
               to a node with multiple predecessors.
            </p>

         <li>
            <i>Loop transformations</i>, including loop inversion, peeling, and
            unrolling.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               Loop peeling in combination with high-level value numbering
               provides a cheap mechanism to hoist loop-invariant computation
               and run-time checks.
            </p>

         <li>
            <i>Guarded devirtualization</i> of virtual method calls to reduce
            their run-time costs and to enable the compiler to in-line their
            targets.<br>
             Provided the exact type information, this IR simplification pass
            can convert a virtual call into a more efficient direct call. When
            the type information is not available, the most probable target of
            the virtual method can be predicted, and the scope enhancement pass
            devirtualizes the call by guarding it with a cheap run-time test to
            verify that the predicted method is in fact the target.

      </ol>
      <p class="class">
         Inliner
      </p>
      <p>
         The central part of the scope enhancement passes is the inliner, which
         removes the overhead of a direct call and specializes the called
         method within the context of its call site. In-lining is an iterative
         process built around other scope enhancement and IR simplification
         passes. In-lining goes as follows:
      </p>
      <ol>
         <li>
            Inliner performs scope enhancement and IR simplification
            transformations on the original intermediate representation:
            <ol type="a">
               <li>
                  Examines each direct call site in the IR, including those
                  exposed by guarded devirtualization.

               <li>
                  Assigns a weight to the call by using heuristic methods.

               <li>
                  Registers the call in a priority queue if it exceeds a
                  certain threshold.

            </ol>

         <li>
            Inliner selects the top candidate, if any, for in-lining.

         <li>
            Translator generates an intermediate representation for the method
            selected for in-lining.

         <li>
            Inliner repeats the cycle on the new IR and processes the
            representation for further in-lining candidates, updates the
            priority queue, merges it with the existing IR, selects a new
            candidate, and repeats the cycle.

      </ol>
      <p>
         The in-liner halts when the queue is empty or after the IR reaches a
         certain size limit. When in-lining is completed, the optimizer
         performs a final IR simplification pass over the entire intermediate
         representation.
      </p>
      <p class="class">
         <a name="JIT_redundance_pass"></a>Redundancy Elimination Passes
      </p>
      <p>
         The final set of optimization passes comprises optimizations to
         eliminate redundant and partially redundant computations and includes
         loop-invariant code motion and bounds-check elimination [<a href="#Muchnik_ref">15</a>].
      </p>
      <dl>
         <dt>
            Bounds-check Elimination
         </dt>
         <dd>
            The Jitrino optimizer uses <i>demand-driven array bounds-check
            elimination</i> analysis based on the ABCD [<a href=
            "#enumer_ref">17</a>] algorithm. Unlike the original ABCD
            algorithm, the Jitrino optimizer bounds-check elimination does not
            construct a separate constraint graph, but uses the SSA graph
            directly to derive constraints during an attempted proof
            instead.<br>
             The optimizer also handles symbolic constants to enable check
            elimination in more complicated cases. Check elimination
            transformations track conditions used to prove that a check can be
            eliminated. At the code selector stage, the selector propagates the
            information about the conditions to the code generator, which can
            use this information for speculative loads generation.
         </dd>
      </dl>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Code_selector"></a>4.4 Code Selector
      </h2>
      <p>
         The code selector translates the high-level intermediate
         representation to a low-level intermediate representation (currently,
         to the IA-32 representation). The component is designed so that code
         generators for different architectures can be plugged into the
         compiler. To be pluggable, a code generator (CG) must implement
         distinct code selector callback interfaces for each structural entity
         of a method. During code selection, the selector uses the callback
         interfaces to translate these entities from HIR to LIR.
      </p>
      <p>
         Code selection is based on the HIR hierarchical structure of the
         compiled method illustrated by Figure 14.
      </p>
      <table align="center">
         <tr>
            <td>
               <img src="images/code_selector.gif" alt=
               "Code Selector work flow">
            </td>
         </tr>
         <tr>
            <td>
               <p class="special">
                  Figure 14. Code Selector Structure
               </p>
               <p class="notetext">
                  Grey indicates callback interfaces.
               </p>
            </td>
         </tr>
      </table>
      <p>
         For every non-leaf structural element in Figure 14, the code selector
         defines:
      </p>
      <ul>
         <li>
            Abstract class representing a selector of the element with a set of
            functions necessary to transform this element to LIR

         <li>
            Default implementation of the selector

         <li>
            Callback interface to transform the direct sub-elements implemented
            by the CG from HIR to LIR

      </ul>
      <p>
         Each class of the code selector defines a <code>genCode()</code>
         function, which takes the callback of this class as an argument. Every
         function in a callback receives a code selector class instance
         corresponding to the lower-level element of the method hierarchy. This
         way, control is transferred between the optimizer part of the code
         selector and the CG part.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Back-end"></a>4.5 IA-32 Back-end
      </h2>
      <p>
         The Jitrino IA-32 code generator has the following key features:
      </p>
      <ul>
         <li>
            Common framework for describing the IA-32 architecture
            irregularities based on the <code>Constraint</code> class:<br>
             Each constraint is a 32-bit value describing allowable or actual
            physical locations of operands imposed by encoding tables and
            operand types.

         <li>
            Pluggable calling convention described by the
            <code>CallingConvention</code> interface to facilitate adapting the
            code generator to various extended compilation scenarios, such as
            ahead-of-time compilation and code caching.

         <li>
            Distinction of each LIR transformation as a separate software unit,
            a descendant of the <code>IRTransformer</code> class.

         <li>
            Core functionality for LIR manipulation concentrated in the
            <code>IRManager, Inst,</code> and <code>Opnd</code> classes.

         <li>
            Complete management of the code generation path via a text string.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               You can override the default hard-coded descriptions on the
               command line.
            </p>

         <li>
            Binding of resolution-dependent constants at the latest stage
            possible:<br>
             Binding is performed during code emission to facilitate support
            for code caching and ahead-of-time compilation.

         <li>
            Spill code generation without register reservation.

         <li>
            GC information maintenance independent from other transformations
            and bound to instructions and not to operands.

         <li>
            Floating point arithmetic based on Streaming SIMD Extensions (SSE)
            scalar instructions.<br>
             The X87 registers are used only as return values according to the
            calling conventions imposed by the virtual machine.

      </ul>
      <h3>
         4.5.1 Limitations
      </h3>
      <ul>
         <li>
            No X87 floating point support: Jitrino cannot work on processors
            without both SSE and SSE2 support.

         <li>
            Incomplete support for arbitrary calling conventions: the framework
            has not been finished yet to support Intel&reg; EM64T or calling
            conventions with incoming arguments placed in registers.

      </ul>
      <p class="class">
         Code Generation Pass
      </p>
      <p>
         The table below describes the passes of the code generation process
         used in the IA-32 code generator. The order of the passes in the table
         mostly corresponds to the default code generation path.
      </p>
      <table border="0">
         <tr>
            <td class="TableHeading">
               Name
            </td>
            <td class="TableHeading">
               Classes
            </td>
            <td class="TableHeading">
               Description
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>selector</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Code selector
            </td>
            <td class="TableCell">
               <code>MethodCodeSelector, CfgCodeSelector,
               InstCodeSelector</code>
            </td>
            <td class="TableCell">
               Builds LIR based on the information from the optimizer. Is based
               on the common code lowering framework.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>i8l</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               8-byte instructions lowerer
            </td>
            <td class="TableCell">
               <code>I8Lowerer</code>
            </td>
            <td class="TableCell">
               Performs additional lowering of operations on 8-byte integer
               values into processor instructions.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <strong>bbp</strong>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Back-branch polling (insertion of safe points)
            </td>
            <td class="TableCell">
               <code>BBPollingTransformer</code>
            </td>
            <td class="TableCell">
               Inserts safe points into loops to ensure that threads can be
               suspended quickly at GC-safe points.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>gcpoints</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               GC safe points Info
            </td>
            <td class="TableCell">
               <code>GCPointsBaseLiveRangeFixer</code>
            </td>
            <td class="TableCell">
               Performs initial data flow analysis and changes the LIR for
               proper GC support: creates mapping of interior pointers
               (pointers to object fields and array elements) to base pointers
               (pointers to objects) and extends liveness of base pointers when
               necessary.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>cafl</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Complex address form loader
            </td>
            <td class="TableCell">
               <code>ComplexAddrFormLoader</code>
            </td>
            <td class="TableCell">
               Translates address computation arithmetic into IA-32 complex
               address forms.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>early_prop</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Early propagation
            </td>
            <td class="TableCell">
               <code>EarlyPropagation</code>
            </td>
            <td class="TableCell">
               Performs fast copy and constant propagation. This pass is fast
               and simple though very conservative.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>native</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Translation to native form
            </td>
            <td class="TableCell">
               <code>InstructionFormTranslator</code>
            </td>
            <td class="TableCell">
               Performs trivial transformation of LIR instructions from their
               extended to native form.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>constraints</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Constraints resolver
            </td>
            <td class="TableCell">
               <code>ConstraintsResolver</code>
            </td>
            <td class="TableCell">
               Checks instruction constraints imposed on operands by
               instructions and split operands when they cannot be used
               simultaneously in all the instructions they are inserted in.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>dce</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Dead code elimination
            </td>
            <td class="TableCell">
               <code>DCE</code>
            </td>
            <td class="TableCell">
               Performs the simple liveness-based one-pass dead code
               elimination.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>bp_regalloc-GP, bp_regalloc-XMM</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Bin-pack register allocator
            </td>
            <td class="TableCell">
               <code>RegAlloc2</code>
            </td>
            <td class="TableCell">
               Perform bin-pack global register allocation for general-purpose
               and XMM registers.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>spillgen</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Spill code generator
            </td>
            <td class="TableCell">
               <code>SpillGen</code>
            </td>
            <td class="TableCell">
               Acts as the local register and stack allocator and the spill
               code generator. Is similar to the constraint resolver but
               addresses the constraints caused by dependencies between
               operands. For example, this pass is used when an instruction
               allows only one memory operand.<br>
                The pass requires no reserved registers, but tries to find
               register usage holes or to evict an already assigned operand
               from a desired register.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>layout</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Code layout
            </td>
            <td class="TableCell">
               <code>Layouter</code>
            </td>
            <td class="TableCell">
               Performs linearization of the CFG. Uses the topological,
               top-down, and bottom-up algorithms.<br>
                In the current code drop the default code layout algorithm is
               topological [<a href="#CodePosit_ref">21</a>].
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>copy</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Copy pseudo inst expansion
            </td>
            <td class="TableCell">
               <code>CopyExpansion</code>
            </td>
            <td class="TableCell">
               Converts copy pseudo-instructions into real instructions.<br>
                Currently, the CG describes instructions that copy operands as
               copy pseudo-instructions and expands them when all operands are
               assigned to physical locations. This facilitates building other
               transformations.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>stack</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Stack layout
            </td>
            <td class="TableCell">
               <code>StackLayouter</code>
            </td>
            <td class="TableCell">
               Creates prolog and epilog code. Uses register usage information,
               the calling convention used for this method, and the stack depth
               required for stack local operands. Also initializes persistent
               stack information to be used in run-time stack unwinding.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>emitter</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Code emitter
            </td>
            <td class="TableCell">
               <code>CodeEmitter</code>
            </td>
            <td class="TableCell">
               Produces several streams:
               <ul>
                  <li>
                     stream of executable code for the method

                  <li>
                     data block with FP constant values and target offset
                     tables for switch instructions

               </ul>
               Registers the exception try and catch regions in the VM for
               handling during runtime, and direct calls for patching.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>si_insts</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               StackInfo inst registrar
            </td>
            <td class="TableCell">
               <code>StackInfoInstRegistrar</code>
            </td>
            <td class="TableCell">
               Traverses call instructions to get information on the stack
               layout on call sites and completes the persistent stack
               information.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>gcmap</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               GC map creation
            </td>
            <td class="TableCell">
               <code>GCMapCreator</code>
            </td>
            <td class="TableCell">
               Creates the GC map comprising sets of locations with base and
               interior pointers representing GC root set for each call site.
            </td>
         </tr>
         <tr>
            <td colspan="3" class="TableCell">
               <b>info</b>
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               Creation of method info block
            </td>
            <td class="TableCell">
               <code>InfoBlockWriter</code>
            </td>
            <td class="TableCell">
               Serializes persistent stack information and the GC map in the VM
               as an information block for later use during run-time stack
               iteration, exception throwing, and GC root set enumeration.
            </td>
         </tr>
      </table>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="JIT_utilities"></a>4.6 Utilities
      </h2>
      <p>
         The utilities used by the JIT compiler major components include:
      </p>
      <ul>
         <li>
            Memory manager, which minimizes the number of calls to system heap
            allocations and automatically frees all allocated memory in the
            destructor

         <li>
            Set of Standard Template Library (STL) containers using the memory
            manager as their allocator class

         <li>
            Timers

         <li>
            Basic control flow graph

         <li>
            Logging system

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The JIT compiler utilities are similar to, but not identical with the
         VM utilities. For example, the JIT compiler and the VM core use
         different loggers.
      </p>
      <h3>
         <a name="JIT_logging"></a>4.6.1 Logging System
      </h3>
      <p>
         The Jitrino logging system facilitates debugging and performance
         bottleneck detection. The system is organized as a set of <i>log
         categories</i> structured into two hierarchical category trees for
         compile-time and run-time logging. This functionality is used in root
         set enumeration and stack iteration at run time.
      </p>
      <p>
         A log category corresponds to a particular compiler component, such as
         the front-end or the code generator, and has a number of levels
         providing different logging details. Figure 15 illustrates logging
         categories and levels, namely:
      </p>
      <ul>
         <li>
            <i>Run-time category</i> (<code>rt</code>) with two sub-categories
            for logging related to garbage collection and call address patching

         <li>
            <i>Compile-time root category</i> (<code>root</code>) with
            sub-categories for the front-end translator and HIR construction
            (<code>fe</code>), the optimizer (<code>opt</code>), and the code
            generator (<code>cg</code>)

         <li>
            <i>Logging levels</i> and their association with the categories

      </ul>
      <p>
         In the logging system, built-in timers measure the time spent by a
         particular compiler component or a code transformation pass during
         compilation.
      </p>
      <table align="center">
         <tr>
            <td>
               <img border="0" src="images/log_categories.gif" alt=
               "Lock Categories Hierarchy">
            </td>
         </tr>
         <tr>
            <td height="29">
               <p class="special">
                  Figure 15. Log Categories Trees
               </p>
            </td>
         </tr>
      </table>
      <p>
         In DRL, all logging is off by default. You can enable logging for a
         category on the command line, use the <code>-Xjit LOG</code> option
         and assign the particular level to it. For example, you can enable
         debug-level logging for the optimizer component and IR dumping for the
         code generator by using the following option:<br>
          <code>-Xjit LOG=\&rdquo;opt=debug,cg=ir,singlefile\&rdquo;</code>
      </p>
      <p>
         On the command line, you can assign logging levels independently to
         the categories in different sub-trees. When redirected to the file
         system, separate logs for different threads are created unless the
         <code>singlefile</code> mode is specified.
      </p>
      <p class="class">
         CFG Visualization
      </p>
      <p>
         Debugging the JIT requires information on the compilation inter-stage
         modification of the control flow graph for the compiled method,
         including instructions and operands. For that, the Jitrino compiler
         enables generation of <i>dot</i> files representing the control flow
         graph at both IR levels. The text dot files can be converted into
         descriptive pictures, which represent the CFG graphically. A variety
         of graph visualization tools are available for dot files conversion.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="JIT_interfaces"></a>4.7 Public Interfaces
      </h2>
      <p>
         This section describes the interfaces that the JIT compiler exports to
         communicate with other components. The Jitrino compiler exposes all
         necessary interfaces to work as a part of the run-time environment.
         Jitrino explicitly supports precise moving garbage collectors
         requiring the JIT to enumerate live references.
      </p>
      <h3>
         <a name="JIT_VM"></a>4.7.1 JIT_VM Interface
      </h3>
      <p>
         Functions inside the <code>JIT_VM</code> interface can be grouped into
         the following categories:
      </p>
      <ul>
         <li>
            <a href="#compilation_interface">Bytecode compilation</a>

         <li>
            <a href="#RSE_JIT">Root set enumeration</a>

         <li>
            <a href="#Stack_unwinding">Stack unwinding</a>

         <li>
            <a href="#JIT_JVMTI">JVMTI support</a>

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         Root set enumeration and stack unwinding are run-time routines called
         only during execution of compiled code.
      </p>
      <p class="class">
         <a name="compilation_interface"></a>Bytecode Compilation
      </p>
      <p>
         Functions in this set are responsible for the primary JIT compiler
         task of running just-in-time compilation to produce native executable
         code from a method bytecode. A request to compile a method can come
         from the VM core or the execution manager.
      </p>
      <p class="class">
         <a name="RSE_JIT"></a>Root Set Enumeration
      </p>
      <p>
         This set of functions supports the garbage collector by enumerating
         and reporting live object references. The JIT compiler uses these
         functions to report locations of object references and interior
         pointers that are live at a given location in the JIT-compiled code.
         The object references and interior pointers constitute the root set
         that the GC uses to traverse all live objects. The interface requires
         reporting locations of the values rather than the values, to enable a
         moving garbage collector to update the locations while moving objects.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         Unlike reference pointers that always point to the object&rsquo;s
         header, <em>interior pointers</em> actually point to a field that is
         inside the target object. If the JIT reports an Interior Pointer
         without the Reference Pointer, then the burden is upon the GC to
         actually reconstruct the Reference Pointer.
      </p>
      <p>
         For more information, see sections <a href="#Root_Set_Enumeration">2.6
         Root Set Enumeration</a> and <a href="#GC">6. Garbage Collector</a>.
      </p>
      <p class="class">
         <a name="Stack_unwinding"></a>Stack Unwinding
      </p>
      <p>
         The virtual machine requires support from the compiler to perform
         stack unwinding, that is, an iteration over the stack from a managed
         frame to the frame of the caller.
      </p>
      <p>
         To facilitate stack walking, the JIT stack unwinding interface does
         the following:
      </p>
      <ul>
         <li>
            Updates the JIT stack frame context reflecting an iteration of
            stack walking. Different JIT compilers can implement different
            physical stack frame layouts and the JIT is responsible for proper
            interpretation of them.

         <li>
            Reports the current location of a given pointer to allow VM to
            remove monitors for synchronized non-static methods during
            exception handling.

         <li>
            Updates the JIT frame context to reflect the stack state at a catch
            handler.

      </ul>
      <p>
         For more information about the stack, see section <a href=
         "#Stack_Support">3.4 Stack Support</a>.
      </p>
      <p class="class">
         <a name="JIT_JVMTI"></a>JVMTI Support
      </p>
      <p>
         The set of JIT functions responsible for JVMTI support is exported for
         interaction with the VM JVMTI component. These functions do the
         following:
      </p>
      <ul>
         <li>
            Process requests about JIT capabilities for JVMTI support.<br>
             For profiling and debugging, the JVMTI support component in the VM
            core requires the JIT compiler to have a set of capabilities. The
            VM core can query the JIT, which the capabilities actually
            supported.

         <li>
            Provide bytecode to native code mapping to identify native and
            bytecode locations for the compiled method.

         <li>
            Access and modify local variables in compiled code.

      </ul>
      <p>
         The VM can request the JIT to compile a method and to support
         generation of specific JVMTI events in compiled code. To facilitate
         these actions, additional parameters are passed to the bytecode
         compilation interface.
      </p>
      <p>
         For a description of functions that the VM core exports to interact
         with the JIT compiler, see section <a href=
         "#VM_exported_interfaces">3.13 Public Interfaces</a> .
      </p>
      <h3>
         4.7.2 JIT_EM INTERFACE
      </h3>
      <p>
         The JIT compiler exports this interface to support the execution
         manager. Functions of this set are responsible for the following
         operations:
      </p>
      <ul>
         <li>
            Compilation interface enabling the EM to request compilation of a
            method

         <li>
            Profile interface enabling the EM to request the JIT to collect or
            to use the specified profile type
   </ul>
      <p>
         For a description of the functions that the execution manager exports
         to interact with the JIT compiler, see section <a href="#EM_JIT">5.5.2
         EM_JIT Interface</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="JET_introduction"></a>4.8 JITRINO.JET
      </h2>
      <p>
         The Jitrino.JET baseline compiler is the Jitrino subcomponent used for
         translating Java<a href="#*">*</a> bytecode into native code with
         practically no optimizations. The compiler emulates operations of
         stack-based machine using a combination of the native stack and
         registers.
      </p>
      <p>
         Jitrino.JET performs two passes over bytecode, as shown in Figure 16.
         During the first pass, Jitrino.JET establishes basic block boundaries
         and generates native code during the second.
      </p>
      <p align="center">
         <img src="images/bytecode_to_native.gif" alt=
         "Two-pass convertion from bytecode to native code. ">
      </p>
      <p class="special">
         Figure 16: Baseline Compilation Path
      </p>
      <p>
         Subsequent sections provide a description of these passes.
      </p>
      <h3>
         4.8.1. Baseline Compilation: Pass 1
      </h3>
      <p>
         During the first pass over the method&rsquo;s bytecode, the compiler
         finds basic block boundaries and counts references for these blocks.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The <em>reference count</em> is the number of ways for reaching a
         basic block (BB).
      </p>
      <p>
         To find basic blocks boundaries, Jitrino.JET does a linear scan over
         the bytecode and analyses instructions, as follows:
      </p>
      <ul>
         <li>
            Instructions <code>athrow</code>, <code>return</code>,
            <code>goto</code>, <code>conditional branches</code>,
            <code>switches</code>, <code>ret</code>, and <code>jsr</code> end a
            basic block.

         <li>
            <em>Basic block leader</em> instructions immediately follow the
            instructions ending a basic block or serve as targets for branches.
            Exception handler entries are also among the basic block leaders.

      </ul>
      <p>
         During the first pass, the compiler also finds the reference count for
         each block. Jitrino.JET then uses the reference count during code
         generation to reduce the number of memory transfers.
      </p>
      <dl>
         <dt>
            Example
         </dt>
         <dd>
            Figure 17 illustrates an example with reference counts. The
            reference count <code>ref_count</code> for the second basic block
            (BB2) is equal to <code>1</code> because this block can only be
            reached from the first basic block (BB1). The other reference count
            is equal to <code>2</code> , because the third basic block can be
            reached as a branch target from BB1 or a fall-through from BB2.
         </dd>
      </dl>
      <p align="center">
         <img src="images/reference_count.gif" alt=
         "Example of reference counters reached from different basic blocks. ">
      </p>
      <p class="special">
         Figure 17: Basic Blocks Reference Count
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         4.8.2 Baseline Compilation: Pass 2
      </h3>
      <p>
         During the second pass, Jitrino.JET performs the code generation by
         doing the following:
      </p>
      <ol>
         <li>
            Walks over the basic blocks found at Pass 1 in the depth-first
            search order

         <li>
            Mimics Java<a href="#*">*</a> operand stack

         <li>
            Generates code for each bytecode instruction

         <li>
            Matches the native code layout and the bytecode layout

         <li>
            Updates relative addressing instructions, such as <code>CALL</code>
            and <code>JMP</code> instructions.

      </ol>
      <p>
         During code generation, Jitrino.JET performs register allocation by
         using an original technique of vCRC (virtual cyclic register cache),
         as described below.
      </p>
      <h3>
         4.8.3 Virtual Cyclic Register Cache
      </h3>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p>
         As it was mentioned in the <a href=
         "#JET_introduction">introduction</a>, Jitrino.JET simulates
         stack-based machine operations with the aid of the <em>virtual cyclic
         register cache</em> (vCRC).
      </p>
      <p>
         Because all the operations involve only the top of the operand stack,
         keeping it on the registers significantly reduces the number of memory
         access operations and improves performance. Even a small amount of
         registers is significant. For example, the average stack depth for
         methods executed during the SpecJVM98 benchmark is only 3.
      </p>
      <p class="class">
         vCRC: Basic Algorithm
      </p>
      <p>
         This section is an overview of the major idea behind vCRC.
      </p>
      <p>
         As shown in Figure 18, the position of the item is counted from the
         bottom of the stack and does not change over time. In contrast to the
         position, the depth of an item is counted from the top of the stack
         and is a relative value.
      </p>
      <p align="center">
         <img src="images/operand_depth.gif" alt=
         "Operands on the Stack with their position and depth indicated">
      </p>
      <p class="special">
         Figure 18: Depth and Position on the Operand Stack
      </p>
      <p>
         The position can provide the following mapping between a registers
         array and the operands&#39; positions in the operand stack:
      </p>
      <p align="center">
         <strong>POSITION % NUMBER_OF_REGISTERS =&gt; Register#</strong>
      </p>
      <p>
         A simple tracking algorithm detects overflows and loads or unloads
         registers when necessary.
      </p>
      <dl>
         <dt>
            Example
         </dt>
         <dd>
            Figure 19 illustrates an example, where the first 3 operations
            occupy 3 registers allocated to keep the top of the operand stack.
            The next operation <code>iconst_4</code> has no register available,
            which causes the first item <code>int32 (1)</code> to get spilled
            to the memory. The register <code>EAX</code> is now free and can
            store the new item.
         </dd>
      </dl>
      <p align="center">
         <code>REGISTERS[3] = {EAX, EBX, ECX}</code><br>
          <img src="images/operand_to_memory.gif" alt=
         "When more registered are required that are available, a register is freed to store another operand">
      </p>
      <p class="special">
         Figure 19: Saving Operand to Memory, Register Re-used
      </p>
      <p>
         With this algorithm, the topmost items are always on registers
         regardless of the number of operands stored on the stack, and the
         system does not need to access memory to operate with the top of the
         stack.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p class="class">
         vCRC: Virtual Stacks
      </p>
      <p>
         The basic algorithm cannot be applied directly. For example, on IA-32,
         storing a floating-point double value of 64 bits on general-purpose
         registers uselessly occupies 2 registers. Operations with
         floating-point values on general-purpose registers are non-trivial and
         mostly useless.
      </p>
      <p>
         Technically speaking, vCRC allows tracking positions for operands of
         the different types as if they were in different virtual stacks.
         Different virtual operand stacks are mapped on different sets of
         registers, as follows:
      </p>
      <ul>
         <li>
            Integer values, objects, and long values go to general-purpose
            registers

         <li>
            Float and double values go to XMM registers [<a href=
            "#intel_manual_ref">10</a>]

      </ul>
      <p>
         Figure 20 provides an example of different operand types on the
         operand stack for an IA-32 platform.
      </p>
      <p align="center">
         <img src="images/vCRC.gif" alt=
         "Different Operand Types tracked separately on the operand stack">
      </p>
      <p class="special">
         Figure 20: Virtual Operand Stacks
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p class="class">
         4.8.4 Java<a href="#*">*</a> Method Frame Mimic
      </p>
      <p>
         During the code generation phase, the state of the method stack frame
         is mimic:
      </p>
      <ul>
         <li>
            The exact state of the operand stack is known for each bytecode
            instruction.

         <li>
            No information is available about the local variables state at the
            beginning of the generation of a basic block.

      </ul>
      <p>
         When code generation for a basic block starts, the reference count
         determines the actions taken, as indicated in the table below.
      </p>
      <table border="0">
         <tr>
            <td class="TableHeading">
               Reference Count
            </td>
            <td class="TableHeading">
               Actions
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               <code>ref_count &gt; 1</code>
            </td>
            <td class="TableCell">
               Local variables are taken from the memory.<br>
                Top of the stack is expected to be on the appropriate
               registers.
            </td>
         </tr>
         <tr>
            <td align="center" class="TableCell">
               <code>ref_count = 1</code>
            </td>
            <td class="TableCell">
               Information on local variables state and stack state is
               inherited from the previous basic block.
            </td>
         </tr>
         <tr>
            <td class="TableCell">
               <code>ref_count = 0</code>
            </td>
            <td class="TableCell">
               Dead code, must not be here.
            </td>
         </tr>
      </table>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p class="class">
         4.8.5 Run-time Support for Generated Code
      </p>
      <p>
         To support run-time operations, such as stack unwinding, root set
         enumeration, and mapping between bytecode and native code, a specific
         structure, the <em>method info block</em>, is prepared and stored for
         each method during Pass 2.
      </p>
      <p>
         At run time, special fields are also pre-allocated on the native stack
         of the method to store GC information, namely the stack depth, stack
         <a href="#GC_map">GC map</a>, and locals GC map.
      </p>
      <p>
         The GC map shows whether the local variables or the stack slots
         contain an object. The GC map for local variables is updated on each
         defining operation with a local slot, as follows:
      </p>
      <ul>
         <li>
            If an object is stored, the appropriate bit in the GC map is set
            (code is generated to set the bit)

         <li>
            If a number is stored, the appropriate bit gets cleared.

      </ul>
      <p>
         The GC map for the stack is updated only at GC points, that is before
         an instruction that may lead to a GC event for example, a VM helpers
         call. The stack depth and the stack state calculated during
         method&rsquo;s compilation get saved before invocation: code is
         generated to save the state.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="EM"></a>5. Execution Manager
      </h1>
      <p>
         The <em>execution manager</em> (EM) is the central part of the DRLVM
         dynamic optimization subsystem. <em>Dynamic optimization</em> is the
         process of modifying compilation and execution time parameters in a
         system at run time. Optimization of compiled code may result to
         recompilation of managed method code. In this system, the execution
         manager makes decisions for optimization based on the profiles that
         are collected by <em>profile collectors</em>. Every profile contains
         specific optimization data and is associated with the method code
         compiled by a particular JIT.
      </p>
      <p>
         The key functions of the execution manager are the following:
      </p>
      <ul>
         <li>
            Instantiate execution engines: JIT compilers or the interpreter

         <li>
            Instantiate and configure profile collectors

         <li>
            Configure execution engines to enable using profile collectors

         <li>
            Defines the (re)compilation and dynamic optimization
            logic using method profiles

      </ul>
      <p>
         The features of the DRL execution manager include the following:
      </p>
      <ul>
         <li>
            Clear interfaces to plug in new profile collectors and execution
            engines

         <li>
            Profile access interface to request method profiles

         <li>
            Support for time-based sampling profile collectors

         <li>
            Configurable selection of an execution engine per method by using
            method filters

         <li>
            Configurable recompilation scenarios

      </ul>
      <h2>
         <a name="EM_architecture"></a>5.1 ARCHITECTURE
      </h2>
      <p>
         The VM core creates the execution manager before loading an execution
         engine. Depending on the configuration, the execution manager
         initializes execution engines and <a href="#PC">profile
         collectors</a>.
      </p>
      <p>
         During JIT compiler instantiation, the execution manager provides the
         JIT with a name and a run-time JIT handle. The JIT can use this name
         to distinguish its persistent settings from settings of other
         execution engines. The compiler can also use the handle to distinguish
         itself from other JIT compilers at run time.
      </p>
      <p>
         The EM also configures the JIT to generate a new profile or to use an
         existing profile via the profile access interface. This interface
         enables accessing profile collectors and their custom interfaces.
         Every profile collector uses its properties to check, whether the JIT
         that generating a profile and the JIT that will use the generated
         profile are profile-compatible compilers. For example, for the edge
         profile, the profile collector can check compatibility using the
         feedback point and IR-level compatibility properties. During its
         initialization, the JIT compiler accepts or rejects profile collection
         and usage.
      </p>
      <p align="center">
         <img src="images/EM_interfaces.gif" alt=
         "Interaction between Execution Manager, JIT, and VM">
      </p>
      <p class="special">
         Figure 21. Execution Manager Interfaces
      </p>
      <p class="notetext">
         In the figure, several blocks of the same type identify instances of
         the same component, as in the case with profile collectors and JIT
         compilers. For details on interfaces displayed in the figure, see
         section <a href="#EM_Interfaces">5.5 EM Public Interfaces</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Recompilation"></a>5.2 RECOMPILATION MODEL
      </h2>
      <p>
         <em>Recompilation chain</em> is the central entity of the EM
         recompilation model. This chain can connect multiple
         profile-compatible JIT compilers into a single recompilation queue. To
         compile a method for the first time, the execution manager calls the
         first JIT compiler in the chain. After profiling information about the
         method is collected, the next JIT in the chain is ready to recompile the method
         applying more aggressive optimizations. The data from method
         profile can be used during method recompilation to adjust custom
         optimizations parameters.
      </p>
      <p>
         If multiple recompilation chains co-exist at run time, the EM selects
         the appropriate recompilation chain to initially compile a method.
         Method filters associated with chains can configure the execution
         manager to use a specific chain for method compilation. Method filters
         can identify a method by its name, class name, signature or ordinal
         compilation number.
      </p>
      <p>
         Within this model, the execution of a method goes as follows:
      </p>
      <ol>
         <li>
            The virtual machine calls the EM to execute a method.

         <li>
            The execution manager uses method filters to select the appropriate
            recompilation chain.

         <li>
            The execution manager instructs the first JIT in the chain to
            compile a method.

         <li>
            After the method is compiled, the virtual machine proceeds with its
            execution.

         <li>
            <font face="Arial" size="2"><span lang="EN-US" style="FONT-SIZE:
            10pt; FONT-FAMILY: Arial">The EM checks, whether the method is hot.
            For hot methods, the EM initiates recompilation by the next JIT in
            the compilation chain.</span></font>
      </ol>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         A method is <em>hot</em> when a profile associated with it satisfies specific
		 parameters in the PC configuration settings. For example, for an entry and back-edge
		 profile collector, these parameters are the entry and back-edge counters' limits.
		 When a counter value  reaches the limit, the method becomes hot.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="PC"></a>5.3 Profile Collector
      </h2>
      <p>
         The <em>profile collector</em> (PC) is the execution manager
         subcomponent that collects profiles for Java<a href="#*">*</a> methods
         compiled by the JIT or executed by the interpreter. The DRL EM
         instantiates and configures profile collectors according to the settings of its
         configuration file.
      </p>
      <p>
         The profile collector can collect method profiles only for the methods
         compiled by the same JIT. To collect the same type of profile
         information for methods compiled by different JIT compilers, the EM
         uses different PC instances.
      </p>
      <p>
         After the PC collects a method profile, subsequent JIT compilers in
         the recompilation chain can reuse this profile. An execution engine is
         allowed to use a method profile in case the configuration file
         indicates that this JIT can use the profile. The EM defines the
         <em>JIT role</em>, that is, configures the JIT compiler to generate or
         to use a specific profile in the file <code>include/open/em.h</code> using
         the following format:
      </p>
      <pre>
enum EM_JIT_PC_Role {
  EM_JIT_PROFILE_ROLE_GEN=1,
  EM_JIT_PROFILE_ROLE_USE=2
  };
</pre>
      <p>
         With this model, instances of the compiler work independently of each
         other at run time. The JIT compiler can always use the PC handle to
         access the profile data that is assigned to be collected or to be used
         by this JIT compiler.<br>
          The profile collector does not trigger method recompilation. Instead,
         the PC notifies the execution manager that a method profile is ready
         according to a configuration passed from the EM during profile
         collector initialization. After that, the EM initiates recompilation
         of the method, if necessary.
      </p>
      <h2>
         <a name="Profiler_thread"></a>5.4 Profiler Thread
      </h2>
      <p>
         To check readiness of a method profile and to recompile hot methods,
         the execution manager requires a special thread created by the VM
         core. This thread must be an ordinary Java<a href="#*">*</a> thread,
         because method compilation may result in execution of JIT-compiled
         code during class resolution or side-effect analysis.
      </p>
      <p>
         The execution manager uses the recompilation thread created by the VM
         after loading all core classes and before executing the main method.
         The EM configures this thread to call back in a specified period of
         time. During this callback, the EM can check profiles and run method
         recompilation as required.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="EM_interfaces"></a>5.5 Public Interfaces
      </h2>
      <p>
         The execution manager interacts with the virtual machine and JIT
         compilers by using specific interfaces. In addition to these external
         interfaces, the execution manager uses the internal interface to
         communicate with profile collectors.
      </p>
      <h3>
         <a name="EM_VM"></a>5.5.1 EM_VM Interface
      </h3>
      <p>
         The execution manager exports this interface to provide the VM with
         method compilation and execution functions. The virtual machine sends
         requests to the EM to execute a method. For that, the VM passes the
         method handle and parameters to the execution manager. The EM selects
         the JIT for compiling the method and runs method compilation and
         execution.
      </p>
      <h3>
         <a name="EM_JIT"></a>5.5.2 EM_JIT Interface
      </h3>
      <p>
         The execution manager exports this interface to enable JIT compilers
         to access method profiles. Via this interface, the JIT can gain access
         to a method profile or to the instance of the profile collector
         assigned to this JIT during initialization. The major part of
         <code>EM_JIT</code> is the <em>profile access interface</em>. By using
         this interface, the JIT compiler can access a custom profiler
         interface specific for a profile collectors family and then interacts
         directly with a specific profile collector.
      </p>
      <h3>
         5.5.3 Internal EM interfaces
      </h3>
      <p>
         The internal EM interfaces handle interaction between the execution
         manager and the profile collector. Via the <em>time-based sampling
         support interface</em> (TBS), the EM registers time-based sampling
         callbacks and configures thresholds of method profiles. The profile
         collector checks method profiles using this interface or the internal
         sampling method if the thresholds are reached. When the method profile
         is ready, the PC reports to the execution manager. The profile
         collector communicates with the EM via the <em>profile-related
         events</em> interface.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="GC"></a>6. Garbage Collector
      </h1>
      <p>
         The garbage collector (GC) component is responsible for allocation and
         reclamation of Java<a href="#*">*</a> objects in the heap. The garbage
         collector automatically reclaims the objects that cannot be reached and
         thus cannot influence the program behavior using <em>tracing
         techniques</em> to identify unreachable objects. The VM can allocate
         new objects in the space recycled by the GC.
      </p>
      <p>
         This component interacts with the VM core, the JIT compiler and the
         interpreter, the thread management functionality, and JIT-compiled
         code. The GC contacts the VM core to access data on the internal
         structure of objects, and uses several assumptions about data layout
         (see section <a href="#GC_assumptions">6.4 Data Layout
         Assumptions</a>).
      </p>
      <h2>
         <a name="GC_architecture"></a>6.1 Architecture
      </h2>
      <p>
         When the heap memory is exhausted, the garbage collector instructs the
         VM core to <a href="#Safe_suspension">safely suspend</a> all managed
         threads, determines the set of root references [<a href=
         "#GC_article2_ref">13</a>], performs the actual collection, and then
         resumes the threads.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The <em>root set</em> is the set of all pointers to Java<a href=
         "#*">*</a> objects and arrays that are on the Java<a href="#*">*</a>
         thread stacks and in static variables. These pointers are called
         <em>root references</em>. See [<a href="#GC_article2_ref">13</a>] for
         a detailed description of fundamentals of tracing garbage collection.
      </p>
      <p>
         The garbage collector relies on the VM core to <a href=
         "#Root_Set_Enumeration">enumerate the root set</a>. The VM core
         enumerates the global and thread-local references in the run-time data
         structures. The VM delegates the enumeration of the stack further to
         the execution engine, the JIT compiler or the interpreter. The GC then
         determines the set of reachable objects by tracing the reference
         graph.
      </p>
      <p>
         To improve efficiency of heap tracing and object allocation, space in
         the VTable is reserved to cache frequently accessed GC information. In
         the current design, the GC caches the object field layout as the list
         of offsets for the fields of reference types in the VTable.
      </p>
      <p>
         For details on garbage collection, see section <a href=
         "#GC_procedure">6.3 GC Procedure</a>.
      </p>
      <h3>
         <a name="GC_data_structures"></a>6.1.1 Block Structure of the  Heap
      </h3>
      <p>
         The garbage collector divides the managed heap into 128-KB blocks and
         stores the mark tables in the first 4 kilobytes of each block. The
         <em>mark table</em> contains one bit for each possible object location
         in the block. Because objects are aligned at the boundary of 4 bytes, any 4-bytes
		 aligned address could be the start of an object. That is why, a mark bit is
		 allocated for each 4-byte aligned location in the block.
	  </p>
      <p>At the start of garbage collection, the mark tables
           are filled with zeroes. During heap trace, the garbage collector identifies
           all live objects and inserts value <code>1</code> in the mark tables
           for these objects only. The mark bit location is computed from the object
		   address by subtracting the block start address and shifting to the right by 2 bits.
			Later, the garbage collector uses the mark
           table to reclaim space taken up by unreachable objects. Other GC data,
           such as free lists, is also stored in the first page of the block. See
           the definition of the <code>block_info</code> structure in <code>gc/src/gc_header.h</code> for more details. </p>
      <p>
         Objects greater than 62 KB use special kinds of blocks allocated
         contiguously to fit the object, <em>single object blocks</em>. The
         part of the last block, which results from the 128-KB alignment,
         remains unused.
      </p>
      <p>
         The collection of blocks used for large block allocation is the
         <em>large object space</em> (LOS).
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="heap_size"></a>6.1.2 Dynamic Heap Resize
      </h3>
      <p>
         In DRLVM, the size of the garbage collected heap can vary depending on
         system needs. The heap has three size characteristics: the current and
         the maximum  heap size, and the committed size.
      </p>
      <p class="class">
         Heap Size
      </p>
      <p>
         This parameter represents the amount of memory the GC uses for Java<a href="#*">*</a> object allocation. During
         normal operation, the GC starts garbage collection when the amount of
         allocated space reaches the heap size.
      </p>
      <p>
         You can specify the initial value of heap size using the
         <code>-Xms</code> command-line option.
      </p>
      <p>
         The default initial size is 64 MB. The GC can decide to change the
         current size after the garbage collection in the following conditions:
      </p>
      <ul>
         <li>
            The number of threads is greater than the current number of blocks.

         <li>
            Large object allocation cannot be satisfied without increasing the
            heap size.

         <li>
            The live set is greater than a half of the heap size.

      </ul>
      <p>
         If at least one condition is true, the garbage collector increases the
         heap to the minimum size that eliminates the condition provided that
         the new heap size does not exceed the maximum value. Additional space
         is committed immediately on heap resize to ensure that the required
         amount of physical memory is available.
      </p>
      <p class="class">
         Maximum Heap Size
      </p>
      <p>
         The garbage
         collector reserves the virtual memory corresponding to the maximum
         size at the VM startup.
You can specify the maximum size using the command-line option
      <code>&ndash;Xmx</code>. The default value is 256 MB. </p>
      <p class="class">
         Committed Size
      </p>
      <p>
         This parameter indicates the physical memory used by the heap. The
         committed size equals to zero at startup and grows dynamically when
         the garbage collector allocates new blocks in the heap memory. After
         reaching the current size, the allocation mechanism triggers garbage
         collection. The committed size grows by blocks when the GC starts a
         new memory block from the block store.
      </p>
      <p>
         On Windows<a href="#*">*</a>, the function
         <code>VirtualAlloc(&hellip;, MEM_COMMIT, &hellip;)</code> performs the
         commit operation. On Linux<a href="#*">*</a>, this operation is no-op
         because the operating system commits the pages automatically on the
         first access. The commit-as-you-go behavior ensures the smallest
         possible footprint when executing small applications.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         <a name="GC_assumptions"></a>6.1.3 Data Layout Assumptions
      </h3>
      <p>
         The GC interface includes an implicit agreement between the VM core
         and the garbage collector regarding the layout of certain data in
         memory. The garbage collector makes assumptions on the layout of objects as
      described below in terms of the <code>ManagedObject</code> data type to load the VTable for
	  an object without calling VM core functions. </p>
      <ul>
         <li> The GC uses the <code>obj_info</code> field to store a <a href="#GC_reclamation">forwarding
            pointer</a> while performing garbage collection and for other
            operations. This field is also used by the synchronization
            subsystem. During garbage collection the original content of the
            field is saved. Once GC completes, the original content is
            restored.

        <li>
            The garbage collector requires that the object field layout never
            changes at run time.

        <li>
            The VM core reserves space in each VTable for the garbage collector
            to cache type information required for garbage collection. This
            cached information is used in frequent operations such as <a href=
            "#mark_scan">scanning</a>, where calling the VM core is too costly.
            When the VM core loads and prepares a class, it calls the GC
            function <code>gc_class_prepared()</code> so that the garbage
            collector can obtain information needed from the VM core through
            the VM interface and can store the information in the VTable.

        <li>
            The VM core reserves space in thread-local storage for the garbage
            collector, and during thread creation calls the
            <code>gc_thread_init()</code> function to allow the garbage
            collector to initialize this space. The garbage collector typically
            stores a pointer to per-thread allocation areas in this space.

        <li>
            The garbage collector requires that arrays are laid out in a
            specific way. The GC can call a VM core function to obtain the
            offset of the length field in an array object, and for each array
            type, the offset of the first element of arrays of that type. The
            garbage collector also requires that the elements are laid out
            contiguously. Using these assumptions, the garbage collector can
            enumerate all references in an array without further interaction
            with the VM core.

      </ul>
      <h3>
         6.1.4 GC Worker Threads
      </h3>
      <p>
         On multiprocessor machines, the GC can use the advantage of multiple processors by
         parallelizing computationally intensive tasks. For that, the garbage
         collector uses special C <em>worker threads</em>. The GC creates
         worker threads during initialization sequence, one worker thread for
         each processor available.
      </p>
      <p>
         Most of the time, worker threads sleep waiting for the task. The GC
         controlling thread assigns the tasks for worker threads by sending an
         event. Once the task is received, the worker threads start their
         activity. While workers are busy, the GC controlling thread waits for
         the completion of the task. When all worker threads complete the
         assigned task, the controlling thread resumes execution and worker
         threads get suspended waiting for a new task.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="GC_procedure"></a>6.2 GC Procedure
      </h2>
      <p>
         In the current implementation, the garbage collector uses the
         <i>mark-sweep-compact stop-the-world collection mechanism</i> [<a
         href="#Wilson_GC_Ref">18</a>], [<a href=
         "#Venners_Inside_VM_ref">19</a>]. The sections below provide details
         on garbage collection in DRLVM at each stage of the process.
      </p>
      <ol>
         <li>
            <p class="class">
               Triggering garbage collection
            </p>
            <p>
               Garbage collection can be triggered by exhaustion of memory
               in the current heap or forced by the
               <code>System.gc()</code> method.
            </p>

         <li>
            <p class="class">
               Obtaining the GC lock
            </p>
            <p>
               Each user thread, which determined that the collection needs to
               be performed, tries to obtain a GC lock by calling the
               <code>vm_gc_lock_enum()</code> function. Only one thread
               succeeds and becomes the <i>GC controlling thread</i>. Other
               threads remain blocked at the <code>vm_gc_lock_enum()</code>
               function call, that is, remain suspended in
               <code>gc_alloc()</code> until the collection completes. After
               the thread manages to get the GC lock, it checks whether another
               thread has already performed the collection.
            </p>

         <li>
            <p class="class">
               Enumerating the root set
            </p>
            <p>
               After the controlling thread gets the lock and checks that the collection is still necessary, the
               thread resets GC global data by clearing the root set array and
               reference lists. Next, the thread calls the
               <code>vm_enumerate_root_set_all_threads()</code> function to
               make the core virtual machine enumerate the root heap pointers.
               In response, the VM suspends all threads and enumerates the root
               set by using the functions <code>gc_add_root_set_entry()</code>,
               <code>gc_add_compressed_root_set_entry()</code>, and others. The
               garbage collector records the root pointers in the root set
               array as the enumeration proceeds.
            </p>

         <li>
            <p class="class">
               Verification trace
            </p>
            <p>
               If the collector is built with debugging code enabled, the
               verification trace is performed after the full root set
               enumeration. This operation verifies that the roots set and heap
               are in consistent state, that is, all pointers into Java<a href=
               "#*">*</a> heap point to the valid Java<a href="#*">*</a>
               objects and no dangling pointers exist.<br>
                The garbage collector marks traced objects using the object
               header bit instead of regular mark tables in order to prevent
               interference with regular GC operation. The verification trace
               procedure uses <a href="#Monitors">the eighth bit</a>
               <code>(0x80)</code> of the object <code>lockword</code> (<a
               href="#object_layout"><code>obj_info</code></a> word) for
               marking. At the end of the verification trace, the GC prints the
               number of objects found to be strongly reachable during the
               trace operation.
            </p>

         <li>
            <p class="class">
               <a name="mark_scan"></a>Mark scan
            </p>
            <P>During the mark scan stage, the GC identifies all objects reachable from the root set.
			 The GC maintains the <I>mark stack</I>, a stack of objects reached during tracing but not scanned yet.
			 The GC repeatedly removes an object from the mark stack and scans all reference fields of the objects.
			 For each reference field, the GC tries to mark an object that the field points to
			 and, if mark operation succeeds, adds the object pointer to the mark stack.
			 The GC continues scanning objects from the mark stack until it is empty.</P>

              <p>Mark scan activity runs in parallel on worker threads, one thread per processor. Each
                 worker thread atomically grabs one root from the root set array
                 and traces all objects reachable from that root by using its own private mark stack.
				 Worker threads mark objects by using the atomic compare and swap operation on
				 the corresponding byte in the mark table. The mark
                 operation failure indicates that another worker thread has
                 marked the object earlier, and is responsible for scanning it.
              </p>
              <dl>
               <dt>
                  <a name="GC_finalizable_objects"></a>Finalizable Objects and
                    Weak References
               </dt>
            </dl>
            <p class="notetext">
               By the end of the mark scan operation, all strongly reachable
               objects are marked and the garbage collector deals with
               collected reference objects and weak roots. Complying to the
               Java<a href="#*">*</a> API specification [<a href=
               "#Java_api_ref">6</a>], the GC maintains the strength of weak
                 references by going through soft, weak, and then phantom
                 reference objects in this specific order.
            </p>
            <p class="note">
               Note
            </p>
            <p class="notetext">
               The current implementation treats soft references as weak
               references, and clears soft referents when they become softly
               reachable.
            </p>
            <p class="notetext">
               To ensure that finalizable objects are not reclaimed before the
               <code>finalize()</code> method is run, the GC uses the
                 finalizable queue as an additional root set and restarts the
                 mark scan process to transitively mark objects reachable from
                 finalizable objects. This increases the number of live objects
                 during collection. For details on handling finalizable objects
                 in the DRL virtual machine, see section <a href=
               "#Finalization">2.7 Finalization</a>.
            </p>
            <p class="note">
               Note
            </p>
            <p class="notetext">
               According to the JVM specification [<a href=
               "#JVM_spec_ref">1</a>], objects are only included into the
                 finalizable queue during <a href="#Object_Allocation">object
                 allocation</a> and not after they are scheduled for
                 finalization.
            </p>
            <p class="notetext">
               The <code>finalize()</code> method is not run during garbage
                 collection. Instead, the GC puts finalizable objects to a separate
                 queue for later finalization.
            </p>
         <li>
            <p class="class">
               Reclamation of unmarked objects
            </p>
            <p>
               Once all the references and finalizable objects have been
               visited, the GC has a list of all reachable objects. In other
               words, any object that remains unmarked at this stage can safely
               be reclaimed.
            </p>
            <dl>
               <dt>
                  <a name="GC_reclamation"></a>Reclamation by Compaction and
                  Sweep
               </dt>
            </dl>
            <p class="notetext">
               Reclamation of unmarked objects can be performed in two ways:
               compaction and sweep. Compaction is preferable because it
               improves the object locality and keeps fragmentation at a low
               level. However, compaction does not cover the objects declared
               pinned during enumeration, and large objects because of high
               costs of copying.
            </p>
            <p class="notetext">
               <i>Compaction</i> is performed block-wise in several stages. All
               blocks that contain pinned objects and blocks with large objects
               are excluded, see the files <code>include/open/gc.h</code> and <code>include/open/vm_gc.h</code>
			   for more information. During compaction, the GC does the following:
            </p>
            <ol>
               <li class="notetext">
                  Calculates the new locations of compacted objects and
                  installs forwarding pointers in the object headers in the
                  <code>obj_info</code> word.<br>
                   Non-zero values of <code>obj_info</code> are saved. The GC
                  sets the new locations by sliding live objects to the lower
                  addresses in order to maintain allocation ordering.
                  <p class="note">
                     Note
                  </p>
                  <p class="notetext">
                     The pointer to the new object location, which is written
                     in the old object copy, is the <em>forwarding
                     pointer.</em>
                  </p>

               <li class="notetext">
                  Updates all slots pointing to compaction areas by using the
                  forwarding pointers.<br>
                   The GC uses the lists of slots collected beforehand during
                  the mark scan phase.

               <li class="notetext">
                  Copies the objects to their target destinations.

               <li class="notetext">
                  Restores the headers overwritten with forwarding pointers.

            </ol>
            <p class="notetext">
               <i>Sweep</i> is performed on blocks that were not compacted and
               objects in the large object space. The GC scans the array of
               mark bits to find sufficiently long zero sequences. The garbage
               collector ignores zero sequences that represent less than 2 KB
               of the Java<a href="#*">*</a> heap. Longer free areas are linked
               to the free list structure and used for object allocation. The
               GC does not perform the sweep operation during the
               stop-the-world pause. Instead, the GC sweeps the block just
               before using it for allocating new objects.
            </p>

         <li>
            <p class="class">
               Final stage of garbage collection
            </p>
            <p>
               At this stage, the object reclamation is complete. In the
               debugging mode, the GC performs the second verification trace
               and can optionally print the number of live objects. The GC
               provides the virtual machine with the list of objects scheduled
               for the <code>finalize()</code> method run and references
               scheduled for an <code>enqueue()</code> method run. Finally, the
               GC commands the VM to resume the user threads and finishes the
               collection.
            </p>

         <li>
            <p class="class">
               Iteration
            </p>
            <p>
               In case garbage collection was triggered by allocation, the
               garbage collector retries to allocate the object. If the
               allocation fails a second time, the garbage collector repeats
               the GC procedure. In case the allocation fails for two
               iterations, an <code>OutOfMemoryError</code> condition is
               reported. For details on allocation techniques, see
               section <a href="#Object_Allocation">6.3 Object Allocation</a>.
            </p>

      </ol>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Object_Allocation"></a>6.3 Object Allocation
      </h2>
      <p>
         The DRL garbage collector provides several object allocation
         mechanisms to improve performance. Below is the description of
         ordinary and optimized object allocation procedures.
      </p>
      <p>
         The <code>gc_alloc()</code> and <code>gc_alloc_fast()</code> functions
         are the key functions in object allocation. The
         <code>gc_alloc()</code> function may trigger garbage collection to
         satisfy allocation, and the <code>gc_alloc_fast()</code> function is
         not allowed to do so. The garbage collector also provides other
         functions that handle specific types of object allocation or optimize
         the allocation procedure, as follows:
      </p>
      <ul>
         <li>
            <code>gc_alloc()</code> function follows the ordinary allocation
            path with no optimizations. This function returns the pointer to
            the allocated object, or <code>NULL</code> if the object cannot be
            allocated even after garbage collection. The caller of the
            <code>gc_alloc()</code> function throws an <code>OutOfMemoryError</code> condition in
            case of <code>NULL</code> return value. The potential necessity to
            enumerate the root set or to throw an exception requires the VM to
            push an <a href="#M2nFrame">M2nFrame</a> before calling <code>gc_alloc()</code>.
         <li>
            <code>gc_alloc_fast()</code> function is called when the expensive overhead
			of an M2nFrame is not required. This is
            the common case because typically a request for new space is
            granted. Only if the function returns <code>NULL</code>, the VM
            pushes the M2nFrame and calls the slower <code>gc_alloc()</code>.

         <li>
            <code>gc_supports_frontier_allocation()</code> function handles
            frontier allocation, the fastest allocation method. In-lined
            allocation fast path optimizes allocation, but, unlike
            <code>gc_alloc()</code> and <code>gc_alloc_fast()</code>, this
            function cannot handle finalizable objects correctly. A special
            trick with overloading object size must be used.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               Currently, Jitrino does not use frontier allocation.
            </p>

         <li>
            <code>gc_alloc_pinned()</code> allocates permanently pinned
            objects.

         <li>
            <code>gc_pinned_malloc_noclass()</code> function provides pinned
            allocation services at VM initialization stage.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               The VM does not currently use functions
               <code>gc_alloc_pinned()</code> and
               <code>gc_pinned_malloc_noclass()</code>.
            </p>

      </ul>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p class="class">
         Allocation Procedure
      </p>
      <p>
         The <code>gc_alloc()</code> and <code>gc_alloc_fast()</code> functions
         do the following in the specified order:
      </p>
      <ol>
         <li>
            Try to allocate the object from the current allocation area.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               An <em>allocation area</em> is a contiguous section of free
               space suitable for bump (frontier) allocation. The GC recreates
               allocation areas in the blocks after each garbage collection.
               Allocation areas range from 2 KB to 124 KB in size. Areas of
               size less than 2 KB are ignored to prevent degradation of
               allocation performance. The maximum allocation area size is
               determined by the block size.
            </p>

         <li>
            If allocation in the current area fails, move to the next
            allocation area and retry step 1.

         <li>
            If allocation in the current block fails, move to the next block in
            the chunk and retry steps 1 and 2.
            <p class="note">
               Note
            </p>
            <p class="notetext">
               A <em>chunk</em> is a linked list of blocks. After the garbage
               collection all memory chunks are freed. To avoid race conditions
               between multiple Java<a href="#*">*</a> threads, chunks are
               removed from the chunk queue atomically. These chunks can then
               be used by the owning thread without further synchronization.
            </p>

         <li>
            After exhausting the current thread chunk, the
            <code>gc_alloc()</code> and <code>gc_alloc_fast()</code> functions
            follow different procedures:
            <ol>
               <li type="a">
                  The <code>gc_alloc()</code> function attempts to grab new
                  chunks from the master chunk list. If this fails, the thread
                  tries to take the GC lock, collect garbage, and restart the
                  allocation procedure. After two garbage collections fail, the
                  <code>gc_alloc()</code> function returns <code>NULL</code>,
                  which produces an out of memory error.

               <li type="a">
                  The <code>gc_alloc_fast()</code> function returns
                  <code>NULL</code> immediately after allocation from current
                  chunk fails. The function never tries to use another memory
                  chunk.

            </ol>

      </ol>
      <p>
         To start garbage collection from <code>gc_alloc()</code>, the VM needs
         to enumerate the root set for the thread that called
         <code>gc_alloc()</code>, and this requires pushing an M2nFrame on the
         stack. Because few allocations fail and trigger garbage collection,
         the effort of pushing an M2nFrame is often wasted. To avoid this, the
         thread invokes the <code>gc_alloc_fast()</code> function without an
         M2nFrame and cannot start garbage collection.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="GC_Exported_Interfaces"></a>6.4 Public Interfaces
      </h2>
      <p>
         This section lists the interfaces the garbage collector exports for
         communication with other components.
      </p>
      <h3>
         6.4.1 GC Interface
      </h3>
      <p>
         The garbage collector provides a number of interface functions to
         support DRLVM activity at various stages, as follows:
      </p>
      <p class="class">
         Handshaking at DRLVM startup
      </p>
      <p>
         The GC exposes several groups of functions that support different
         startup operations, as described below.
      </p>
      <ul>
         <li>
            The VM core and the JIT call the GC interface function
            <code>gc_requires_barriers()</code> to determine whether the
            garbage collector requires write barriers. The current GC
            implementation does not require write barriers.
            <dl>
               <dt>
                  Background
               </dt>
            </dl>
            <p class="notetext">
               <i><a name="Write_barriers"></a>Write barriers</i> can be used
               for generational incremental collection, and concurrent garbage
               collection techniques to track the root sets of portions of the
               heap that are targeted for collection. In case the garbage
               collector requires write barriers, the JIT generates calls to
               the GC function <code>gc_write_barrier()</code> after the
               references are stored into an object field [<a href=
               "#GC_article2_ref">13</a>].

            </p>
        <li>
            The VM core calls the function
            <code>gc_supports_compressed_references()</code> to find out,
            whether the GC compresses reference fields and VTable pointers. If
            the configuration of the VM core or the JIT differs from the GC
            configuration, for example, GC compresses references, while VM and
            the JIT do not, an error message is printed and the VM process is
            terminated. For details on compression techniques, see section <a
            href="#compressed_references">2.4.2 Compressed References</a>

        <li>
            The VM core calls the
            <code>gc_supports_frontier_allocation()</code> function to find
            out, whether the GC supports fast thread-local allocation. Fast
            thread-local allocation, the same as <em>bump allocation</em> or
            <em>frontier allocation</em>, increases the current pointer and
            compares it to the ceiling pointer. If the GC supports fast
            allocation, the function returns the offsets of current and ceiling
            pointers in GC thread-local data.

      </ul>
      <p class="class">
         <a name="gc_init"></a>Initializing the Garbage Collector
      </p>
      <p>
         The VM core calls the <code>gc_init()</code> function to initialize
         the garbage collector. In this function, the GC does the following:
      </p>
      <ol>
         <li>
            Uses the VM property mechanism to read GC-specific configuration
            options from the application command line. The GC calls the
            <code>vm_get_ property()</code> function to query configuration
            options that may have been specified on the command line. For
            example, the heap size parameters are passed to the GC as values of
            the properties <code>gc.ms</code> and <code>gc.mx</code> for
            initial and maximum heap size parameters respectively.

         <li>
            Allocates the managed heap and prepares to serve memory allocation
            requests.

         <li>
            Creates a GC worker thread for each available processor. GC worker
            threads wait until the controlling thread wakes the threads for
            parallel-mode collection activities, for example, for mark scanning
            and compaction.

      </ol>
      <p>
         After these actions, the garbage collector returns from function
         <code>gc_init()</code>, and the VM initialization sequence continues.
         After the call to <code>gc_init()</code>, the VM starts allocating
         Java<a href="#*">*</a> objects, but garbage collection is disabled
         until the end of the VM initialization procedure.<br>
          Finally, the virtual machine calls the
         <code>gc_vm_initialized()</code> function to inform the garbage
         collector that the VM core is sufficiently initialized to enumerate
         roots, and that garbage collection is permitted. The VM can allocate a
         moderate amount of objects between the calls to <code>gc_init()</code>
         and <code>gc_vm_initialized()</code>.
      </p>
      <p class="class">
         Class Loading and Creating a Thread
      </p>
      <p>
         The VM core calls the functions <code>gc_class_prepared()</code> and
         <code>gc_thread_init()</code>. The function
         <code>gc_thread_init()</code> assigns a private allocation to a
         thread. The function <code>gc_class_prepared()</code> caches the field
         layout information in the <a href="#vtable">VTable structure</a>.
      </p>
      <p class="class">
         Managed Object Allocation
      </p>
      <p>
         To allocate a new object,  JIT-compiled code or native methods call
         the <code>gc_alloc()</code> or <code>gc_alloc_fast()</code> functions
         in the GC interface. If the heap space is exhausted, the garbage
         collector stops all managed threads and performs the garbage
         collection. To allocate an object, the GC can use one of several
         available functions, as described in section <a href=
         "#Object_Allocation">6.3 Object Allocation</a>.
      </p>
      <p class="class">
         Root Set Enumeration
      </p>
      <p>
         The <code>gc_add_root_set_entry()</code> function and several similar
         functions support this operation on the GC side.
      </p>
      <p class="class">
         Virtual Machine Shutdown
      </p>
      <p>
         The VM core calls the <code>gc_wrapup()</code> function to tell the GC
         that the managed heap is no longer required. In response, the GC frees
         the heap and other auxiliary data structures.
      </p>
      <p>
         Other interface groups include functions for forcing garbage
         collection and querying information about available memory and details
         of the garbage collection operation.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h3>
         6.4.2 VM_GC interface
      </h3>
      <p>
         The VM implements the several groups of functions to support GC
         operation as described below. The functions of this interface are
         grouped by the period of operation, during which they are activated.
      </p>
      <p class="class">
         Collection Time
      </p>
      <p>
         The VM core exposes the following functions to support garbage
         collection:
      </p>
      <ul>
         <li>
            <code>vm_gc_lock_enum()</code> and <code>vm_gc_unlock_enum()</code>
            provide global GC locking services. The global GC lock determines
            the thread to run the garbage collection. The VM also protects
            thread structure modifications by using this lock, because the
            threads blocked on the global GC lock are considered to be <a href=
            "#Safe_suspension">suspended safely</a> for the purpose of garbage
            collection.

         <li>
            <code>vm_enumerate_root_set_all_threads()</code> suspends all
            Java<a href="#*">*</a> threads and enumerates their root set, which
            is used at the beginning of the stop-the-world phase of garbage
            collection.

         <li>
            <code>vm_resume_threads_after()</code> performs the opposite
            operation: resumes the suspended threads and ends the
            stop-the-world phase.

         <li>
            <code>vm_classloader_iterate_objects()</code> notifies the VM that
            the GC is ready to iterate the live objects during the
            stop-the-world phase.

         <li>
            <code>vm_hint_finalize()</code> informs the VM core that objects
            awaiting finalization may have been found during the garbage
            collection.<br>
             Normally, the <code>vm_hint_finalize()</code> function wakes up <a
            href="#Finalization">finalizer threads</a>. The GC can also call
            this function during normal operation in case the number of
            finalizable objects is rapidly growing. The finalization subsystem
            performs load balancing by increasing the number of finalizer
            threads in case the size of finalization queue exceeds a pre-set
            threshold. The VM provides the function
            <code>is_it_finalize_thread()</code> to let the GC differentiate
            its service for different threads.

         <li>
            <code>get_global_safepoint_status()</code> indicates whether
            garbage collection is in progress.

      </ul>
      <p class="class">
         Finalization and Weak Reference Handling
      </p>
      <p>
         The GC handles weak reference objects differently from regular
         objects. When preparing GC data about a class in
         <code>gc_class_prepared()</code>, the GC uses the function
         <code>class_is_reference()</code> to find out, whether the objects of
         this class require special handling. The GC calls
         <code>class_get_referent_offset()</code> to get the offset of the
         referent field with weak reference properties.
      </p>
      <p>
         During the garbage collection, the GC finds the objects that need to
         be finalized and resets weak references. The GC does not execute
         Java<a href="#*">*</a> code, but transfers the set of finalizable
         objects and reference objects to the VM by using the functions
         <code>vm_finalize_object()</code> and
         <code>vm_enqueue_reference()</code>.
      </p>
      <p class="class">
         Handshaking at VM Startup
      </p>
      <p>
         At this stage, the GC uses the following functions exposed by the VM
         core:
      </p>
      <ul>
         <li>
            <code>vm_number_of_gc_bytes_in_vtable()</code> returning the number
            of bytes that the VM reserves for GC use at the beginning of each
            VTable structure.

         <li>
            <code>vm_number_of_gc_bytes_in_thread_local()</code> returning the
            number of bytes that the VM reserves in the thread structure.<br>
             The details of managing thread-local data are encapsulated by the
            VM. The VM provides the thread pointer for all GC functions that
            use thread pointer. Another way to get the pointer to the current
            thread GC data is the function
            <code>vm_get_gc_thread_local()</code>.

      </ul>
     <p class="backtotop">
         <a href="#Top">Back to Top</a>
   </p>
      <h1>
         <a name="Interpreter"></a>7. Interpreter
      </h1>
      <p>
         The interpreter component executes Java<a href="#*">*</a> bytecode and
         is used in the VM interchangeably with the JIT compiler. The
         interpreter does the following:
      </p>
      <ul>
         <li>
            <i>Simplifies VM debugging<br>
            </i> The native debugger is used to examine the stack trace with
            the minimum of native code used, and data structures are made
            transparent to the debugger.

         <li>
            <i>Provides support for <a href="#TI_in_interpreter">JVMTI</a><br>
            </i> The interpreter supports JVMTI functionality: breakpoints,
            locals inspection, stack trace retrieval, and the pop frame
            functionality.

         <li>
            <i>Enables VM platform portability<br>
            </i> The interpreter code is mostly portable, and platform-specific
            stubs are used only for execution of native methods.

      </ul>
      <p>
         The interpreter supports the following platforms: Windows<a href=
         "#*">*</a> / IA-32, Linux<a href="#*">*</a> / IA-32, Linux<a href=
         "#*">*</a> / Itanium&reg; processor family and Linux<a href="#*">*</a>
         / Intel&reg; EM64T.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The DRL interpreter works on Intel&reg; EM64T, but no JIT compiler is
         currently available for this platform.
      </p>
      <p>
         Currently, the interpreter is closely tied  to the VM core, see <a href=
         "#Interpreter_interface">section 7.2.2</a> for details.
      </p>
      <h3>
         <a name="Interpreter_and_JIT"></a>7.0.1 Interpreter and JIT
      </h3>
      <p>
         The interpreter differs from the JIT compiler. The JIT translates byte
         code into native code and executes the produced native code. The
         interpreter reads the original bytecode and executes a short sequence
         of corresponding C/C++ code. Interpretation is simpler, but substantially slower
         than executing JIT-compiled code.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Characteristics_of_the_Interpreter"></a>7.1 Characteristics
      </h2>
      <h3>
         <a name="Calling_conventions"></a>7.1.1 Calling Conventions
      </h3>
      <p>
         The interpreter is a C/C++ module and its calling conventions
         correspond to the JNI specification conventions.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         In native code, it is impossible to call a function with the number of
         arguments unknown at compile time. That is why, arguments of Java<a
         href="#*">*</a> methods are passed as pointers to arrays of arguments.
      </p>
      <h3>
         <a name="Stack_structure"></a>7.1.2 Stack Structure
      </h3>
      <p>
         The interpreter has its own Java<a href="#*">*</a> stack frame format.
         Each Java<a href="#*">*</a> frame contains the following fields:
      </p>
      <ul>
         <li>
            Pointer to the currently executed method

         <li>
            Operand stack

         <li>
            Area of local variables

         <li>
            Execution pointer

         <li>
            List of locked monitors used by JVMTI

         <li>
            Pointer to the previous Java<a href="#*">*</a> frame

      </ul>
      <p>
         The Java<a href="#*">*</a> frame is allocated on the C stack by using
         the <code>alloca()</code> function.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Interpreter_structure"></a>7.2 Internal Structure
      </h2>
      <p>
         The interpreter consists of the following major components:
      </p>
      <ul>
         <li>
            <i>Bytecode decoder and main switch</i> constitute the main part of
            the interpreter, which locate the micro program corresponding to a
            given bytecode and executes it.

         <li>
            <i>Set of micro programs for each bytecode</i> includes:
            <ul>
               <li>
                  Simple operations, such as integer arithmetic

               <li>
                  Complex operations that request the VM to load a class,
                  perform synchronization, throw an exception, create an object
                  or an array or to request information from the class loader.

            </ul>

         <li>
            <i>JVMTI support functions</i> are used as part of the JVMTI
            implementation and include JVMTI event subsystem support,
            information getters and setters, and breakpoint and frame-popping
            support.

         <li>
            <i>Invoker</i> serves as the entry point to the interpreter for the
            VM; this function runs the interpreter for the given methods with a
            set of parameters.

         <li>
            <i>Platform-specific code,</i> which covers the execution procedure
            for native methods. This function cannot be implemented in a
            platform-independent way, and contains different native code units
            for each supported architecture.

      </ul>
      <h3>
         7.2.1 Packaging structure
      </h3>
      <p>
         This section lists the file groups responsible for major functions of
         the interpreter located in the <code>interpreter</code> folder. </p>
      <pre>
<b>src</b> &ndash; Interpreter source files location.
|
<b>interpreter.cpp</b>
  &ndash; Major interpreter functionality, bytecode handlers.
<b>interpreter_ti.cpp</b>
    &ndash; Support for JVMTI in VM.
<strong>interp_stack_trace.cpp</strong>
    &ndash; Stack trace retrieval and thread root set enumeration for GC.
<strong>interp_vm_helpers.cpp</strong>
    &ndash; Wrappers around VM core functions that enable the interpreter to use them.
<strong>invokeJNI_*.asm</strong>
    &ndash; Platform-specific execution of JNI methods.
    Native function call constructed from the JNI function pointer and an array of arguments.
<strong>interp_native_*.cpp</strong>
    &ndash; Platform-specific execution of JNI methods.
    Definition of the InvokeJNI() function for the Windows<a href=
"#*">*</a>  / IA-32 platform.
<strong>interp_exports.cpp</strong>
    &ndash; Exporting interpreter interface functions to the virtual machine via the functions table.
</pre>
      <h3>
         <a name="Interpreter_interface"></a>7.2.2 Interfaces
      </h3>
      <p>
         The interpreter has a tightly bound and complicated interface for communication with the
         VM core. The interpreter is dynamically linked with the VM core and uses its
         internal interfaces. At the same time, the interpreter exports its
         enumeration, stack trace generation and JVMTI support functions via a
         single method table.
These make up the <em>Interpreter</em> interface. </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="Interpreter_support_VM"></a>7.3 Support Functions
      </h2>
      <h3>
         7.3.1 JNI Support
      </h3>
      <p>
         VM support for execution of JNI methods relies on stub generation.
         This does not suit the interpreter because dynamic code in the stubs
         is hardly fit for debugging. In
         the current implementation, the  interpreter  is mainly aimed at VM code debugging and  uses
         its own code for handling JNI methods.
      </p>
      <p>
         The DRL interpreter provides functions for each type of JNI functions:
         static, virtual, executed from an interpreted frame or from
         interpreter invocation code. The interpreter executes JNI methods by
         performing the following actions:
      </p>
      <ol>
         <li>
            Locates the method native code via a
            <code>find_native_method()</code> call.

         <li>
            Pushes an M2nFrame on the stack to transfer control from managed to
            native code for compatibility with the JIT mode.

         <li>
            Places all arguments in one or several arrays according to calling
            conventions specific for a platform:
            <ol>
               <li>
                  On the IA-32 platform, all arguments are on the stack and in
                  one array.

               <li>
                  On the Itanium&reg; processor family platform, a special
                  handling mechanism is used for arguments placed in integer
                  and floating point registers. A similar mechanism is used on
                  the Intel&reg; EM64T platform.

            </ol>

         <li>
            Optionally, calls the JVMTI method entry event callback.

         <li>
            Synchronizes methods lock with the corresponding monitor.

         <li>
            Notifies the thread management component that the current thread
            can be suspended because at this stage, the code is <a href=
            "#Safe_suspension">GC-safe</a>.

         <li>
            Executes the JNI method via the <code>invokeJNI</code> stub, which
            converts the native code address and arguments array or arrays into
            a function call.

         <li>
            Notifies the thread manager that the current thread cannot be
            suspended at an arbitrary point because the code is no longer
            GC-safe.

         <li>
            Synchronized methods release corresponding monitor.

         <li>
            With JVMTI enabled, calls the method exit event callback.

         <li>
            Destroys the M2nFrame.

      </ol>
      <h3>
         <a name="TI_in_interpreter"></a>7.3.2 JVMTI Support
      </h3>
      <p>
         The DRL interpreter assists the virtual machine in supporting <a href=
         "#JVMTI_Support">JVMTI</a>. The interpreter enables stack walking,
         stack frame examination, method entry and exit events, breakpoints,
         single step and PopFrame functions.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="Porting_Layer"></a>8. Porting Layer
      </h1>
      <h2>
         <a name="Porting_Layer_Characteristics"></a>8.1 Characteristics
      </h2>
      <p>
         This component provides unified interfaces to low-level system
         routines across different platforms. The porting layer mainly covers
         the following functional areas:
      </p>
      <ul>
         <li>
            system and environment information

         <li>
            native and virtual memory management

         <li>
            shared libraries support

         <li>
            file information and I/O

         <li>
            networking

         <li>
            atomic operations

         <li>
            synchronization primitives

         <li>
            low-level facilities for manipulating native processes and threads.

            <p class="note">
               Note
            </p>
            <p class="notetext">
               For most components, high-level threading provided by the thread
               management interface suffices.
            </p>

      </ul>
      <p>
         To maximize benefits of the porting layer, other components interact
         with the underlying operating system and hardware via this component.
         Currently, most DRLVM code uses the <a href="#APR_ref">Apache Portable
         Runtime</a> library as a base porting library, though certain parts
         are still not completely ported to APR, and access the operating
         system directly. The DRL porting library also includes about 20
         additional functions and macros, designed as potential extensions to
         APR. These additions mostly relate to querying system information and
         virtual memory management.
      </p>
      <h2>
         <a name="Component_Manager"></a>8.2 Component Manager
      </h2>
      <p>
         The <em>component manager</em> is a subcomponent of the porting layer
         responsible for loading and subsequent initialization of VM
         components.
      </p>
      <p>
         During the loading stage, the component manager queries the default
         interface from each loading component, and then makes this information
         available at the initialization stage via interface queries. The
         component manager also enables instance creation for interfaces.
         Currently, only the execution manager uses the component manager
         loading scheme.
      </p>
      <h2>
         <a name="Portlib_exported"></a>8.3 Public Interfaces
      </h2>
      <p>
         The porting library is statically linked to the VM core component and
         exports its interfaces through this component.
      </p>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         This implies that APR objects are compiled as exported but packaged as
         a static library (not linked as a self-contained dynamic shared
         library).
      </p>
      <p>
         Other components may directly include porting library headers (APR or
         additional ones), and dynamically link with the VM core.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="Class_Libraries"></a>9. Class Libraries
      </h1>
      <p>
         The class libraries complement the DRLVM to provide a full J2SE<a
         href="#*">*</a>-compliant run-time environment. The class libraries
         contain all classes defined by J2SE<a href="#*">*</a> specification
         [<a href="#Java_api_ref">6</a>] except for the set of <a href=
         "#Kernel_Classes">kernel classes</a>.
      </p>
      <h2>
         <a name="CL_characteristics"></a>9.1 Characteristics
      </h2>
      <p>
         The DRL class libraries satisfy the following requirements:
      </p>
      <ul>
         <li>
            Class files format is compliant with the JVM Specification [<a
            href="#JVM_spec_ref">1</a>].

         <li>
            Class files major version is 46 or earlier.

         <li>
            Provided API complies with the J2SE<a href="#*">*</a> 1.5.0
            specification.

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         DRLVM does not require the full J2SE<a href="#*">*</a> API set in
         order to be functional.
      </p>
      <p class="notetext">
         At startup, DRLVM preloads approximately 20 classes, including the
         kernel classes. The minimal subset for the VM startup is defined by
         the dependencies of the preloaded classes, which can vary in different
         implementations. You can get the exact list from DRLVM sources, mainly
         from <code>vmcore\src\init\vm_init.cpp</code> file.
      </p>
      <h3>
         9.1.1 Interaction
      </h3>
      <p>
         The class libraries interact with the VM through the following
         interfaces:
      </p>
      <ul>
         <li>
            <i><a href="#Kernel_Classes">Kernel classes</a></i>, set of classes
            tied to the VM

         <li>
            <i><a href="#JNI_support">JNI</a></i>, standard interface for
            communication between Java<a href="#*">*</a> classes and native
            code as defined in the JNI specification [<a href="#JNI_ref">5</a>]

         <li>
            <i><a href="#C_VM_Interface">C VM Interface</a></i>, C interface
            used by native parts of the class libraries to access VM
            functionality not available through the kernel classes or the JNI
            framework

         <li>
            <i>VM accessors</i>, Java<a href="#*">*</a> interface used by
            Java<a href="#*">*</a> classes to access VM functionality not
            available through the kernel classes or the JNI framework.

      </ul>
      <p class="note">
         Note
      </p>
      <p class="notetext">
         The current implementation of VM accessors is built on top of JNI.
         Future implementations may utilize the VM-specific Fast (Raw) Native
         Interface or any intrinsic mechanism in order to achieve the better
         performance.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h2>
         <a name="CL_packaging_structure"></a>9.2 Packaging Structure
      </h2>
      <p>
         In DRL, the class libraries are packaged according to the following
         structure on Windows<a href="#*">*</a> and Linux<a href="#*">*</a>:
      </p>
<pre>
<b>ij</b> -java.home
|
+-<b>bin</b> - java.library.path
|
+-<b>lib</b> - vm.boot.class.path
</pre>
      <h3>
         9.2.1 Java<a href="#*">*</a> Classes
      </h3>
      <p>
         The class libraries are packaged as <code>.jar</code> or
         <code>.zip</code> files and stored in the <code>\lib</code> directory.
         Each <code>.jar</code> file contains the classes that belong to a
         specific functional area [<a href="#APR_ref">9</a>]. By default, the
         VM boot class path points to the location of <code>.jar</code> and
         <code>.zip</code> archives, as listed above. You can set an alternate
         location of the boot class path on the command line by using the
         <code>&ndash;Xbootclasspath</code> command-line option.
      </p>

      <h3>
         9.2.2 Native Libraries
      </h3>
      <p>
         Native libraries, <code>.dll</code> files on Windows<a href="#*">*</a>
         and <code>.so</code> files on Linux<a href="#*">*</a> used by the
         class libraries are placed in the <code>\bin</code> directory. You can
         set an alternate location for the native libraries on the command line
         by using the <code>java.library.path</code> property.
      </p>
      <h3>
         9.2.3 Resources
      </h3>
      <p>
         The class libraries would typically use the <code>java.home</code>
         property in order to determine the location of the necessary
         resources, for example, the location of the
         <code>java.security.policy</code> file. By default, the
         <code>java.home</code> property is initialized to the parent directory
         of the <code>ij</code> executable, which is the <code>\ij</code>
         directory, as shown above. You can set an alternate value for the
         <code>java.home</code> property on the command line.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="Inter_component_Optimizations"></a>10. Inter-component
         Optimizations
      </h1>
      <p>
         In DRLVM, safety requirements and dynamic class loading affect the
         applicability and effectiveness of traditional compiler optimizations,
         such as null-check elimination or array-bounds checking. To improve
         performance, DRLVM applies inter-component optimizations to reduce or
         eliminate these safety overheads, and to ensure effective operation in
         the presence of dynamic loading.
      </p>
      <p>
         Inter-component optimizations include various optimization techniques
         supported by more than one component in DRLVM, as described in the
         subsequent sections.
      </p>
      <h2>
         <a name="Fast_subtype_checking"></a>10.1 Fast Subtype Checking
      </h2>
      <p>
         Java<a href="#*">*</a> programs widely use inheritance. The VM needs
         to check whether an object is an instance of a specific super type
         thousand of times per second. These type tests are the result of
         explicit checks in application code (for example, the Java<a href=
         "#*">*</a> <code>checkcast</code> bytecode), as well as implicit
         checks during array stores (for example, Java<a href="#*">*</a>
         <code>aastore</code> bytecode). The array store checks verify that the
         types of objects being stored into arrays are compatible with the
         element types of the arrays. Although functions
         <code>checkcast()</code>, <code>instanceof()</code>, and
         <code>aastore()</code> take up at most a couple of percent of the
         execution time for Java<a href="#*">*</a> benchmarks, that is enough
         to justify some degree of in-lining. The VM core provides the <a href=
         "#VM_JIT"><code>VM_JIT</code></a> interface to allow JIT compilers to
         perform a faster, in-lined type check under certain commonly used
         conditions.
      </p>
      <h2>
         <a name="Direct_call_conversion"></a>10.2 Direct-call Conversion
      </h2>
      <p>
         In DRLVM, Java<a href="#*">*</a> virtual functions are called
         indirectly by using a pointer from a VTable even when the target
         method is precisely known. This is done because a method may not have
         been compiled yet, or it may be recompiled in the future. By using an
         indirect call, the JIT-compiled code for a method can easily be
         changed after the method is first compiled, or after it is
         recompiled.<br>
          Because indirect calls may require additional instructions (at least
         on the Itanium&reg; processor family), and may put additional pressure
         on the branch predictor, converting them into direct calls is
         important. For direct-call conversion, the VM core includes a callback
         mechanism to enable the JIT compiler to patch direct calls when the
         targets change due to compilation or recompilation. When the JIT
         produces a direct call to a method, it calls a function to inform the
         VM core. If the target method is compiled, the VM core calls back into
         the JIT to patch and redirect the call.
      </p>
      <h2>
         <a name="Fast_constant_string"></a>10.3 Fast constant-string
         instantiation
      </h2>
      <p>
         Constant-string instantiation is common in Java<a href="#*">*</a>
         applications, and DRLVM, loads constant strings at run time in a
         single load, as is with static fields. To use this optimization,
         Jitrino calls the class loader interface function
         <code>class_get_const_string_intern_addr()</code> at compile time.
         This function interns the string and returns the address of a location
         pointing to the interned string. Note that the VM core reports this
         location as part of the root set during garbage collection.<br>
          Because string objects are created at compile time regardless of the
         control paths actually executed, the optimization applied blindly to
         all JIT-compiled code, might result in allocation of a significant
         number of unnecessary string objects. To avoid this, apply the
         heuristic method of not using fast strings in exception handlers.
      </p>
      <h2>
         <a name="Lazy_exceptions"></a>10.4 Lazy Exceptions
      </h2>
      <p>
         Certain applications make extensive use of exceptions for control
         flow. Often, however, the exception object is not used in the
         exception handler. In such cases, the time spent on creating the
         exception object and creating and recording the stack trace in the
         exception object is wasted. The lazy exceptions optimization enables
         the JIT compiler and the VM core to cooperate on eliminating the
         creation of exception objects with an ordinary constructor in case
         these objects are not used later on.
      </p>
      <p>
         To implement lazy exceptions, the JIT compiler finds the exception
         objects that are used only in the <code>throw</code> statements in the
         compiled method. The JIT compiler analyzes the constructors of these
         objects for possible side effects. If the constructor has no side
         effects, the JIT removes the exception object construction
         instructions and substitutes a <code>throw</code> statement with a
         call to a run-time function that performs the lazy exception throwing
         operation. During execution of the new function, the VM core unwinds
         the stack to find the matching handler, and does one of the following
         depending on the exception object state:
      </p>
      <ul>
         <li>
            If the exception object is not used in the handler, the VM core
            transfers control to the handler without creating the exception
            object and the associated stack trace.

         <li>
            If the exception object is used inside the handler, the VM core
            creates the exception object and invokes the constructor passing
            the appropriate arguments to it.

      </ul>
      <p>
         The lazy exceptions technique significantly improves performance. For more information on exceptions in DRLVM,
         see section <a href="#Exception_Handling">3.9 Exception Handling</a>.
      </p>
      <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <h1>
         <a name="References"></a>11. References
      </h1>
      <p>
         This section lists the external references to various sources used in
         DRLVM documentation, and to standards applied to DRLVM implementation.
      </p>
      <p>
         [<a name="JVM_spec_ref">1</a>] Java<a href="#*">*</a> Virtual Machine
         Specification, <a href=
         "http://java.sun.com/docs/books/vmspec/2nd-edition/html/VMSpecTOC.doc.html"
          target=
         "_blank">http://java.sun.com/docs/books/vmspec/2nd-edition/html/VMSpecTOC.doc.html</a>
      </p>
      <p>
         [<a name="Java_lang_spec_ref" target="_blank">2</a>]Java<a href=
         "#*">*</a> Language Specification, Third Edition, <a href=
         "http://java.sun.com/docs/books/jls/" target=
         "_blank">http://java.sun.com/docs/books/jls/</a>
      </p>
      <p>
         [<a name="JIT_spec_ref" target="_blank">3</a>]JIT Compiler Interface
         Specification, Sun Microsystems, <a href=
         "http://java.sun.com/docs/jit_interface.html" target=
         "_blank">http://java.sun.com/docs/jit_interface.html</a>
      </p>
      <p>
         [<a name="JVMTI_ref" target="_blank">4</a>]JVM Tool Interface
         Specification, <a href=
         "http://java.sun.com/j2se/1.5.0/docs/guide/jvmti/jvmti.html" target=
         "_blank">http://java.sun.com/j2se/1.5.0/docs/guide/jvmti/jvmti.html</a>
      </p>
      <p>
         [<a name="JNI_ref" target="_blank">5</a>] Java<a href="#*">*</a>
         Native Interface Specification, <a href=
         "http://java.sun.com/j2se/1.5.0/docs/guide/jni/spec/jniTOC.html"
         target=
         "_blank">http://java.sun.com/j2se/1.5.0/docs/guide/jni/spec/jniTOC.html</a>
      </p>
      <p>
         [<a name="Java_api_ref" target="_blank">6</a>]Java<a href="#*">*</a>
         API Specification, <a href="http://java.sun.com/j2se/1.5.0/docs/api"
         target="_blank">http://java.sun.com/j2se/1.5.0/docs/api</a>
      </p>
      <p>
         [<a name="Invoc_api_ref">7</a>] Java<a href="#*">*</a> Invocation API
         Specification, <a href=
         "http://java.sun.com/j2se/1.5.0/docs/guide/jni/spec/invocation.html"
         target=
         "_blank">http://java.sun.com/j2se/1.5.0/docs/guide/jni/spec/invocation.html</a>
      </p>
      <p>
         [<a name="debug_tut_ref">8</a>]Creating a Debugging and Profiling
         Agent with JVMTI tutorial, <a href=
         "http://java.sun.com/developer/technicalArticles/Programming/jvmti/index.html"
          target=
         "_blank">http://java.sun.com/developer/technicalArticles/Programming/jvmti/index.html</a>
      </p>
      <p>
         [<a name="harmony_ref">9</a>] Apache Harmony project, <a href=
         "http://incubator.apache.org/harmony/" target=
         "_blank">http://incubator.apache.org/harmony/</a>.
      </p>
      <p>
         [<a name="Intel_manual_ref">10</a>] <i>IA-32 Intel Architecture
         Software Developer&#39;s Manual</i>, Intel Corp., <a href=
         "http://www.intel.com/design" target=
         "_blank">http://www.intel.com/design</a>
      </p>
      <p>
         [<a name="compres_ref">11</a>] Ali-Reza Adl-Tabatabai, Jay Bharadwaj,
         Michal Cierniak, Marsha Eng, Jesse Fang, Brian T. Lewis, Brian R.
         Murphy, and James M. Stichnoth, <i>Improving 64-Bit Java<a href=
         "#*">*</a> IPF Performance by Compressing Heap References, Proceedings
         of the International Symposium on Code Generation and Optimization</i>
         (CGO&rsquo;04), 2004, <a href="http://www.cgo.org/cgo2004/" target=
         "_blank">http://www.cgo.org/cgo2004/</a>
      </p>
      <p>
         [<a name="GC_article_ref">12</a>] Stichnoth, J.M., Lueh, G.-Y. and
         Cierniak, M., <i>Support for Garbage Collection at Every Instruction
         in a Java<a href="#*">*</a> Compiler</i>, <i>ACM Conference on
         Programming Language Design and Implementation</i>, Atlanta, Georgia,
         1999, <a href="http://www.cs.rutgers.edu/pldi99/" target=
         "_blank">http://www.cs.rutgers.edu/pldi99/</a>
      </p>
      <p>
         [<a name="GC_article2_ref">13</a>] Wilson, P.R., <i>Uniprocessor
         Garbage Collection Techniques</i>, in revision (accepted for ACM
         Computing Surveys). <a href=
         "ftp://ftp.cs.utexas.edu/pub/garbage/bigsurv.ps" target=
         "_blank">ftp://ftp.cs.utexas.edu/pub/garbage/bigsurv.ps</a>
      </p>
      <p>
         [<a name="APR_ref">14</a>] Apache Portable Runtime library, <a href=
         "http://apr.apache.org/" target="_blank">http://apr.apache.org/</a>
      </p>
      <p>
         [<a name="Muchnik_ref">15</a>] S. Muchnick, <i>Advanced Compiler
         Design and Implementation</i>, Morgan Kaufmann, San Francisco, CA,
         1997.
      </p>
      <p>
         [<a name="value_number_ref">16</a>] P. Briggs, K.D., Cooper and L.T.
         Simpson, <i>Value Numbering. Software-Practice and Experience</i>,
         vol. 27(6), June 1997, <a href=
         "http://www.informatik.uni-trier.de/~ley/db/journals/spe/spe27.html"
         target=
         "_blank">http://www.informatik.uni-trier.de/~ley/db/journals/spe/spe27.html</a>
      </p>
      <p>
         [<a name="enumer_ref">17</a>] R. Bodik, R. Gupta, and V. Sarkar,
         <i>ABCD: Eliminating Array-Bounds Checks on Demand, in proceedings of
         the SIGPLAN &rsquo;00 Conference on Program Language Design and
         Implementation</i>, Vancouver, Canada, June 2000, <a href=
         "http://research.microsoft.com/~larus/pldi2000/pldi2000.htm" target=
         "_blank">http://research.microsoft.com/~larus/pldi2000/pldi2000.htm</a></p>
      <p>
         [<a name="Wilson_GC_Ref"></a>18] Paul R. Wilson, <em>Uniprocessor
         garbage collection techniques</em>, Yves Bekkers and Jacques Cohen
         (eds.), Memory Management - International Workshop IWMM 92, St. Malo,
         France, September 1992, proceedings published as Springer-Verlag
         Lecture Notes in Computer Science no. 637.
      </p>
      <p>
         [<a name="Venners_Inside_VM_ref"></a>19] Bill Venners, <em>Inside Java
         2 Virtual Machine</em>, <a href="http://www.artima.com/insidejvm/ed2/"
         target="_blank">http://www.artima.com/insidejvm/ed2/</a>
</p>
      <p>[<a name="SVN_IBMdoc_ref"></a>20] Harmony Class Library Porting Documentation,
	  <a href="http://svn.apache.org/viewcvs.cgi/*checkout*/incubator/harmony/enhanced/classlib/trunk/doc/vm_doc/html/index.html?content-type=text%2Fplain"
	  target="_blank">
	  http://svn</a><a href="http://svn.apache.org/viewcvs.cgi/*checkout*/incubator/harmony/enhanced/classlib/trunk/doc/vm_doc/html/index.html?content-type=text%2Fplain"
	  target="_blank">.apache.org/viewcvs.cgi/*checkout*/incubator/harmony/enhanced/classlib/trunk/doc/vm_doc/html/index.html?content-type=text%2Fplain </a>
	  </p>
	        <p>
         [<a name="CodePosit_ref"></a>21]Karl Pettis, Robert C. Hansen,
         <em>Profile Guided Code Positioning</em>, <a href=
         "http://www.informatik.uni-trier.de/~ley/db/conf/pldi/pldi90.html"
         target=
         "_blank">http://www.informatik.uni-trier.de/~ley/db/conf/pldi/pldi90.html</a>
</p>
            <p class="backtotop">
         <a href="#Top">Back to Top</a>
      </p>
      <p>
         (C) Copyright 2005 Intel Corporation
      </p>
      <p>
         <a name="*">*</a> Other brands and names are the property of their
         respective owners.
      </p>
   </body>
</html>

